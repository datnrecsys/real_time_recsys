{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from loguru import logger\n",
    "from pydantic import BaseModel, model_validator\n",
    "from load_dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from feast import FeatureStore\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src.utils.split_time_based import train_test_split_timebased\n",
    "from src.utils.embedding_id_mapper import IDMapper\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "_ = load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"run_name\": \"data_preparation\",\n",
      "  \"run_description\": \"Splitting data into train, val, test sets, then sampling data for quick iteration\",\n",
      "  \"testing\": false,\n",
      "  \"sample_data_persit_path\": \"/home/ubuntu/local-data/real_time_recsys/data_for_ai/interim\",\n",
      "  \"notebook_persit_path\": \"/home/ubuntu/local-data/real_time_recsys/notebooks/data/data_preparation\",\n",
      "  \"random_seed\": 41,\n",
      "  \"user_col\": \"user_id\",\n",
      "  \"item_col\": \"parent_asin\",\n",
      "  \"rating_col\": \"rating\",\n",
      "  \"timestamp_col\": \"timestamp\",\n",
      "  \"sample_users\": 5000,\n",
      "  \"min_user_interactions\": 5,\n",
      "  \"min_item_interactions\": 10,\n",
      "  \"val_num_days\": 15,\n",
      "  \"test_num_days\": 30,\n",
      "  \"user\": \"resys-user\",\n",
      "  \"password\": \"hehehe\",\n",
      "  \"db\": \"amazon_rating\",\n",
      "  \"host\": \"0.0.0.0\",\n",
      "  \"port\": 5432,\n",
      "  \"oltp_shema\": \"oltp\",\n",
      "  \"transtion_table_name\": \"transactions\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Args(BaseModel):\n",
    "    run_name: str = \"data_preparation\"\n",
    "    run_description: str = \"Splitting data into train, val, test sets, then sampling data for quick iteration\"\n",
    "    testing: bool = False\n",
    "    sample_data_persit_path: str = None    # path of the sampled data: train, test and val\n",
    "    notebook_persit_path: str = None    # path of the notebook\n",
    "    random_seed: int = 41\n",
    "\n",
    "    user_col: str = \"user_id\"\n",
    "    item_col: str = \"parent_asin\"\n",
    "    rating_col: str = \"rating\"\n",
    "    timestamp_col: str = \"timestamp\"\n",
    "\n",
    "    sample_users: int = 5000\n",
    "    min_user_interactions: int = 5\n",
    "    min_item_interactions: int = 10\n",
    "\n",
    "    val_num_days: int = 15\n",
    "    test_num_days: int = 30\n",
    "\n",
    "    # Database credentials\n",
    "    user: str = None\n",
    "    password: str = None\n",
    "    db: str = None\n",
    "    host: str = None\n",
    "    port: int = None\n",
    "    oltp_shema: str = None\n",
    "    transtion_table_name: str = \"transactions\"\n",
    "\n",
    "    @model_validator(mode=\"before\")\n",
    "    def load_env_vars(cls, values):\n",
    "        # Load environment variables if not explicitly set\n",
    "        values[\"user\"] = values.get(\"user\") or os.getenv(\"POSTGRES_USER\")\n",
    "        values[\"password\"] = values.get(\"password\") or os.getenv(\"POSTGRES_PASSWORD\")\n",
    "        values[\"db\"] = values.get(\"db\") or os.getenv(\"POSTGRES_DB\")\n",
    "        values[\"host\"] = values.get(\"host\") or os.getenv(\"POSTGRES_HOST\")\n",
    "        values[\"port\"] = values.get(\"port\") or os.getenv(\"POSTGRES_PORT\")\n",
    "        values[\"oltp_shema\"] = values.get(\"oltp_shema\") or os.getenv(\"POSTGRES_OLTP_SCHEMA\")\n",
    "        return values\n",
    "\n",
    "    def init(self):\n",
    "        self.sample_data_persit_path = os.path.abspath(f\"../data_for_ai/interim\")\n",
    "        self.notebook_persit_path = os.path.abspath(f\"./data/{self.run_name}\")\n",
    "        if not self.testing:\n",
    "            os.makedirs(self.sample_data_persit_path, exist_ok=True)\n",
    "            os.makedirs(self.notebook_persit_path, exist_ok=True)\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "args = Args().init()\n",
    "\n",
    "print(args.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from a specific period in order to train the model\n",
    "\n",
    "In notebook 002-simulate-oltp, we can see that the time period from March 2020 to Sep 2020 is the good choice. There are active interactions between users and items in this period and wen can keep the recency. So, we will load data from this period to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create connection\n",
    "connection_string = f\"postgresql://{args.user}:{args.password}@{args.host}:{args.port}/{args.db}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Query with chunk processing\n",
    "query = f\"\"\"\n",
    "SELECT {args.timestamp_col}, {args.user_col}, {args.item_col}, {args.rating_col} \n",
    "FROM {args.oltp_shema}.{args.transtion_table_name}\n",
    "WHERE {args.timestamp_col} >= EXTRACT(EPOCH FROM TIMESTAMP '2020-06-01') * 1000 \n",
    "\"\"\"\n",
    "\n",
    "# Process chunks with tqdm for progress tracking\n",
    "df_list = []\n",
    "chunk_size = 10000  # Adjust chunk size based on available memory\n",
    "\n",
    "chunks = pd.read_sql(query, engine, chunksize=chunk_size)\n",
    "for chunk in tqdm(chunks, desc=\"Loading data\", unit=\"chunk\"):\n",
    "    df_list.append(chunk.drop_duplicates())  # Drop duplicates per chunk\n",
    "\n",
    "# Concatenate all processed chunks into a final DataFrame\n",
    "full_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "print(f\"Final DataFrame shape: {full_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.assign(timestamp=pd.to_datetime(full_df.timestamp, unit=\"ms\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train, val, test\n",
    "train_df, val_df, test_df = train_test_split_timebased(\n",
    "    full_df, user_id_col=\"user_id\",\n",
    "        item_id_col=\"parent_asin\",\n",
    "        timestamp_col=\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_df[args.timestamp_col].max() < val_df[args.timestamp_col].min(), \"There are overlapping timestamps between train and validation datasets.\"\n",
    "assert val_df[args.timestamp_col].max() < test_df[args.timestamp_col].min(), \"There are overlapping timestamps between validation and test datasets.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Train: {train_df.shape}, Val: {val_df.shape}, Test: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling data\n",
    "\n",
    "Just randomly get X users will not guarantee that the output dataset would qualify the condition of **richness**. Instead we take an iterative approach where we gradually drop random users from the dataset while keeping an eye on the conditions and our sampling target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_random_users(df, k=10):\n",
    "    users = df[args.user_col].unique()\n",
    "    np.random.seed(args.random_seed)\n",
    "    to_remove_users = np.random.choice(users, size=k, replace=False)\n",
    "    return df.loc[lambda df: ~df[args.user_col].isin(to_remove_users)]\n",
    "\n",
    "\n",
    "def get_unqualified(df, col: str, threshold: int):\n",
    "    unqualified = df.groupby(col).size().loc[lambda s: s < threshold].index\n",
    "    return unqualified\n",
    "\n",
    "\n",
    "get_unqualified_users = partial(\n",
    "    get_unqualified, col=args.user_col, threshold=args.min_user_interactions\n",
    ")\n",
    "get_unqualified_items = partial(\n",
    "    get_unqualified, col=args.item_col, threshold=args.min_item_interactions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_perc = 0.2\n",
    "perc_users_removed_each_round = 0.01\n",
    "debug = True\n",
    "keep_random_removing = True\n",
    "r = 1\n",
    "\n",
    "sample_df = train_df.copy()\n",
    "\n",
    "while keep_random_removing:\n",
    "    num_users_removed_each_round = int(\n",
    "        perc_users_removed_each_round * sample_df[args.user_col].nunique()\n",
    "    )\n",
    "    print(\n",
    "        f\"\\n\\nRandomly removing {num_users_removed_each_round} users - Round {r} started\"\n",
    "    )\n",
    "    sample_df = remove_random_users(sample_df, k=num_users_removed_each_round)\n",
    "\n",
    "    keep_removing = True\n",
    "    i = 1\n",
    "\n",
    "    while keep_removing:\n",
    "        if debug:\n",
    "            logger.info(f\"Sampling round {i} started\")\n",
    "        keep_removing = False\n",
    "        uu = get_unqualified_users(sample_df)\n",
    "        if debug:\n",
    "            logger.info(f\"{len(uu)=}\")\n",
    "        if len(uu):\n",
    "            sample_df = sample_df.loc[lambda df: ~df[args.user_col].isin(uu)]\n",
    "            if debug:\n",
    "                logger.info(f\"After removing uu: {len(sample_df)=}\")\n",
    "            assert len(get_unqualified_users(sample_df)) == 0\n",
    "            keep_removing = True\n",
    "        ui = get_unqualified_items(sample_df)\n",
    "        if debug:\n",
    "            logger.info(f\"{len(ui)=}\")\n",
    "        if len(ui):\n",
    "            sample_df = sample_df.loc[lambda df: ~df[args.item_col].isin(ui)]\n",
    "            if debug:\n",
    "                logger.info(f\"After removing ui: {len(sample_df)=}\")\n",
    "            assert len(get_unqualified_items(sample_df)) == 0\n",
    "            keep_removing = True\n",
    "        i += 1\n",
    "\n",
    "    sample_users = sample_df[args.user_col].unique()\n",
    "    sample_items = sample_df[args.item_col].unique()\n",
    "    num_users = len(sample_users)\n",
    "    logger.info(f\"After randomly removing users - round {r}: {num_users=}\")\n",
    "    if num_users > args.sample_users * (1 + buffer_perc):\n",
    "        logger.info(\n",
    "            f\"Number of users {num_users} are still greater than expected, keep removing...\"\n",
    "        )\n",
    "    else:\n",
    "        logger.info(\n",
    "            f\"Number of users {num_users} are falling below expected threshold, stop and use `sample_df` as final output...\"\n",
    "        )\n",
    "        keep_random_removing = False\n",
    "    \n",
    "    val_sample_df = val_df.loc[\n",
    "                lambda df: df[args.user_col].isin(sample_users)\n",
    "                & df[args.item_col].isin(sample_items)\n",
    "            ]\n",
    "    test_sample_df = test_df.loc[\n",
    "                lambda df: df[args.user_col].isin(sample_users)\n",
    "                & df[args.item_col].isin(sample_items)\n",
    "            ]\n",
    "    if (num_val_records := val_sample_df.shape[0]) < 3000:\n",
    "        logger.info(\n",
    "            f\"Number of val_df records {num_val_records:,.0f} are falling below expected threshold, stop and use `sample_df` as final output...\"\n",
    "        )\n",
    "        keep_random_removing = False\n",
    "    if (num_test_records := test_sample_df.shape[0]) < 3000:\n",
    "        logger.info(\n",
    "            f\"Number of test_df records {num_test_records:,.0f} are falling below expected threshold, stop and use `sample_df` as final output...\"\n",
    "        )\n",
    "        keep_random_removing = False\n",
    "\n",
    "    r += 1\n",
    "\n",
    "sample_users = sample_df[args.user_col].unique()\n",
    "sample_items = sample_df[args.item_col].unique()\n",
    "logger.info(f\"Final sample sizes: {len(sample_users)=:,.0f}, {len(sample_items)=:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sample_df[args.timestamp_col].max() < val_sample_df[args.timestamp_col].min(), \"There are overlapping timestamps between train and validation datasets.\"\n",
    "assert val_sample_df[args.timestamp_col].max() < test_sample_df[args.timestamp_col].min(), \"There are overlapping timestamps between validation and test datasets.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert val_sample_df.loc[lambda df: ~df[args.user_col].isin(sample_users)].shape[0] == 0, \"Validation DataFrame contains unexpected users.\"\n",
    "assert test_sample_df.loc[lambda df: ~df[args.user_col].isin(sample_users)].shape[0] == 0, \"Test DataFrame contains unexpected users.\"\n",
    "assert val_sample_df.loc[lambda df: ~df[args.item_col].isin(sample_items)].shape[0] == 0, \"Validation DataFrame contains unexpected items.\"\n",
    "assert test_sample_df.loc[lambda df: ~df[args.item_col].isin(sample_items)].shape[0] == 0, \"Test DataFrame contains unexpected items.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(sample_df.groupby(args.user_col).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(sample_df.groupby(args.item_col).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = [\"train\", \"val\", \"test\"]\n",
    "original_length = {\"train\": train_df.shape[0], \"val\": val_df.shape[0], \"test\": test_df.shape[0]}\n",
    "sampled_length = {\"train\": sample_df.shape[0], \"val\": val_sample_df.shape[0], \"test\": test_sample_df.shape[0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=3)\n",
    "\n",
    "# Add data for each subset\n",
    "for i, subset in enumerate(subsets):\n",
    "    row = i // 3 + 1\n",
    "    col = i % 3 +1\n",
    "\n",
    "    # Add trace for 'curr'\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name=\"original\",\n",
    "            x=[subset],\n",
    "            y=[original_length[subset]],\n",
    "            marker_color = \"lightblue\",\n",
    "            showlegend=(i == 0),\n",
    "            texttemplate=\"%{y:.2}\",\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col,\n",
    "    )\n",
    "\n",
    "    # Add trace for 'new'\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name=\"sample\",\n",
    "            x=[subset],\n",
    "            y=[sampled_length[subset]],\n",
    "            marker_color=\"lightgreen\",\n",
    "            showlegend=(i == 0),\n",
    "            texttemplate=\"%{y:.2}\",\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col,\n",
    "    )\n",
    "\n",
    "    # Add diff annotation\n",
    "    difference = (sampled_length[subset] - original_length[subset]) / original_length[\n",
    "        subset\n",
    "    ]\n",
    "    fig.add_annotation(\n",
    "        x=subset,\n",
    "        y=sampled_length[subset] * 1.10,  # Position above the tallest bar\n",
    "        text=f\"Δ={difference:.2%}\",\n",
    "        showarrow=False,\n",
    "        font=dict(color=\"black\", size=14),\n",
    "        row=row,\n",
    "        col=col,\n",
    "    )\n",
    "\n",
    "fig.update_layout(showlegend=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perit the sampled data\n",
    "sample_df.to_parquet(f\"{args.sample_data_persit_path}/train_sample_interactions_8000u.parquet\")\n",
    "val_sample_df.to_parquet(f\"{args.sample_data_persit_path}/val_sample_interactions_8000u.parquet\")\n",
    "test_sample_df.to_parquet(f\"{args.sample_data_persit_path}/test_sample_interactions_8000u.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to version your data with dvc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data and split it into train-val-test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_df = pd.read_parquet(f\"{args.sample_data_persit_path}/train_sample_interactions_8000u.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_interactions_over_time(df):\n",
    "    df = df.assign(timestamp=df[args.timestamp_col].dt.date)\n",
    "    plot_df = df.groupby(args.timestamp_col).size()\n",
    "\n",
    "    fig = px.line(\n",
    "        x=plot_df.index,\n",
    "        y=plot_df.values,\n",
    "        labels={\"x\": \"Date\", \"y\": \"Number of Interactions\"},\n",
    "        title=\"Interactions Over Time\",\n",
    "        height=500,\n",
    "    )\n",
    "\n",
    "    fig.update_layout(yaxis=dict(showticklabels=True, tickformat=\",\"))\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2931</th>\n",
       "      <td>2020-11-21 11:31:14.232</td>\n",
       "      <td>AH6U3RG4SKWXF4KNH3RC6VD5P4QQ</td>\n",
       "      <td>B0953YFR2M</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>2021-05-25 12:17:57.423</td>\n",
       "      <td>AGBOFSSHGILKH73MJZUUOTRCD4CA</td>\n",
       "      <td>B0BW9DSR52</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>2020-07-19 13:47:10.212</td>\n",
       "      <td>AEEDFUQ7SXVEZ4VBHTED5D6MZ7QA</td>\n",
       "      <td>B08YX4HGRY</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3375</th>\n",
       "      <td>2020-10-19 19:13:42.773</td>\n",
       "      <td>AHR6RGZTLOMBD7EBF3OK43JWMGNQ</td>\n",
       "      <td>B09NTXBJDM</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>2021-05-17 23:23:05.132</td>\n",
       "      <td>AGZMKHWSCB3UXDGFUPFRZSL4EAWQ</td>\n",
       "      <td>B08XD3WW2H</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24565423</th>\n",
       "      <td>2020-07-13 10:51:57.066</td>\n",
       "      <td>AFGEK77LF27ECZWRR5J2TZGEOJ7A</td>\n",
       "      <td>B00KDSGIPK</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24565424</th>\n",
       "      <td>2020-07-13 10:55:37.739</td>\n",
       "      <td>AFGEK77LF27ECZWRR5J2TZGEOJ7A</td>\n",
       "      <td>B017250D16</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24565425</th>\n",
       "      <td>2020-07-13 11:08:07.474</td>\n",
       "      <td>AFGEK77LF27ECZWRR5J2TZGEOJ7A</td>\n",
       "      <td>B076TCPKJT</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24565426</th>\n",
       "      <td>2020-09-02 18:58:47.052</td>\n",
       "      <td>AFGEK77LF27ECZWRR5J2TZGEOJ7A</td>\n",
       "      <td>B01MDKA8EH</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24565428</th>\n",
       "      <td>2020-12-02 01:05:35.494</td>\n",
       "      <td>AFGEK77LF27ECZWRR5J2TZGEOJ7A</td>\n",
       "      <td>B07DD3Z1VV</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183267 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       timestamp                       user_id parent_asin  \\\n",
       "2931     2020-11-21 11:31:14.232  AH6U3RG4SKWXF4KNH3RC6VD5P4QQ  B0953YFR2M   \n",
       "2992     2021-05-25 12:17:57.423  AGBOFSSHGILKH73MJZUUOTRCD4CA  B0BW9DSR52   \n",
       "3303     2020-07-19 13:47:10.212  AEEDFUQ7SXVEZ4VBHTED5D6MZ7QA  B08YX4HGRY   \n",
       "3375     2020-10-19 19:13:42.773  AHR6RGZTLOMBD7EBF3OK43JWMGNQ  B09NTXBJDM   \n",
       "3547     2021-05-17 23:23:05.132  AGZMKHWSCB3UXDGFUPFRZSL4EAWQ  B08XD3WW2H   \n",
       "...                          ...                           ...         ...   \n",
       "24565423 2020-07-13 10:51:57.066  AFGEK77LF27ECZWRR5J2TZGEOJ7A  B00KDSGIPK   \n",
       "24565424 2020-07-13 10:55:37.739  AFGEK77LF27ECZWRR5J2TZGEOJ7A  B017250D16   \n",
       "24565425 2020-07-13 11:08:07.474  AFGEK77LF27ECZWRR5J2TZGEOJ7A  B076TCPKJT   \n",
       "24565426 2020-09-02 18:58:47.052  AFGEK77LF27ECZWRR5J2TZGEOJ7A  B01MDKA8EH   \n",
       "24565428 2020-12-02 01:05:35.494  AFGEK77LF27ECZWRR5J2TZGEOJ7A  B07DD3Z1VV   \n",
       "\n",
       "          rating  \n",
       "2931         5.0  \n",
       "2992         5.0  \n",
       "3303         5.0  \n",
       "3375         4.0  \n",
       "3547         4.0  \n",
       "...          ...  \n",
       "24565423     5.0  \n",
       "24565424     4.0  \n",
       "24565425     3.0  \n",
       "24565426     4.0  \n",
       "24565428     5.0  \n",
       "\n",
       "[183267 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build up idm\n",
    "# Sorted to make sure that even rerun we get same idm mapping\n",
    "unique_user_ids = sorted(train_sample_df[args.user_col].unique())\n",
    "unique_item_ids = sorted(train_sample_df[args.item_col].unique())\n",
    "logger.info(f\"Number of unique users: {len(unique_user_ids):,.0f}\")\n",
    "logger.info(f\"Number of unique items: {len(unique_item_ids):,.0f}\")\n",
    "idm = IDMapper()\n",
    "idm.fit(unique_user_ids, unique_item_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idm.save(f\"{args.notebook_persit_path}/idm_8000u.json\")\n",
    "idm_persist_fp = f\"{args.notebook_persit_path}/idm_8000u.json\"\n",
    "idm = IDMapper().load(idm_persist_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(idm.item_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, _ in idm.item_to_index.items():\n",
    "    assert type(k) is str, \"Type of user id should be string\"\n",
    "for k,_ in idm.user_to_index.items():\n",
    "    assert type(k) is str, \"Type of item id should be string\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
