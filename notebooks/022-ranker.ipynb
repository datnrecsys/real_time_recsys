{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bf1577c-6f3b-4b1c-a848-8f5e45ff8111",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Ranker that can takes into accound different features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9309e017-0449-46ee-b7ca-4c4bcadeedf6",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8f6e8d-f776-4d39-898c-d783c5ae3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b3499d-dc9c-405a-8714-a26341b581e1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src.ann'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mranker\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UserItemBinaryDFDataset\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membedding_id_mapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IDMapper\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mranker\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RankerInferenceWrapper\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mranker\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Ranker\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mranker\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LitRanker\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\..\\src\\algo\\ranker\\inference.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mann\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AnnIndex\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeatures\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtimestamp_bucket\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m from_ts_to_bucket\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mid_mapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IDMapper\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src.ann'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import dill\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from loguru import logger\n",
    "from mlflow.exceptions import MlflowException\n",
    "from mlflow.models.signature import infer_signature\n",
    "from pydantic import BaseModel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import mlflow\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from cfg.run_cfg import RunCfg\n",
    "from src.ann import AnnIndex\n",
    "from src.utils.data_prep import chunk_transform\n",
    "from src.algo.ranker.dataset import UserItemBinaryDFDataset\n",
    "from src.utils.embedding_id_mapper import IDMapper\n",
    "from src.algo.ranker.inference import RankerInferenceWrapper\n",
    "from src.algo.ranker.model import Ranker\n",
    "from src.algo.ranker.trainer import LitRanker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd804021-3424-48e0-973a-e662a72db544",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce522d9e-f35c-4cc5-a71e-68447956b31f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# This is a parameter cell used by papermill\n",
    "max_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea4e9a93-5b6a-4dec-97f0-b9aa3383c64d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-23 15:11:36.236\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcfg.run_cfg\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m31\u001b[0m - \u001b[34m\u001b[1mSetting use_sbert_features=True requires running notebook 016-sentence-transformers\u001b[0m\n",
      "\u001b[32m2025-06-23 15:11:36.236\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcfg.run_cfg\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m38\u001b[0m - \u001b[34m\u001b[1mChanging use_item_tags_from_llm requires re-running notebook 002-features-v2 to get the new item_metadata_pipeline.dill file\u001b[0m\n",
      "\u001b[32m2025-06-23 15:11:36.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mSetting up MLflow experiment RecSys MVP - Ranker - run 004-use-sbert-features-and-llm-tags...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"testing\": false,\n",
      "  \"author\": \"quy.dinh\",\n",
      "  \"log_to_mlflow\": true,\n",
      "  \"experiment_name\": \"RecSys MVP - Ranker\",\n",
      "  \"run_name\": \"004-use-sbert-features-and-llm-tags\",\n",
      "  \"notebook_persist_dp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\notebooks\\\\data\\\\004-use-sbert-features-and-llm-tags\",\n",
      "  \"random_seed\": 41,\n",
      "  \"device\": \"cpu\",\n",
      "  \"rc\": {\n",
      "    \"use_sbert_features\": true,\n",
      "    \"use_item_tags_from_llm\": false,\n",
      "    \"item_feature_cols\": [\n",
      "      \"main_category\",\n",
      "      \"categories\",\n",
      "      \"price\",\n",
      "      \"parent_asin_rating_cnt_365d\",\n",
      "      \"parent_asin_rating_avg_prev_rating_365d\",\n",
      "      \"parent_asin_rating_cnt_90d\",\n",
      "      \"parent_asin_rating_avg_prev_rating_90d\",\n",
      "      \"parent_asin_rating_cnt_30d\",\n",
      "      \"parent_asin_rating_avg_prev_rating_30d\",\n",
      "      \"parent_asin_rating_cnt_7d\",\n",
      "      \"parent_asin_rating_avg_prev_rating_7d\"\n",
      "    ]\n",
      "  },\n",
      "  \"item_metadata_pipeline_fp\": \"../data_for_ai/interim/item_metadata_pipeline.dill\",\n",
      "  \"qdrant_url\": \"138.2.61.6:6333\",\n",
      "  \"qdrant_collection_name\": \"item_desc_sbert\",\n",
      "  \"max_epochs\": 100,\n",
      "  \"batch_size\": 128,\n",
      "  \"tfm_chunk_size\": 10000,\n",
      "  \"neg_to_pos_ratio\": 1,\n",
      "  \"user_col\": \"user_id\",\n",
      "  \"item_col\": \"parent_asin\",\n",
      "  \"rating_col\": \"rating\",\n",
      "  \"timestamp_col\": \"timestamp\",\n",
      "  \"top_K\": 100,\n",
      "  \"top_k\": 10,\n",
      "  \"embedding_dim\": 128,\n",
      "  \"item_sequence_ts_bucket_size\": 10,\n",
      "  \"bucket_embedding_dim\": 16,\n",
      "  \"dropout\": 0.3,\n",
      "  \"early_stopping_patience\": 5,\n",
      "  \"learning_rate\": 0.001,\n",
      "  \"l2_reg\": 0.00001,\n",
      "  \"mlf_item2vec_model_name\": \"item2vec\",\n",
      "  \"mlf_model_name\": \"ranker\",\n",
      "  \"min_roc_auc\": 0.7,\n",
      "  \"best_checkpoint_path\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Args(BaseModel):\n",
    "    testing: bool = False\n",
    "    author: str = \"quy.dinh\"\n",
    "    log_to_mlflow: bool = True\n",
    "    experiment_name: str = \"RecSys MVP - Ranker\"\n",
    "    run_name: str = \"004-use-sbert-features-and-llm-tags\"\n",
    "    notebook_persist_dp: str = None\n",
    "    random_seed: int = 41\n",
    "    device: str = None\n",
    "\n",
    "    rc: RunCfg = RunCfg().init()\n",
    "\n",
    "    item_metadata_pipeline_fp: str = \"../data_for_ai/interim/item_metadata_pipeline.dill\"\n",
    "    qdrant_url: str = None\n",
    "    qdrant_collection_name: str = \"item_desc_sbert\"\n",
    "\n",
    "    max_epochs: int = max_epochs\n",
    "    batch_size: int = 128\n",
    "    tfm_chunk_size: int = 10000\n",
    "    neg_to_pos_ratio: int = 1\n",
    "\n",
    "    user_col: str = \"user_id\"\n",
    "    item_col: str = \"parent_asin\"\n",
    "    rating_col: str = \"rating\"\n",
    "    timestamp_col: str = \"timestamp\"\n",
    "\n",
    "    top_K: int = 100\n",
    "    top_k: int = 10\n",
    "\n",
    "    embedding_dim: int = 128\n",
    "    item_sequence_ts_bucket_size: int = 10\n",
    "    bucket_embedding_dim: int = 16\n",
    "    dropout: float = 0.3\n",
    "    early_stopping_patience: int = 5\n",
    "    learning_rate: float = 0.001\n",
    "    l2_reg: float = 1e-5\n",
    "\n",
    "    mlf_item2vec_model_name: str = \"item2vec\"\n",
    "    mlf_model_name: str = \"ranker\"\n",
    "    min_roc_auc: float = 0.7\n",
    "\n",
    "    best_checkpoint_path: str = None\n",
    "\n",
    "    def init(self):\n",
    "        self.notebook_persist_dp = os.path.abspath(f\"data/{self.run_name}\")\n",
    "        os.makedirs(self.notebook_persist_dp, exist_ok=True)\n",
    "\n",
    "        if not (qdrant_host := os.getenv(\"QDRANT_HOST\")):\n",
    "            raise Exception(f\"Environment variable QDRANT_HOST is not set.\")\n",
    "\n",
    "        qdrant_port = os.getenv(\"QDRANT_PORT\")\n",
    "        self.qdrant_url = f\"{qdrant_host}:{qdrant_port}\"\n",
    "\n",
    "        if not (mlflow_uri := os.environ.get(\"MLFLOW_TRACKING_URI\")):\n",
    "            logger.warning(\n",
    "                f\"Environment variable MLFLOW_TRACKING_URI is not set. Setting self.log_to_mlflow to false.\"\n",
    "            )\n",
    "            self.log_to_mlflow = False\n",
    "\n",
    "        if self.log_to_mlflow:\n",
    "            logger.info(\n",
    "                f\"Setting up MLflow experiment {self.experiment_name} - run {self.run_name}...\"\n",
    "            )\n",
    "            self._mlf_logger = MLFlowLogger(\n",
    "                experiment_name=self.experiment_name,\n",
    "                run_name=self.run_name,\n",
    "                tracking_uri=mlflow_uri,\n",
    "                log_model=True,\n",
    "            )\n",
    "\n",
    "        if self.device is None:\n",
    "            self.device = (\n",
    "                \"cuda\"\n",
    "                if torch.cuda.is_available()\n",
    "                else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "            )\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "args = Args().init()\n",
    "\n",
    "print(args.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acedcb-89e6-41c6-8969-bf3437fc7898",
   "metadata": {},
   "source": [
    "# Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a34cb5b-c7db-4b95-952b-5f4cb2e1a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(\n",
    "    n_users,\n",
    "    n_items,\n",
    "    embedding_dim,\n",
    "    item_sequence_ts_bucket_size,\n",
    "    bucket_embedding_dim,\n",
    "    item_feature_size,\n",
    "    dropout,\n",
    "    item_embedding=None,\n",
    "):\n",
    "    model = Ranker(\n",
    "        n_users,\n",
    "        n_items,\n",
    "        embedding_dim,\n",
    "        item_sequence_ts_bucket_size=item_sequence_ts_bucket_size,\n",
    "        bucket_embedding_dim=bucket_embedding_dim,\n",
    "        item_feature_size=item_feature_size,\n",
    "        dropout=dropout,\n",
    "        item_embedding=item_embedding,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49b92fb-3b4c-482f-a584-62288873d8c3",
   "metadata": {},
   "source": [
    "## Load pretrained Item2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cfc84a-75bb-4973-b619-194cc8698ee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlf_client = mlflow.MlflowClient()\n",
    "model = mlflow.pyfunc.load_model(\n",
    "    model_uri=f\"models:/{args.mlf_item2vec_model_name}@champion\"\n",
    ")\n",
    "skipgram_model = model.unwrap_python_model().model\n",
    "embedding_0 = skipgram_model.embeddings(torch.tensor(0))\n",
    "embedding_dim = embedding_0.size()[0]\n",
    "id_mapping = model.unwrap_python_model().id_mapping\n",
    "pretrained_item_embedding = skipgram_model.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3baa82d-859d-4414-8e19-4c7d92750fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    pretrained_item_embedding.embedding_dim == args.embedding_dim\n",
    "), \"Mismatch pretrained item_embedding dimension\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43bc0b9-9d56-4cb2-b821-61dd9b9858b1",
   "metadata": {},
   "source": [
    "## Load vectorized item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff750e3-fa06-42b4-a5c3-9b93d3c2b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.item_metadata_pipeline_fp, \"rb\") as f:\n",
    "    item_metadata_pipeline = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58607871-619d-46a0-9f7d-405e8f500462",
   "metadata": {},
   "source": [
    "## Load ANN Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3a82c4-247e-4402-a87b-198c698be866",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.rc.use_sbert_features:\n",
    "    ann_index = AnnIndex(args.qdrant_url, args.qdrant_collection_name)\n",
    "    vector = ann_index.get_vector_by_ids([0])[0]\n",
    "    sbert_embedding_dim = vector.shape[0]\n",
    "    logger.info(f\"{sbert_embedding_dim=}\")\n",
    "    neighbors = ann_index.get_neighbors_by_ids([0])\n",
    "    display(neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170dec89-a874-4dce-8f94-07d978fcc5b8",
   "metadata": {},
   "source": [
    "# Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83803362-5eaa-40bb-b28b-878316d5db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"../data/train_features_neg_df.parquet\")\n",
    "val_df = pd.read_parquet(\"../data/val_features_neg_df.parquet\")\n",
    "idm_fp = \"../data/idm.json\"\n",
    "idm = IDMapper().load(idm_fp)\n",
    "\n",
    "assert (\n",
    "    train_df[args.user_col].map(lambda s: idm.get_user_index(s))\n",
    "    != train_df[\"user_indice\"]\n",
    ").sum() == 0, \"Mismatch IDM\"\n",
    "assert (\n",
    "    val_df[args.user_col].map(lambda s: idm.get_user_index(s)) != val_df[\"user_indice\"]\n",
    ").sum() == 0, \"Mismatch IDM\"\n",
    "\n",
    "if args.rc.use_item_tags_from_llm:\n",
    "    assert (\n",
    "        \"tags\" in train_df.columns\n",
    "    ), \"There is no column `tags` in train_df, please make sure you have run notebook 002, 020 with RunCfg.use_item_tags_from_llm=True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a8ea7-928c-4656-b92c-2e137d78404a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd469969-aaa6-4763-a0fc-d432961cf4dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_indices = train_df[\"user_indice\"].unique()\n",
    "item_indices = train_df[\"item_indice\"].unique()\n",
    "if args.rc.use_sbert_features:\n",
    "    all_sbert_vectors = ann_index.get_vector_by_ids(\n",
    "        item_indices.tolist(), chunk_size=1000\n",
    "    ).astype(np.float32)\n",
    "\n",
    "train_item_features = chunk_transform(\n",
    "    train_df, item_metadata_pipeline, chunk_size=args.tfm_chunk_size\n",
    ")\n",
    "train_item_features = train_item_features.astype(np.float32)\n",
    "\n",
    "val_item_features = chunk_transform(\n",
    "    val_df, item_metadata_pipeline, chunk_size=args.tfm_chunk_size\n",
    ")\n",
    "val_item_features = val_item_features.astype(np.float32)\n",
    "\n",
    "if args.rc.use_sbert_features:\n",
    "    train_sbert_vectors = all_sbert_vectors[train_df[\"item_indice\"].values]\n",
    "    train_item_features = np.hstack([train_item_features, train_sbert_vectors])\n",
    "    val_sbert_vectors = all_sbert_vectors[val_df[\"item_indice\"].values]\n",
    "    val_item_features = np.hstack([val_item_features, val_sbert_vectors])\n",
    "\n",
    "logger.info(f\"{len(user_indices)=:,.0f}, {len(item_indices)=:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5260fbe7-2f90-44a1-be74-ce5db9b511ee",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240a04ed-8898-443f-b0f4-7399bfa63810",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset = UserItemBinaryDFDataset(\n",
    "    train_df,\n",
    "    \"user_indice\",\n",
    "    \"item_indice\",\n",
    "    args.rating_col,\n",
    "    args.timestamp_col,\n",
    "    item_feature=train_item_features,\n",
    ")\n",
    "val_rating_dataset = UserItemBinaryDFDataset(\n",
    "    val_df,\n",
    "    \"user_indice\",\n",
    "    \"item_indice\",\n",
    "    args.rating_col,\n",
    "    args.timestamp_col,\n",
    "    item_feature=val_item_features,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    rating_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_rating_dataset, batch_size=args.batch_size, shuffle=False, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dcf157-425f-4d15-9b53-e1ff93887def",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_items = len(item_indices)\n",
    "n_users = len(user_indices)\n",
    "item_feature_size = train_item_features.shape[1]\n",
    "\n",
    "model = init_model(\n",
    "    n_users,\n",
    "    n_items,\n",
    "    args.embedding_dim,\n",
    "    args.item_sequence_ts_bucket_size,\n",
    "    args.bucket_embedding_dim,\n",
    "    item_feature_size,\n",
    "    args.dropout,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cbb2a8-a578-4ad2-941e-efd01d930336",
   "metadata": {},
   "source": [
    "#### Predict before train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0112de1e-1dce-4982-9663-a1df91fd0001",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_df = val_rating_dataset.df\n",
    "val_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb1583b-40f7-4157-a383-5891389ac119",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_id = val_df.sample(1)[args.user_col].values[0]\n",
    "test_df = val_df.loc[lambda df: df[args.user_col].eq(user_id)]\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48fbc80-eda8-4dff-a246-95f8f2f75082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_row = test_df.loc[lambda df: df[args.rating_col].gt(0)].iloc[0]\n",
    "item_id = test_row[args.item_col]\n",
    "item_sequence = test_row[\"item_sequence\"]\n",
    "item_sequence_ts_bucket = test_row[\"item_sequence_ts_bucket\"]\n",
    "row_idx = test_row.name\n",
    "item_feature = val_item_features[row_idx]\n",
    "logger.info(\n",
    "    f\"Test predicting before training with {args.user_col} = {user_id} and {args.item_col} = {item_id}\"\n",
    ")\n",
    "user_indice = idm.get_user_index(user_id)\n",
    "item_indice = idm.get_item_index(item_id)\n",
    "user = torch.tensor([user_indice])\n",
    "item_sequence = torch.tensor([item_sequence])\n",
    "item_sequence_ts_bucket = torch.tensor([item_sequence_ts_bucket])\n",
    "item_feature = torch.tensor([item_feature])\n",
    "item = torch.tensor([item_indice])\n",
    "\n",
    "model.eval()\n",
    "model.predict(user, item_sequence, item_sequence_ts_bucket, item_feature, item)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fd217c-c0c8-4e7c-81fe-6eb36f4729b5",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9daad4-1365-4e8e-8f73-80ca5513572b",
   "metadata": {},
   "source": [
    "##### Overfit 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1cd9bd-e2c6-404b-b6ae-b26a7d35a0ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=10, mode=\"min\", verbose=False\n",
    ")\n",
    "\n",
    "model = init_model(\n",
    "    n_users,\n",
    "    n_items,\n",
    "    args.embedding_dim,\n",
    "    args.item_sequence_ts_bucket_size,\n",
    "    args.bucket_embedding_dim,\n",
    "    item_feature_size,\n",
    "    dropout=0,\n",
    ")\n",
    "lit_model = LitRanker(\n",
    "    model,\n",
    "    learning_rate=args.learning_rate,\n",
    "    l2_reg=0.0,\n",
    "    log_dir=args.notebook_persist_dp,\n",
    "    accelerator=args.device,\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persist_dp}/logs/overfit\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    max_epochs=100,\n",
    "    overfit_batches=1,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=train_loader,\n",
    ")\n",
    "logger.info(f\"Logs available at {trainer.log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cc9ae0-a993-4815-bebd-85cc51e68e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to make sure port 6006 at local is accessible\n",
    "%tensorboard --logdir $trainer.log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c7e4af-5c66-454e-9e2c-2ca134f4e1cf",
   "metadata": {},
   "source": [
    "##### Fit on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d821e0-3255-4947-b720-81a2f83a4911",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_items_df = train_df.drop_duplicates(subset=[\"item_indice\"])\n",
    "all_items_indices = all_items_df[\"item_indice\"].values\n",
    "all_items_features = item_metadata_pipeline.transform(all_items_df).astype(np.float32)\n",
    "logger.info(\n",
    "    f\"Mean std over categorical and numerical features: {all_items_features.std(axis=0).mean()}\"\n",
    ")\n",
    "if args.rc.use_sbert_features:\n",
    "    all_sbert_vectors = ann_index.get_vector_by_ids(all_items_indices.tolist()).astype(\n",
    "        np.float32\n",
    "    )\n",
    "    logger.info(f\"Mean std over text features: {all_sbert_vectors.std(axis=0).mean()}\")\n",
    "    all_items_features = np.hstack([all_items_features, all_sbert_vectors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3e950d-008b-4564-845e-a68d3c96ef5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# papermill_description=fit-model\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_roc_auc\", patience=args.early_stopping_patience, mode=\"max\", verbose=False\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{args.notebook_persist_dp}/checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_roc_auc\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "model = init_model(\n",
    "    n_users,\n",
    "    n_items,\n",
    "    args.embedding_dim,\n",
    "    args.item_sequence_ts_bucket_size,\n",
    "    args.bucket_embedding_dim,\n",
    "    item_feature_size,\n",
    "    dropout=args.dropout,\n",
    "    item_embedding=pretrained_item_embedding,\n",
    ")\n",
    "lit_model = LitRanker(\n",
    "    model,\n",
    "    learning_rate=args.learning_rate,\n",
    "    l2_reg=args.l2_reg,\n",
    "    log_dir=args.notebook_persist_dp,\n",
    "    evaluate_ranking=True,\n",
    "    idm=idm,\n",
    "    all_items_indices=all_items_indices,\n",
    "    all_items_features=all_items_features,\n",
    "    args=args,\n",
    "    neg_to_pos_ratio=args.neg_to_pos_ratio,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    accelerator=args.device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9142d9-2c1c-47e0-890b-2104f6726ff0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_dir = f\"{args.notebook_persist_dp}/logs/run\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    max_epochs=args.max_epochs,\n",
    "    callbacks=[early_stopping, checkpoint_callback],\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    logger=args._mlf_logger if args.log_to_mlflow else None,\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af44bf35-e7c7-4718-97b8-238e89b7f3f0",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.info(\n",
    "    f\"Test predicting after training with {args.user_col} = {user_id} and {args.item_col} = {item_id}\"\n",
    ")\n",
    "model.eval()\n",
    "model = model.to(user.device)  # Move model back to align with data device\n",
    "model.predict(user, item_sequence, item_sequence_ts_bucket, item_feature, item)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e1dd22-bcb9-4582-96d0-30acc4e8b790",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Load best checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092427a8-ac4e-4752-a0ee-10729b6e563c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.info(f\"Loading best checkpoint from {checkpoint_callback.best_model_path}...\")\n",
    "args.best_checkpoint_path = checkpoint_callback.best_model_path\n",
    "\n",
    "best_trainer = LitRanker.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    model=init_model(\n",
    "        n_users,\n",
    "        n_items,\n",
    "        args.embedding_dim,\n",
    "        args.item_sequence_ts_bucket_size,\n",
    "        args.bucket_embedding_dim,\n",
    "        item_feature_size,\n",
    "        dropout=0,\n",
    "        item_embedding=pretrained_item_embedding,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68989e7-cd28-4cb3-9a28-5bd477bb67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = best_trainer.model.to(lit_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72062d94-6ee8-480f-b7c6-9dcae2ceeb8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "best_model.predict(user, item_sequence, item_sequence_ts_bucket, item_feature, item)\n",
    "best_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26afc39d-5cbd-4ea4-9484-f6419b460bde",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Persist artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275bcb81-bf50-4757-9e63-5c7a317b276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.log_to_mlflow:\n",
    "    # Persist id_mapping so that at inference we can predict based on item_ids (string) instead of item_index\n",
    "    run_id = trainer.logger.run_id\n",
    "    mlf_client = trainer.logger.experiment\n",
    "    mlf_client.log_artifact(run_id, idm_fp)\n",
    "    # Persist item_feature_metadata pipeline\n",
    "    mlf_client.log_artifact(run_id, args.item_metadata_pipeline_fp)\n",
    "\n",
    "    # Persist model architecture\n",
    "    model_architecture_fp = f\"{args.notebook_persist_dp}/model_architecture.txt\"\n",
    "    with open(model_architecture_fp, \"w\") as f:\n",
    "        f.write(repr(model))\n",
    "    mlf_client.log_artifact(run_id, model_architecture_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a53735-cada-4b16-b6ec-b958e20d8093",
   "metadata": {},
   "source": [
    "### Wrap inference function and register best checkpoint as MLflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1da4ca-1616-4f57-99fb-cb851c535a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferrer = RankerInferenceWrapper(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91c26a5-d86e-4d3a-b3a2-87e6a5e88427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_item_features():\n",
    "    sample_row = train_df.iloc[0].fillna(0)\n",
    "    output = dict()\n",
    "    for col in args.rc.item_feature_cols:\n",
    "        v = sample_row[col]\n",
    "        if isinstance(v, np.ndarray):\n",
    "            v = \"__\".join(\n",
    "                sample_row[col].tolist()\n",
    "            )  # Workaround to avoid MLflow Got error: Per-column arrays must each be 1-dimensional\n",
    "        output[col] = [v]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21791a9-d5fc-4abe-bc3c-820aba9f0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = {\n",
    "    args.user_col: [idm.get_user_id(0)],\n",
    "    \"item_sequence\": [\",\".join([idm.get_item_id(0), idm.get_item_id(1)])],\n",
    "    \"item_sequence_ts\": [\n",
    "        \"1095133116,109770848\"\n",
    "    ],  # Here we input unix timestamp seconds instead of timestamp bucket because we need to calculate the bucket\n",
    "    # **{col: [train_df.iloc[0].fillna(0)[col]] for col in args.item_feature_cols},\n",
    "    **generate_sample_item_features(),\n",
    "    args.item_col: [idm.get_item_id(0)],\n",
    "}\n",
    "sample_output = inferrer.infer([0], [[0, 1]], [[2, 0]], [train_item_features[0]], [0])\n",
    "sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b5cf4-5e51-4641-bdfe-6ce289344bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c043a-f777-4ade-ab80-cfa4d90aafa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args.log_to_mlflow:\n",
    "    run_id = trainer.logger.run_id\n",
    "    sample_output_np = sample_output\n",
    "    signature = infer_signature(sample_input, sample_output_np)\n",
    "    idm_filename = idm_fp.split(\"/\")[-1]\n",
    "    item_metadata_pipeline_filename = args.item_metadata_pipeline_fp.split(\"/\")[-1]\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        mlflow.pyfunc.log_model(\n",
    "            python_model=inferrer,\n",
    "            artifact_path=\"inferrer\",\n",
    "            artifacts={\n",
    "                # We log the id_mapping to the predict function so that it can accept item_id and automatically convert ot item_indice for PyTorch model to use\n",
    "                \"idm\": mlflow.get_artifact_uri(idm_filename),\n",
    "                \"item_metadata_pipeline\": mlflow.get_artifact_uri(\n",
    "                    item_metadata_pipeline_filename\n",
    "                ),\n",
    "            },\n",
    "            model_config={\"use_sbert_features\": args.rc.use_sbert_features},\n",
    "            signature=signature,\n",
    "            input_example=sample_input,\n",
    "            registered_model_name=args.mlf_model_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d5150-9851-4e61-b1af-8e619abc9ea4",
   "metadata": {},
   "source": [
    "# Set the newly trained model as champion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72c27d5-6f7c-401b-9322-7d428ab51240",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.log_to_mlflow:\n",
    "    # Get current champion\n",
    "    deploy_alias = \"champion\"\n",
    "    curr_model_run_id = None\n",
    "\n",
    "    min_roc_auc = args.min_roc_auc\n",
    "\n",
    "    try:\n",
    "        curr_champion_model = mlf_client.get_model_version_by_alias(\n",
    "            args.mlf_model_name, deploy_alias\n",
    "        )\n",
    "        curr_model_run_id = curr_champion_model.run_id\n",
    "    except MlflowException as e:\n",
    "        if \"not found\" in str(e).lower():\n",
    "            logger.info(\n",
    "                f\"There is no {deploy_alias} alias for model {args.mlf_model_name}\"\n",
    "            )\n",
    "\n",
    "    # Compare new vs curr models\n",
    "    new_mlf_run = trainer.logger.experiment.get_run(trainer.logger.run_id)\n",
    "    new_metrics = new_mlf_run.data.metrics\n",
    "    roc_auc = new_metrics[\"roc_auc\"]\n",
    "    if curr_model_run_id:\n",
    "        curr_model_run_info = mlf_client.get_run(curr_model_run_id)\n",
    "        curr_metrics = curr_model_run_info.data.metrics\n",
    "        if (curr_roc_auc := curr_metrics[\"roc_auc\"]) > min_roc_auc:\n",
    "            logger.info(\n",
    "                f\"Current {deploy_alias} model has {curr_roc_auc:,.4f} ROC-AUC...\"\n",
    "            )\n",
    "            min_roc_auc = curr_roc_auc\n",
    "\n",
    "        top_metrics = [\"roc_auc\", \"val_PersonalizationMetric\"]\n",
    "        vizer = ModelMetricsComparisonVisualizer(curr_metrics, new_metrics, top_metrics)\n",
    "        print(f\"Comparing metrics between new run and current champion:\")\n",
    "        display(vizer.compare_metrics_df())\n",
    "        vizer.create_metrics_comparison_plot(n_cols=5)\n",
    "        vizer.plot_diff()\n",
    "\n",
    "    # Register new champion\n",
    "    if roc_auc < min_roc_auc:\n",
    "        logger.info(\n",
    "            f\"Current run has ROC-AUC = {roc_auc:,.4f}, smaller than {min_roc_auc:,.4f}. Skip aliasing this model as the new {deploy_alias}..\"\n",
    "        )\n",
    "    else:\n",
    "        logger.info(f\"Aliasing the new model as champion...\")\n",
    "        # Get the model version for current run by assuming it's the most recent registered version\n",
    "        model_version = (\n",
    "            mlf_client.get_registered_model(args.mlf_model_name)\n",
    "            .latest_versions[0]\n",
    "            .version\n",
    "        )\n",
    "\n",
    "        mlf_client.set_registered_model_alias(\n",
    "            name=args.mlf_model_name, alias=\"champion\", version=model_version\n",
    "        )\n",
    "\n",
    "        mlf_client.set_model_version_tag(\n",
    "            name=args.mlf_model_name,\n",
    "            version=model_version,\n",
    "            key=\"author\",\n",
    "            value=args.author,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd09b91a-023e-4db4-8f10-e0444b118c85",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719214cc-6c54-44ad-997e-ad3e18fbba95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_params = [args]\n",
    "\n",
    "if args.log_to_mlflow:\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        for params in all_params:\n",
    "            params_dict = params.dict()\n",
    "            params_ = dict()\n",
    "            for k, v in params_dict.items():\n",
    "                if k == \"top_K\":\n",
    "                    k = \"top_big_K\"\n",
    "                if k == \"top_k\":\n",
    "                    k = \"top_small_k\"\n",
    "                params_[f\"{params.__repr_name__()}.{k}\"] = v\n",
    "            mlflow.log_params(params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cff81a-484e-4919-be8f-0351cce91a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hm-scalablerecs-QHnDFvap-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
