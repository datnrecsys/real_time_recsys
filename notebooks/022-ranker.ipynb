{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bf1577c-6f3b-4b1c-a848-8f5e45ff8111",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Ranker that can takes into accound different features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9309e017-0449-46ee-b7ca-4c4bcadeedf6",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c8f6e8d-f776-4d39-898c-d783c5ae3407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35b3499d-dc9c-405a-8714-a26341b581e1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinhln/Desktop/real_time_recsys/.venv/lib/python3.11/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import dill\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from loguru import logger\n",
    "from mlflow.exceptions import MlflowException\n",
    "from mlflow.models.signature import infer_signature\n",
    "from pydantic import BaseModel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import mlflow\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from cfg.run_cfg import RunCfg\n",
    "# from src.ann import AnnIndex\n",
    "from src.utils.data_prep import chunk_transform\n",
    "from src.algo.ranker.dataset import UserItemBinaryDFDataset\n",
    "from src.utils.embedding_id_mapper import IDMapper\n",
    "from src.algo.ranker.inference import RankerInferenceWrapper\n",
    "from src.algo.ranker.model import Ranker\n",
    "from src.algo.ranker.trainer import LitRanker\n",
    "from src.algo.item2vec.trainer import LitSkipGram\n",
    "from src.algo.item2vec.model import SkipGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe46f91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd804021-3424-48e0-973a-e662a72db544",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce522d9e-f35c-4cc5-a71e-68447956b31f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# This is a parameter cell used by papermill\n",
    "max_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea4e9a93-5b6a-4dec-97f0-b9aa3383c64d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-01 00:15:40.248\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcfg.run_cfg\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m31\u001b[0m - \u001b[34m\u001b[1mSetting use_sbert_features=True requires running notebook 016-sentence-transformers\u001b[0m\n",
      "\u001b[32m2025-07-01 00:15:40.249\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcfg.run_cfg\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m38\u001b[0m - \u001b[34m\u001b[1mChanging use_item_tags_from_llm requires re-running notebook 002-features-v2 to get the new item_metadata_pipeline.dill file\u001b[0m\n",
      "\u001b[32m2025-07-01 00:15:40.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSetting up MLflow experiment RecSys MVP - Ranker - run 004-use-sbert-features-and-llm-tags...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"testing\": false,\n",
      "  \"author\": \"dinh-trieu\",\n",
      "  \"log_to_mlflow\": true,\n",
      "  \"experiment_name\": \"RecSys MVP - Ranker\",\n",
      "  \"run_name\": \"004-use-sbert-features-and-llm-tags\",\n",
      "  \"notebook_persist_dp\": \"/home/dinhln/Desktop/real_time_recsys/notebooks/data/004-use-sbert-features-and-llm-tags\",\n",
      "  \"random_seed\": 41,\n",
      "  \"device\": \"cuda\",\n",
      "  \"rc\": {\n",
      "    \"use_sbert_features\": true,\n",
      "    \"use_item_tags_from_llm\": false,\n",
      "    \"item_feature_cols\": [\n",
      "      \"main_category\",\n",
      "      \"categories\",\n",
      "      \"price\",\n",
      "      \"parent_asin_rating_cnt_365d\",\n",
      "      \"parent_asin_rating_avg_prev_rating_365d\",\n",
      "      \"parent_asin_rating_cnt_90d\",\n",
      "      \"parent_asin_rating_avg_prev_rating_90d\",\n",
      "      \"parent_asin_rating_cnt_30d\",\n",
      "      \"parent_asin_rating_avg_prev_rating_30d\",\n",
      "      \"parent_asin_rating_cnt_7d\",\n",
      "      \"parent_asin_rating_avg_prev_rating_7d\"\n",
      "    ]\n",
      "  },\n",
      "  \"item_metadata_pipeline_fp\": \"../data_for_ai/interim/item_metadata_pipeline_wo_user_item_manipulate.dill\",\n",
      "  \"qdrant_url\": \"138.2.61.6:6333\",\n",
      "  \"qdrant_collection_name\": \"item_desc_sbert\",\n",
      "  \"max_epochs\": 10,\n",
      "  \"batch_size\": 128,\n",
      "  \"tfm_chunk_size\": 10000,\n",
      "  \"neg_to_pos_ratio\": 1,\n",
      "  \"user_col\": \"user_id\",\n",
      "  \"item_col\": \"parent_asin\",\n",
      "  \"rating_col\": \"rating\",\n",
      "  \"timestamp_col\": \"timestamp\",\n",
      "  \"top_K\": 100,\n",
      "  \"top_k\": 10,\n",
      "  \"embedding_dim\": 256,\n",
      "  \"item_sequence_ts_bucket_size\": 10,\n",
      "  \"bucket_embedding_dim\": 16,\n",
      "  \"dropout\": 0.3,\n",
      "  \"early_stopping_patience\": 5,\n",
      "  \"learning_rate\": 0.001,\n",
      "  \"l2_reg\": 0.00001,\n",
      "  \"mlf_item2vec_model_name\": \"item2vec\",\n",
      "  \"mlf_model_name\": \"ranker\",\n",
      "  \"min_roc_auc\": 0.7,\n",
      "  \"best_checkpoint_path\": null,\n",
      "  \"use_item_feature\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Args(BaseModel):\n",
    "    testing: bool = False\n",
    "    author: str = \"dinh-trieu\"\n",
    "    log_to_mlflow: bool = True\n",
    "    experiment_name: str = \"RecSys MVP - Ranker\"\n",
    "    run_name: str = \"004-use-sbert-features-and-llm-tags\"\n",
    "    notebook_persist_dp: str = None\n",
    "    random_seed: int = 41\n",
    "    device: str = None\n",
    "\n",
    "    rc: RunCfg = RunCfg().init()\n",
    "\n",
    "    item_metadata_pipeline_fp: str = \"../data_for_ai/interim/item_metadata_pipeline_wo_user_item_manipulate.dill\"\n",
    "    qdrant_url: str = None\n",
    "    qdrant_collection_name: str = \"item_desc_sbert\"\n",
    "\n",
    "    max_epochs: int = max_epochs\n",
    "    batch_size: int = 128\n",
    "    tfm_chunk_size: int = 10000\n",
    "    neg_to_pos_ratio: int = 1\n",
    "\n",
    "    user_col: str = \"user_id\"\n",
    "    item_col: str = \"parent_asin\"\n",
    "    rating_col: str = \"rating\"\n",
    "    timestamp_col: str = \"timestamp\"\n",
    "\n",
    "    top_K: int = 100\n",
    "    top_k: int = 10\n",
    "\n",
    "    embedding_dim: int = 256\n",
    "    item_sequence_ts_bucket_size: int = 10\n",
    "    bucket_embedding_dim: int = 16\n",
    "    dropout: float = 0.3\n",
    "    early_stopping_patience: int = 5\n",
    "    learning_rate: float = 0.001\n",
    "    l2_reg: float = 1e-5\n",
    "\n",
    "    mlf_item2vec_model_name: str = \"item2vec\"\n",
    "    mlf_model_name: str = \"ranker\"\n",
    "    min_roc_auc: float = 0.7\n",
    "\n",
    "    best_checkpoint_path: str = None\n",
    "    use_item_feature: bool = True\n",
    "\n",
    "    def init(self):\n",
    "        self.notebook_persist_dp = os.path.abspath(f\"data/{self.run_name}\")\n",
    "        os.makedirs(self.notebook_persist_dp, exist_ok=True)\n",
    "\n",
    "        if not (qdrant_host := os.getenv(\"QDRANT_HOST\")):\n",
    "            raise Exception(f\"Environment variable QDRANT_HOST is not set.\")\n",
    "\n",
    "        qdrant_port = os.getenv(\"QDRANT_PORT\")\n",
    "        self.qdrant_url = f\"{qdrant_host}:{qdrant_port}\"\n",
    "\n",
    "        if not (mlflow_uri := os.environ.get(\"MLFLOW_TRACKING_URI\")):\n",
    "            logger.warning(\n",
    "                f\"Environment variable MLFLOW_TRACKING_URI is not set. Setting self.log_to_mlflow to false.\"\n",
    "            )\n",
    "            self.log_to_mlflow = False\n",
    "\n",
    "        if self.log_to_mlflow:\n",
    "            logger.info(\n",
    "                f\"Setting up MLflow experiment {self.experiment_name} - run {self.run_name}...\"\n",
    "            )\n",
    "            self._mlf_logger = MLFlowLogger(\n",
    "                experiment_name=self.experiment_name,\n",
    "                run_name=self.run_name,\n",
    "                tracking_uri=mlflow_uri,\n",
    "                log_model=True,\n",
    "            )\n",
    "\n",
    "        if self.device is None:\n",
    "            self.device = (\n",
    "                \"cuda\"\n",
    "                if torch.cuda.is_available()\n",
    "                else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "            )\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "args = Args().init()\n",
    "\n",
    "print(args.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acedcb-89e6-41c6-8969-bf3437fc7898",
   "metadata": {},
   "source": [
    "# Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a34cb5b-c7db-4b95-952b-5f4cb2e1a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(\n",
    "    n_users,\n",
    "    n_items,\n",
    "    embedding_dim,\n",
    "    item_sequence_ts_bucket_size,\n",
    "    bucket_embedding_dim,\n",
    "    item_feature_size,\n",
    "    dropout,\n",
    "    item_embedding=None,\n",
    "    use_item_feature=False,\n",
    "):\n",
    "    model = Ranker(\n",
    "        n_users,\n",
    "        n_items,\n",
    "        embedding_dim,\n",
    "        item_sequence_ts_bucket_size=item_sequence_ts_bucket_size,\n",
    "        bucket_embedding_dim=bucket_embedding_dim,\n",
    "        use_item_feature=use_item_feature,\n",
    "        item_feature_size=item_feature_size,\n",
    "        dropout=dropout,\n",
    "        item_embedding=item_embedding,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49b92fb-3b4c-482f-a584-62288873d8c3",
   "metadata": {},
   "source": [
    "## Load pretrained Item2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc40cc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-01 00:15:40.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.item2vec.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mInitializing item embeddings with num items 4817, embedding dim 256\u001b[0m\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/dinhln/Desktop/real_time_recsys/notebooks/../data_for_ai/interim/best-item2vec-weight.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m n_items = \u001b[32m4817\u001b[39m  \u001b[38;5;66;03m# This should be the number of unique items in your dataset\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m args.embedding_dim == \u001b[32m256\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mEmbedding dimension must be 256\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m best_trainer = \u001b[43mLitSkipGram\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data_for_ai/interim/best-item2vec-weight.ckpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskipgram_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSkipGram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m skipgram_item_embedding = best_trainer.skipgram_model.embeddings.weight.data.cpu()\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSkipGram Item embedding shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mskipgram_item_embedding.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_time_recsys/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/model_helpers.py:125\u001b[39m, in \u001b[36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    122\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.method.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` cannot be called on an instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    123\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    124\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_time_recsys/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py:1611\u001b[39m, in \u001b[36mLightningModule.load_from_checkpoint\u001b[39m\u001b[34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[39m\n\u001b[32m   1522\u001b[39m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[32m   1523\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_from_checkpoint\u001b[39m(\n\u001b[32m   1524\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1529\u001b[39m     **kwargs: Any,\n\u001b[32m   1530\u001b[39m ) -> Self:\n\u001b[32m   1531\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[32m   1532\u001b[39m \u001b[33;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[32m   1533\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1609\u001b[39m \n\u001b[32m   1610\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1611\u001b[39m     loaded = \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1612\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1613\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1614\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1615\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1616\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1617\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1618\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1619\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_time_recsys/.venv/lib/python3.11/site-packages/lightning/pytorch/core/saving.py:63\u001b[39m, in \u001b[36m_load_from_checkpoint\u001b[39m\u001b[34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[39m\n\u001b[32m     61\u001b[39m map_location = map_location \u001b[38;5;129;01mor\u001b[39;00m _default_map_location\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pl_legacy_patch():\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     checkpoint = \u001b[43mpl_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# convert legacy checkpoints to the new format\u001b[39;00m\n\u001b[32m     66\u001b[39m checkpoint = _pl_migrate_checkpoint(\n\u001b[32m     67\u001b[39m     checkpoint, checkpoint_path=(checkpoint_path \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(checkpoint_path, (\u001b[38;5;28mstr\u001b[39m, Path)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     68\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_time_recsys/.venv/lib/python3.11/site-packages/lightning/fabric/utilities/cloud_io.py:60\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(path_or_url, map_location, weights_only)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.hub.load_state_dict_from_url(\n\u001b[32m     55\u001b[39m         \u001b[38;5;28mstr\u001b[39m(path_or_url),\n\u001b[32m     56\u001b[39m         map_location=map_location,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m     57\u001b[39m         weights_only=weights_only,\n\u001b[32m     58\u001b[39m     )\n\u001b[32m     59\u001b[39m fs = get_filesystem(path_or_url)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.load(\n\u001b[32m     62\u001b[39m         f,\n\u001b[32m     63\u001b[39m         map_location=map_location,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m     64\u001b[39m         weights_only=weights_only,\n\u001b[32m     65\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_time_recsys/.venv/lib/python3.11/site-packages/fsspec/spec.py:1303\u001b[39m, in \u001b[36mAbstractFileSystem.open\u001b[39m\u001b[34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[39m\n\u001b[32m   1301\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1302\u001b[39m     ac = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mautocommit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._intrans)\n\u001b[32m-> \u001b[39m\u001b[32m1303\u001b[39m     f = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1304\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1306\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1307\u001b[39m \u001b[43m        \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1308\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1309\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1310\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1312\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfsspec\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_time_recsys/.venv/lib/python3.11/site-packages/fsspec/implementations/local.py:191\u001b[39m, in \u001b[36mLocalFileSystem._open\u001b[39m\u001b[34m(self, path, mode, block_size, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mself\u001b[39m.makedirs(\u001b[38;5;28mself\u001b[39m._parent(path), exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLocalFileOpener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_time_recsys/.venv/lib/python3.11/site-packages/fsspec/implementations/local.py:355\u001b[39m, in \u001b[36mLocalFileOpener.__init__\u001b[39m\u001b[34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28mself\u001b[39m.compression = get_compression(path, compression)\n\u001b[32m    354\u001b[39m \u001b[38;5;28mself\u001b[39m.blocksize = io.DEFAULT_BUFFER_SIZE\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/real_time_recsys/.venv/lib/python3.11/site-packages/fsspec/implementations/local.py:360\u001b[39m, in \u001b[36mLocalFileOpener._open\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f.closed:\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.autocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode:\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m         \u001b[38;5;28mself\u001b[39m.f = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    361\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compression:\n\u001b[32m    362\u001b[39m             compress = compr[\u001b[38;5;28mself\u001b[39m.compression]\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/dinhln/Desktop/real_time_recsys/notebooks/../data_for_ai/interim/best-item2vec-weight.ckpt'"
     ]
    }
   ],
   "source": [
    "n_items = 4817  # This should be the number of unique items in your dataset\n",
    "assert args.embedding_dim == 256, \"Embedding dimension must be 256\"\n",
    "best_trainer = LitSkipGram.load_from_checkpoint(\n",
    "    \"../data_for_ai/interim/best-item2vec-weight.ckpt\",\n",
    "    skipgram_model=SkipGram(n_items, args.embedding_dim).to(args.device),\n",
    ")\n",
    "skipgram_item_embedding = best_trainer.skipgram_model.embeddings.weight.data.cpu()\n",
    "print(f\"SkipGram Item embedding shape: {skipgram_item_embedding.shape}\")\n",
    "print(f\"SkipGram Item embedding dtype: {skipgram_item_embedding.dtype}\")\n",
    "\n",
    "# create a embedding layer with num_items + 1 embedding, then apply the pretrained weights\n",
    "pretrained_item_embedding = torch.nn.Embedding(\n",
    "    num_embeddings=n_items + 1,  # +1 for the unknown item (-1 padding)\n",
    "    embedding_dim=args.embedding_dim,\n",
    "    padding_idx=n_items,  # Set padding_idx to the last index\n",
    ")\n",
    "pretrained_item_embedding.weight.data[:n_items] = skipgram_item_embedding[:n_items]\n",
    "pretrained_item_embedding.weight.data[n_items] = torch.zeros(\n",
    "    args.embedding_dim, dtype=skipgram_item_embedding.dtype\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cfc84a-75bb-4973-b619-194cc8698ee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mlf_client = mlflow.MlflowClient()\n",
    "# model = mlflow.pyfunc.load_model(\n",
    "#     model_uri=f\"models:/{args.mlf_item2vec_model_name}@champion\"\n",
    "# )\n",
    "# skipgram_model = model.unwrap_python_model().model\n",
    "# embedding_0 = skipgram_model.embeddings(torch.tensor(0))\n",
    "# embedding_dim = embedding_0.size()[0]\n",
    "# id_mapping = model.unwrap_python_model().id_mapping\n",
    "# pretrained_item_embedding = skipgram_model.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3baa82d-859d-4414-8e19-4c7d92750fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    pretrained_item_embedding.embedding_dim == args.embedding_dim\n",
    "), \"Mismatch pretrained item_embedding dimension\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43bc0b9-9d56-4cb2-b821-61dd9b9858b1",
   "metadata": {},
   "source": [
    "## Load vectorized item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff750e3-fa06-42b4-a5c3-9b93d3c2b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.item_metadata_pipeline_fp, \"rb\") as f:\n",
    "    item_metadata_pipeline = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58607871-619d-46a0-9f7d-405e8f500462",
   "metadata": {},
   "source": [
    "## Load ANN Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3a82c4-247e-4402-a87b-198c698be866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if args.rc.use_sbert_features:\n",
    "#     ann_index = AnnIndex(args.qdrant_url, args.qdrant_collection_name)\n",
    "#     vector = ann_index.get_vector_by_ids([0])[0]\n",
    "#     sbert_embedding_dim = vector.shape[0]\n",
    "#     logger.info(f\"{sbert_embedding_dim=}\")\n",
    "#     neighbors = ann_index.get_neighbors_by_ids([0])\n",
    "#     display(neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170dec89-a874-4dce-8f94-07d978fcc5b8",
   "metadata": {},
   "source": [
    "# Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83803362-5eaa-40bb-b28b-878316d5db5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4817 items in the dataset\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_parquet(\"../data_for_ai/interim/train_sample_interactions_16407u_features_neg_seq_without_stats_item_user.parquet\")\n",
    "val_df = pd.read_parquet(\"../data_for_ai/interim/val_sample_interactions_16407u_features_neg_seq_without_stats_item_user.parquet\")\n",
    "idm_fp = \"../data_for_ai/interim/idm_16407u.json\"\n",
    "idm = IDMapper().load(idm_fp)\n",
    "\n",
    "assert (\n",
    "    train_df[args.user_col].map(lambda s: idm.get_user_index(s))\n",
    "    != train_df[\"user_indice\"]\n",
    ").sum() == 0, \"Mismatch IDM\"\n",
    "assert (\n",
    "    val_df[args.user_col].map(lambda s: idm.get_user_index(s)) != val_df[\"user_indice\"]\n",
    ").sum() == 0, \"Mismatch IDM\"\n",
    "\n",
    "if args.rc.use_item_tags_from_llm:\n",
    "    assert (\n",
    "        \"tags\" in train_df.columns\n",
    "    ), \"There is no column `tags` in train_df, please make sure you have run notebook 002, 020 with RunCfg.use_item_tags_from_llm=True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b05b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>timestamp_unix</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "      <th>item_sequence_ts</th>\n",
       "      <th>item_sequence_ts_bucket</th>\n",
       "      <th>main_category</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>categories</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AENOXSRSNC5VGY3JQKZQ5DD7HIUA</td>\n",
       "      <td>B00SG3CWGS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-06-10 00:30:32.698</td>\n",
       "      <td>1497054632</td>\n",
       "      <td>2546</td>\n",
       "      <td>4213</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, 218, 2648]</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, 1457886402, 1...</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, 6, 0]</td>\n",
       "      <td>Cell Phones &amp; Accessories</td>\n",
       "      <td>Garmin Nuvi 67LMT 6-Inch GPS Navigator</td>\n",
       "      <td>[With bright 6” dual-orientation displays, spo...</td>\n",
       "      <td>[Electronics, GPS, Finders &amp; Accessories, Spor...</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AEMPVT2U6BIHQDV52BDEDDKPH4HA</td>\n",
       "      <td>B01BCWKBZI</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-08-03 00:40:30.172</td>\n",
       "      <td>1501720830</td>\n",
       "      <td>2416</td>\n",
       "      <td>2467</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "      <td>Computers</td>\n",
       "      <td>Samsung T3 Portable SSD - 2TB - USB 3.1 Extern...</td>\n",
       "      <td>[Portability is the key element shared among a...</td>\n",
       "      <td>[Electronics, Computers &amp; Accessories, Data St...</td>\n",
       "      <td>348.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF3CKYP3BTJ7MEKU6J64BS57MQBA</td>\n",
       "      <td>B09BW3XJQV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-12-08 16:57:03.101</td>\n",
       "      <td>1544288223</td>\n",
       "      <td>4292</td>\n",
       "      <td>1208</td>\n",
       "      <td>[-1, -1, -1, -1, 3541, 3089, 4168, 3936, 4066,...</td>\n",
       "      <td>[-1, -1, -1, -1, 1488569087, 1499723220, 15334...</td>\n",
       "      <td>[-1, -1, -1, -1, 6, 6, 5, 5, 4, 4]</td>\n",
       "      <td>Computers</td>\n",
       "      <td>ASUS AC1300 WiFi Router (RT-ACRH13) - Dual Ban...</td>\n",
       "      <td>[Upgrade to AC Wi-Fi for your bandwidth-hungry...</td>\n",
       "      <td>[Electronics, Computers &amp; Accessories, Network...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AE7IGXXTK7XTWRJGLIAL5BJDTEAQ</td>\n",
       "      <td>B005L38VRU</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-09-04 02:03:39.000</td>\n",
       "      <td>1409796219</td>\n",
       "      <td>728</td>\n",
       "      <td>689</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, 193, 3945, 1849, 4407]</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, 1327177801, 133520743...</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, 6, 6, 6, 5]</td>\n",
       "      <td>All Electronics</td>\n",
       "      <td>Logitech K750 Wireless Solar Keyboard for Mac ...</td>\n",
       "      <td>[Battery hassles are a thing of the past with ...</td>\n",
       "      <td>[Electronics, Computers &amp; Accessories, Compute...</td>\n",
       "      <td>49.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFEJ5GRYG2PQD6EWSAKVG56XMKNA</td>\n",
       "      <td>B001W6Q7SU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-09-14 16:29:39.000</td>\n",
       "      <td>1473870579</td>\n",
       "      <td>5481</td>\n",
       "      <td>834</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, 3965, 4617, 2003]</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, 1473870313, 14738...</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, 0, 0, 0]</td>\n",
       "      <td>All Electronics</td>\n",
       "      <td>PNY Optima 2GB (2x1GB) Dual Channel Kit DDR2 6...</td>\n",
       "      <td>[PNY OPTIMA 2GB (2x1GB) Dual Channel Kit DDR2 ...</td>\n",
       "      <td>[Electronics, Computers &amp; Accessories, Compute...</td>\n",
       "      <td>65.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user_id parent_asin  rating               timestamp  \\\n",
       "0  AENOXSRSNC5VGY3JQKZQ5DD7HIUA  B00SG3CWGS     0.0 2017-06-10 00:30:32.698   \n",
       "1  AEMPVT2U6BIHQDV52BDEDDKPH4HA  B01BCWKBZI     2.0 2017-08-03 00:40:30.172   \n",
       "2  AF3CKYP3BTJ7MEKU6J64BS57MQBA  B09BW3XJQV     0.0 2018-12-08 16:57:03.101   \n",
       "3  AE7IGXXTK7XTWRJGLIAL5BJDTEAQ  B005L38VRU     5.0 2014-09-04 02:03:39.000   \n",
       "4  AFEJ5GRYG2PQD6EWSAKVG56XMKNA  B001W6Q7SU     0.0 2016-09-14 16:29:39.000   \n",
       "\n",
       "   timestamp_unix  user_indice  item_indice  \\\n",
       "0      1497054632         2546         4213   \n",
       "1      1501720830         2416         2467   \n",
       "2      1544288223         4292         1208   \n",
       "3      1409796219          728          689   \n",
       "4      1473870579         5481          834   \n",
       "\n",
       "                                       item_sequence  \\\n",
       "0        [-1, -1, -1, -1, -1, -1, -1, -1, 218, 2648]   \n",
       "1           [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]   \n",
       "2  [-1, -1, -1, -1, 3541, 3089, 4168, 3936, 4066,...   \n",
       "3    [-1, -1, -1, -1, -1, -1, 193, 3945, 1849, 4407]   \n",
       "4     [-1, -1, -1, -1, -1, -1, -1, 3965, 4617, 2003]   \n",
       "\n",
       "                                    item_sequence_ts  \\\n",
       "0  [-1, -1, -1, -1, -1, -1, -1, -1, 1457886402, 1...   \n",
       "1           [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]   \n",
       "2  [-1, -1, -1, -1, 1488569087, 1499723220, 15334...   \n",
       "3  [-1, -1, -1, -1, -1, -1, 1327177801, 133520743...   \n",
       "4  [-1, -1, -1, -1, -1, -1, -1, 1473870313, 14738...   \n",
       "\n",
       "                    item_sequence_ts_bucket              main_category  \\\n",
       "0    [-1, -1, -1, -1, -1, -1, -1, -1, 6, 0]  Cell Phones & Accessories   \n",
       "1  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]                  Computers   \n",
       "2        [-1, -1, -1, -1, 6, 6, 5, 5, 4, 4]                  Computers   \n",
       "3      [-1, -1, -1, -1, -1, -1, 6, 6, 6, 5]            All Electronics   \n",
       "4     [-1, -1, -1, -1, -1, -1, -1, 0, 0, 0]            All Electronics   \n",
       "\n",
       "                                               title  \\\n",
       "0             Garmin Nuvi 67LMT 6-Inch GPS Navigator   \n",
       "1  Samsung T3 Portable SSD - 2TB - USB 3.1 Extern...   \n",
       "2  ASUS AC1300 WiFi Router (RT-ACRH13) - Dual Ban...   \n",
       "3  Logitech K750 Wireless Solar Keyboard for Mac ...   \n",
       "4  PNY Optima 2GB (2x1GB) Dual Channel Kit DDR2 6...   \n",
       "\n",
       "                                         description  \\\n",
       "0  [With bright 6” dual-orientation displays, spo...   \n",
       "1  [Portability is the key element shared among a...   \n",
       "2  [Upgrade to AC Wi-Fi for your bandwidth-hungry...   \n",
       "3  [Battery hassles are a thing of the past with ...   \n",
       "4  [PNY OPTIMA 2GB (2x1GB) Dual Channel Kit DDR2 ...   \n",
       "\n",
       "                                          categories   price  \n",
       "0  [Electronics, GPS, Finders & Accessories, Spor...   199.0  \n",
       "1  [Electronics, Computers & Accessories, Data St...  348.69  \n",
       "2  [Electronics, Computers & Accessories, Network...    None  \n",
       "3  [Electronics, Computers & Accessories, Compute...   49.99  \n",
       "4  [Electronics, Computers & Accessories, Compute...   65.99  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aad489",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd469969-aaa6-4763-a0fc-d432961cf4dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_indices = train_df[\"user_indice\"].unique()\n",
    "item_indices = train_df[\"item_indice\"].unique()\n",
    "\n",
    "train_item_features = chunk_transform(\n",
    "    train_df, item_metadata_pipeline, chunk_size=args.tfm_chunk_size\n",
    ")\n",
    "train_item_features = train_item_features.astype(np.float32)\n",
    "\n",
    "val_item_features = chunk_transform(\n",
    "    val_df, item_metadata_pipeline, chunk_size=args.tfm_chunk_size\n",
    ")\n",
    "val_item_features = val_item_features.astype(np.float32)\n",
    "\n",
    "logger.info(f\"{len(user_indices)=:,.0f}, {len(item_indices)=:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70546689",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_item_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5260fbe7-2f90-44a1-be74-ce5db9b511ee",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240a04ed-8898-443f-b0f4-7399bfa63810",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset = UserItemBinaryDFDataset(\n",
    "    train_df,\n",
    "    \"user_indice\",\n",
    "    \"item_indice\",\n",
    "    args.rating_col,\n",
    "    args.timestamp_col,\n",
    "    item_feature=train_item_features,\n",
    ")\n",
    "val_rating_dataset = UserItemBinaryDFDataset(\n",
    "    val_df,\n",
    "    \"user_indice\",\n",
    "    \"item_indice\",\n",
    "    args.rating_col,\n",
    "    args.timestamp_col,\n",
    "    item_feature=val_item_features,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    rating_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_rating_dataset, batch_size=args.batch_size, shuffle=True, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dcf157-425f-4d15-9b53-e1ff93887def",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_items = len(item_indices)\n",
    "n_users = len(user_indices)\n",
    "item_feature_size = train_item_features.shape[1]\n",
    "\n",
    "model = init_model(\n",
    "    n_users,\n",
    "    n_items,\n",
    "    args.embedding_dim,\n",
    "    args.item_sequence_ts_bucket_size,\n",
    "    args.bucket_embedding_dim,\n",
    "    item_feature_size,\n",
    "    args.dropout,\n",
    "    use_item_feature=args.use_item_feature,\n",
    ")\n",
    "model.item_embedding.padding_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4271b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in val_loader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cbb2a8-a578-4ad2-941e-efd01d930336",
   "metadata": {},
   "source": [
    "#### Predict before train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f435c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_df.shape)\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0112de1e-1dce-4982-9663-a1df91fd0001",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_df = val_rating_dataset.df\n",
    "val_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb1583b-40f7-4157-a383-5891389ac119",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_id = val_df.sample(1)[args.user_col].values[0]\n",
    "test_df = val_df.loc[lambda df: df[args.user_col].eq(user_id)]\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ffbabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_item_features.shape, train_item_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48fbc80-eda8-4dff-a246-95f8f2f75082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_row = test_df.loc[lambda df: df[args.rating_col].gt(0)].iloc[0]\n",
    "item_id = test_row[args.item_col]\n",
    "item_sequence = test_row[\"item_sequence\"]\n",
    "item_sequence_ts_bucket = test_row[\"item_sequence_ts_bucket\"]\n",
    "row_idx = test_row.name\n",
    "item_feature = val_item_features[row_idx]\n",
    "logger.info(\n",
    "    f\"Test predicting before training with {args.user_col} = {user_id} and {args.item_col} = {item_id}\"\n",
    ")\n",
    "user_indice = idm.get_user_index(user_id)\n",
    "item_indice = idm.get_item_index(item_id)\n",
    "user = torch.tensor([user_indice])\n",
    "item_sequence = torch.tensor([item_sequence])\n",
    "item_sequence_ts_bucket = torch.tensor([item_sequence_ts_bucket])\n",
    "item_feature = torch.tensor([item_feature])\n",
    "item = torch.tensor([item_indice])\n",
    "\n",
    "model.eval()\n",
    "model.predict(user, item_sequence, item_sequence_ts_bucket, item_feature, item)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fd217c-c0c8-4e7c-81fe-6eb36f4729b5",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9daad4-1365-4e8e-8f73-80ca5513572b",
   "metadata": {},
   "source": [
    "##### Overfit 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1cd9bd-e2c6-404b-b6ae-b26a7d35a0ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=10, mode=\"min\", verbose=False\n",
    ")\n",
    "\n",
    "model = init_model(\n",
    "    n_users,\n",
    "    n_items,\n",
    "    args.embedding_dim,\n",
    "    args.item_sequence_ts_bucket_size,\n",
    "    args.bucket_embedding_dim,\n",
    "    item_feature_size,\n",
    "    dropout=args.dropout,\n",
    "    use_item_feature=args.use_item_feature,\n",
    ")\n",
    "lit_model = LitRanker(\n",
    "    model,\n",
    "    learning_rate=args.learning_rate,\n",
    "    l2_reg=0.0,\n",
    "    log_dir=args.notebook_persist_dp,\n",
    "    accelerator=args.device,\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persist_dp}/logs/overfit\"\n",
    "\n",
    "# # train model\n",
    "# trainer = L.Trainer(\n",
    "#     default_root_dir=log_dir,\n",
    "#     accelerator=args.device if args.device else \"auto\",\n",
    "#     max_epochs=2,\n",
    "#     overfit_batches=1,\n",
    "#     callbacks=[early_stopping],\n",
    "# )\n",
    "# trainer.fit(\n",
    "#     model=lit_model,\n",
    "#     train_dataloaders=train_loader,\n",
    "#     val_dataloaders=val_loader,\n",
    "\n",
    "# )\n",
    "# logger.info(f\"Logs available at {trainer.log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cc9ae0-a993-4815-bebd-85cc51e68e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to make sure port 6006 at local is accessible\n",
    "# %tensorboard --logdir $trainer.log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c7e4af-5c66-454e-9e2c-2ca134f4e1cf",
   "metadata": {},
   "source": [
    "##### Fit on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d42874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of rows in train_df that has rating = 0 and 1\n",
    "print(\n",
    "    f\"Number of rows in train_df that has rating = 0: {train_df[train_df[args.rating_col] == 0.0].shape[0]}\"\n",
    ")\n",
    "print(\n",
    "    f\"Number of rows in train_df that has rating = 1: {train_df[train_df[args.rating_col] >= 1.0].shape[0]}\"\n",
    ")\n",
    "print(f\"Number of rows in train_df: {train_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baa4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by a specific user_id and all the rows for that user\n",
    "user_id = \"AF5KKBAOVY7J7LGPHAECKUTDQVTA\"\n",
    "user_df = train_df.loc[lambda df: df[args.user_col].eq(user_id)]\n",
    "print(f\"Number of rows for user {user_id}: {user_df.shape[0]}\")\n",
    "user_df = user_df.sort_values(by=args.timestamp_col, ascending=False)\n",
    "user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc5f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the train_df by timestamp and get the lastest item features from train_df\n",
    "all_items_df = train_df.sort_values(by=args.timestamp_col, ascending=False)\n",
    "# get the lastest item features from train_df\n",
    "all_items_indices = all_items_df.drop_duplicates(subset=[args.item_col], keep=\"first\")[\"item_indice\"].values\n",
    "all_items_features = item_metadata_pipeline.transform(all_items_df).astype(np.float32)\n",
    "logger.info(\n",
    "    f\"Mean std over categorical and numerical features: {all_items_features.std(axis=0).mean()}\"\n",
    ")\n",
    "# if args.rc.use_sbert_features:\n",
    "#     all_sbert_vectors = ann_index.get_vector_by_ids(all_items_indices.tolist()).astype(\n",
    "#         np.float32\n",
    "#     )\n",
    "#     logger.info(f\"Mean std over text features: {all_sbert_vectors.std(axis=0).mean()}\")\n",
    "#     all_items_features = np.hstack([all_items_features, all_sbert_vectors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d821e0-3255-4947-b720-81a2f83a4911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_items_df = train_df.drop_duplicates(subset=[\"item_indice\"])\n",
    "# all_items_indices = all_items_df[\"item_indice\"].values\n",
    "# all_items_features = item_metadata_pipeline.transform(all_items_df).astype(np.float32)\n",
    "# logger.info(\n",
    "#     f\"Mean std over categorical and numerical features: {all_items_features.std(axis=0).mean()}\"\n",
    "# )\n",
    "# # if args.rc.use_sbert_features:\n",
    "# #     all_sbert_vectors = ann_index.get_vector_by_ids(all_items_indices.tolist()).astype(\n",
    "# #         np.float32\n",
    "# #     )\n",
    "# #     logger.info(f\"Mean std over text features: {all_sbert_vectors.std(axis=0).mean()}\")\n",
    "# #     all_items_features = np.hstack([all_items_features, all_sbert_vectors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3e950d-008b-4564-845e-a68d3c96ef5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# papermill_description=fit-model\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_roc_auc\", patience=args.early_stopping_patience, mode=\"max\", verbose=False\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{args.notebook_persist_dp}/checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_roc_auc\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "model = init_model(\n",
    "    n_users,\n",
    "    n_items,\n",
    "    args.embedding_dim,\n",
    "    args.item_sequence_ts_bucket_size,\n",
    "    args.bucket_embedding_dim,\n",
    "    item_feature_size,\n",
    "    dropout=args.dropout,\n",
    "    item_embedding=pretrained_item_embedding,\n",
    "    use_item_feature=args.use_item_feature,\n",
    ")\n",
    "lit_model = LitRanker(\n",
    "    model,\n",
    "    learning_rate=args.learning_rate,\n",
    "    l2_reg=args.l2_reg,\n",
    "    log_dir=args.notebook_persist_dp,\n",
    "    evaluate_ranking=True,\n",
    "    idm=idm,\n",
    "    all_items_indices=all_items_indices,\n",
    "    all_items_features=all_items_features,\n",
    "    args=args,\n",
    "    neg_to_pos_ratio=args.neg_to_pos_ratio,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    accelerator=args.device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9142d9-2c1c-47e0-890b-2104f6726ff0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_dir = f\"{args.notebook_persist_dp}/logs/run\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    max_epochs=args.max_epochs,\n",
    "    callbacks=[early_stopping, checkpoint_callback],\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    logger=args._mlf_logger if args.log_to_mlflow else None,\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14174c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of unique items in val_df\n",
    "print(f\"Number of unique items in val_df: {val_df['item_indice'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af44bf35-e7c7-4718-97b8-238e89b7f3f0",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# logger.info(\n",
    "#     f\"Test predicting after training with {args.user_col} = {user_id} and {args.item_col} = {item_id}\"\n",
    "# )\n",
    "# model.eval()\n",
    "# model = model.to(user.device)  # Move model back to align with data device\n",
    "# model.predict(user, item_sequence, item_sequence_ts_bucket, item_feature, item)\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e1dd22-bcb9-4582-96d0-30acc4e8b790",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Load best checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb3a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Loading best checkpoint from {checkpoint_callback.best_model_path}...\")\n",
    "args.best_checkpoint_path = checkpoint_callback.best_model_path\n",
    "\n",
    "best_trainer = LitRanker.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    model=init_model(\n",
    "        n_users,\n",
    "        n_items,\n",
    "        args.embedding_dim,\n",
    "        args.item_sequence_ts_bucket_size,\n",
    "        args.bucket_embedding_dim,\n",
    "        item_feature_size,\n",
    "        dropout=0,\n",
    "        item_embedding=pretrained_item_embedding,\n",
    "        use_item_feature=args.use_item_feature,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a330527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_trainer = LitRanker.load_from_checkpoint(\n",
    "#     \"C:/Users/Trieu/Downloads/best-checkpoint (2).ckpt\",\n",
    "#     model=init_model(\n",
    "#         n_users,\n",
    "#         n_items,\n",
    "#         args.embedding_dim,\n",
    "#         args.item_sequence_ts_bucket_size,\n",
    "#         args.bucket_embedding_dim,\n",
    "#         item_feature_size,\n",
    "#         dropout=0,\n",
    "#         item_embedding=pretrained_item_embedding,\n",
    "#     ),\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b679e7",
   "metadata": {},
   "source": [
    "## testing after train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfba578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_id = val_df.sample(1)[args.user_col].values[0]\n",
    "# test_df = val_df.loc[lambda df: df[args.user_col].eq(user_id)]\n",
    "# # with pd.option_context(\"display.max_colwidth\", None):\n",
    "# #     display(test_df)\n",
    "# test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9d574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_row = test_df.loc[lambda df: df[args.rating_col].eq(0)].iloc[0]\n",
    "# item_id = test_row[args.item_col]\n",
    "# item_sequence = test_row[\"item_sequence\"]\n",
    "# item_sequence_ts_bucket = test_row[\"item_sequence_ts_bucket\"]\n",
    "# row_idx = test_row.name\n",
    "# item_feature = val_item_features[row_idx]\n",
    "# logger.info(\n",
    "#     f\"Test predicting before training with {args.user_col} = {user_id} and {args.item_col} = {item_id}\"\n",
    "# )\n",
    "# user_indice = idm.get_user_index(user_id)\n",
    "# item_indice = idm.get_item_index(item_id)\n",
    "# user = torch.tensor([user_indice])\n",
    "# item_sequence = torch.tensor([item_sequence])\n",
    "# item_sequence_ts_bucket = torch.tensor([item_sequence_ts_bucket])\n",
    "# item_feature = torch.tensor([item_feature])\n",
    "# item = torch.tensor([item_indice])\n",
    "\n",
    "# # print the information of the user and item and rating we are testing as a row in dataframe\n",
    "# user_df = pd.DataFrame({\n",
    "#     args.user_col: [user_id],\n",
    "#     args.item_col: [item_id],\n",
    "#     args.rating_col: [test_row[args.rating_col]],\n",
    "#     \"item_sequence\": [item_sequence.tolist()],\n",
    "#     \"item_sequence_ts_bucket\": [item_sequence_ts_bucket],\n",
    "#     \"item_feature\": [item_feature.tolist()],\n",
    "# })\n",
    "# user_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68989e7-cd28-4cb3-9a28-5bd477bb67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = best_trainer.model.to(lit_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72062d94-6ee8-480f-b7c6-9dcae2ceeb8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# best_model.eval()\n",
    "# best_model.predict(user, item_sequence, item_sequence_ts_bucket, item_feature, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26afc39d-5cbd-4ea4-9484-f6419b460bde",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Persist artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275bcb81-bf50-4757-9e63-5c7a317b276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.log_to_mlflow:\n",
    "    # Persist id_mapping so that at inference we can predict based on item_ids (string) instead of item_index\n",
    "    run_id = trainer.logger.run_id\n",
    "    mlf_client = trainer.logger.experiment\n",
    "    mlf_client.log_artifact(run_id, idm_fp)\n",
    "    # Persist item_feature_metadata pipeline\n",
    "    mlf_client.log_artifact(run_id, args.item_metadata_pipeline_fp)\n",
    "\n",
    "    # Persist model architecture\n",
    "    model_architecture_fp = f\"{args.notebook_persist_dp}/model_architecture.txt\"\n",
    "    with open(model_architecture_fp, \"w\") as f:\n",
    "        f.write(repr(model))\n",
    "    mlf_client.log_artifact(run_id, model_architecture_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a53735-cada-4b16-b6ec-b958e20d8093",
   "metadata": {},
   "source": [
    "### Wrap inference function and register best checkpoint as MLflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1da4ca-1616-4f57-99fb-cb851c535a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferrer = RankerInferenceWrapper(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91c26a5-d86e-4d3a-b3a2-87e6a5e88427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_item_features():\n",
    "    sample_row = train_df.iloc[0].fillna(0)\n",
    "    output = dict()\n",
    "    for col in args.rc.item_feature_cols:\n",
    "        v = sample_row[col]\n",
    "        if isinstance(v, np.ndarray):\n",
    "            v = \"__\".join(\n",
    "                sample_row[col].tolist()\n",
    "            )  # Workaround to avoid MLflow Got error: Per-column arrays must each be 1-dimensional\n",
    "        output[col] = [v]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21791a9-d5fc-4abe-bc3c-820aba9f0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = {\n",
    "    args.user_col: [idm.get_user_id(0)],\n",
    "    \"item_sequence\": [\",\".join([idm.get_item_id(0), idm.get_item_id(1)])],\n",
    "    \"item_sequence_ts\": [\n",
    "        \"1095133116,109770848\"\n",
    "    ],  # Here we input unix timestamp seconds instead of timestamp bucket because we need to calculate the bucket\n",
    "    # **{col: [train_df.iloc[0].fillna(0)[col]] for col in args.item_feature_cols},\n",
    "    **generate_sample_item_features(),\n",
    "    args.item_col: [idm.get_item_id(0)],\n",
    "}\n",
    "sample_output = inferrer.infer([0], [[0, 1]], [[2, 0]], [train_item_features[0]], [0])\n",
    "sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b5cf4-5e51-4641-bdfe-6ce289344bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c043a-f777-4ade-ab80-cfa4d90aafa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args.log_to_mlflow:\n",
    "    run_id = trainer.logger.run_id\n",
    "    sample_output_np = sample_output\n",
    "    signature = infer_signature(sample_input, sample_output_np)\n",
    "    idm_filename = idm_fp.split(\"/\")[-1]\n",
    "    item_metadata_pipeline_filename = args.item_metadata_pipeline_fp.split(\"/\")[-1]\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        mlflow.pyfunc.log_model(\n",
    "            python_model=inferrer,\n",
    "            artifact_path=\"inferrer\",\n",
    "            artifacts={\n",
    "                # We log the id_mapping to the predict function so that it can accept item_id and automatically convert ot item_indice for PyTorch model to use\n",
    "                \"idm\": mlflow.get_artifact_uri(idm_filename),\n",
    "                \"item_metadata_pipeline\": mlflow.get_artifact_uri(\n",
    "                    item_metadata_pipeline_filename\n",
    "                ),\n",
    "            },\n",
    "            model_config={\"use_sbert_features\": args.rc.use_sbert_features},\n",
    "            signature=signature,\n",
    "            input_example=sample_input,\n",
    "            registered_model_name=args.mlf_model_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d5150-9851-4e61-b1af-8e619abc9ea4",
   "metadata": {},
   "source": [
    "# Set the newly trained model as champion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72c27d5-6f7c-401b-9322-7d428ab51240",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.log_to_mlflow:\n",
    "    # Get current champion\n",
    "    deploy_alias = \"champion\"\n",
    "    curr_model_run_id = None\n",
    "\n",
    "    min_roc_auc = args.min_roc_auc\n",
    "\n",
    "    try:\n",
    "        curr_champion_model = mlf_client.get_model_version_by_alias(\n",
    "            args.mlf_model_name, deploy_alias\n",
    "        )\n",
    "        curr_model_run_id = curr_champion_model.run_id\n",
    "    except MlflowException as e:\n",
    "        if \"not found\" in str(e).lower():\n",
    "            logger.info(\n",
    "                f\"There is no {deploy_alias} alias for model {args.mlf_model_name}\"\n",
    "            )\n",
    "\n",
    "    # Compare new vs curr models\n",
    "    new_mlf_run = trainer.logger.experiment.get_run(trainer.logger.run_id)\n",
    "    new_metrics = new_mlf_run.data.metrics\n",
    "    roc_auc = new_metrics[\"roc_auc\"]\n",
    "    if curr_model_run_id:\n",
    "        curr_model_run_info = mlf_client.get_run(curr_model_run_id)\n",
    "        curr_metrics = curr_model_run_info.data.metrics\n",
    "        if (curr_roc_auc := curr_metrics[\"roc_auc\"]) > min_roc_auc:\n",
    "            logger.info(\n",
    "                f\"Current {deploy_alias} model has {curr_roc_auc:,.4f} ROC-AUC...\"\n",
    "            )\n",
    "            min_roc_auc = curr_roc_auc\n",
    "\n",
    "        top_metrics = [\"roc_auc\", \"val_PersonalizationMetric\"]\n",
    "        vizer = ModelMetricsComparisonVisualizer(curr_metrics, new_metrics, top_metrics)\n",
    "        print(f\"Comparing metrics between new run and current champion:\")\n",
    "        display(vizer.compare_metrics_df())\n",
    "        vizer.create_metrics_comparison_plot(n_cols=5)\n",
    "        vizer.plot_diff()\n",
    "\n",
    "    # Register new champion\n",
    "    if roc_auc < min_roc_auc:\n",
    "        logger.info(\n",
    "            f\"Current run has ROC-AUC = {roc_auc:,.4f}, smaller than {min_roc_auc:,.4f}. Skip aliasing this model as the new {deploy_alias}..\"\n",
    "        )\n",
    "    else:\n",
    "        logger.info(f\"Aliasing the new model as champion...\")\n",
    "        # Get the model version for current run by assuming it's the most recent registered version\n",
    "        model_version = (\n",
    "            mlf_client.get_registered_model(args.mlf_model_name)\n",
    "            .latest_versions[0]\n",
    "            .version\n",
    "        )\n",
    "\n",
    "        mlf_client.set_registered_model_alias(\n",
    "            name=args.mlf_model_name, alias=\"champion\", version=model_version\n",
    "        )\n",
    "\n",
    "        mlf_client.set_model_version_tag(\n",
    "            name=args.mlf_model_name,\n",
    "            version=model_version,\n",
    "            key=\"author\",\n",
    "            value=args.author,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd09b91a-023e-4db4-8f10-e0444b118c85",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719214cc-6c54-44ad-997e-ad3e18fbba95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_params = [args]\n",
    "\n",
    "if args.log_to_mlflow:\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        for params in all_params:\n",
    "            params_dict = params.dict()\n",
    "            params_ = dict()\n",
    "            for k, v in params_dict.items():\n",
    "                if k == \"top_K\":\n",
    "                    k = \"top_big_K\"\n",
    "                if k == \"top_k\":\n",
    "                    k = \"top_small_k\"\n",
    "                params_[f\"{params.__repr_name__()}.{k}\"] = v\n",
    "            mlflow.log_params(params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cff81a-484e-4919-be8f-0351cce91a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
