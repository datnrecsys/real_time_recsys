{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydantic import BaseModel\n",
    "import sys\n",
    "import os\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from loguru import logger\n",
    "from load_dotenv import load_dotenv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import mlflow\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src.utils.embedding_id_mapper import IDMapper\n",
    "from src.algo.sequence.model import SequenceRatingPrediction\n",
    "from src.algo.sequence.dataset import UserItemBinaryRatingDFDataset\n",
    "from src.algo.sequence.trainer import SeqModellingLitModule\n",
    "from src.algo.item2vec.trainer import LitSkipGram\n",
    "from src.algo.item2vec.model import SkipGram\n",
    "from src.eval.utils import create_rec_df, create_label_df, merge_recs_with_target\n",
    "from src.eval.log_metrics import log_ranking_metrics, log_classification_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-26 20:38:46.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mSetting up Mlflow experiment: pruning-sequence-modelling, run_name: attn-256-dim-bce-prelu\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"testing\": false,\n",
      "  \"log_to_mlflow\": true,\n",
      "  \"experiment_name\": \"pruning-sequence-modelling\",\n",
      "  \"notebook_persit_dp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\notebooks\\\\data\\\\pruning-sequence-modelling\\\\attn-256-dim-bce-prelu\",\n",
      "  \"run_name\": \"attn-256-dim-bce-prelu\",\n",
      "  \"user_col\": \"user_id\",\n",
      "  \"item_col\": \"parent_asin\",\n",
      "  \"rating_col\": \"rating\",\n",
      "  \"timestamp_col\": \"timestamp\",\n",
      "  \"group_name\": \"seq-modelling\",\n",
      "  \"top_K\": 100,\n",
      "  \"top_k\": 10,\n",
      "  \"batch_size\": 512,\n",
      "  \"learning_rate\": 0.001,\n",
      "  \"l2_reg\": 1e-6,\n",
      "  \"early_stopping_patience\": 10,\n",
      "  \"device\": \"cpu\",\n",
      "  \"max_epochs\": 1,\n",
      "  \"dropout\": 0.3,\n",
      "  \"embedding_dim\": 256,\n",
      "  \"use_user_embedding\": true,\n",
      "  \"user_embedding_dim\": 32,\n",
      "  \"use_metadata\": true,\n",
      "  \"metadata_embedding_dim\": 384,\n",
      "  \"metadata_fc_dim\": 32,\n",
      "  \"train_data_fp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\data_for_ai\\\\interim\\\\train_sample_interactions_16407u_neg_seq.parquet\",\n",
      "  \"val_data_fp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\data_for_ai\\\\interim\\\\val_sample_interactions_16407u_neg_seq.parquet\",\n",
      "  \"best_checkpoint_path\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Args(BaseModel):\n",
    "    testing: bool = False\n",
    "    log_to_mlflow: bool = True\n",
    "    experiment_name: str = \"pruning-sequence-modelling\"\n",
    "    notebook_persit_dp: str = None\n",
    "    \n",
    "    run_name: str = None\n",
    "\n",
    "    user_col: str = \"user_id\"\n",
    "    item_col: str = \"parent_asin\"\n",
    "    rating_col: str = \"rating\"\n",
    "    timestamp_col: str = \"timestamp\"\n",
    "    group_name: str = \"seq-modelling\"\n",
    "\n",
    "    top_K: int = 100\n",
    "    top_k: int = 10\n",
    "\n",
    "    batch_size: int = 512\n",
    "    learning_rate: float = 0.001\n",
    "    l2_reg: float = 1e-6\n",
    "    early_stopping_patience: int = 10\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    max_epochs: int = 100\n",
    "\n",
    "    # TwoTower specific\n",
    "    dropout: float = 0.3\n",
    "    embedding_dim: int = 256\n",
    "    use_user_embedding: bool = True\n",
    "    user_embedding_dim: int = 32\n",
    "\n",
    "    use_metadata: bool = True\n",
    "    metadata_embedding_dim: int = 384\n",
    "    metadata_fc_dim: int = 128\n",
    "\n",
    "\n",
    "    train_data_fp: str = os.path.abspath(\"../data_for_ai/interim/train_sample_interactions_16407u_neg_seq.parquet\")\n",
    "    val_data_fp: str = os.path.abspath(\"../data_for_ai/interim/val_sample_interactions_16407u_neg_seq.parquet\")\n",
    "\n",
    "    best_checkpoint_path: str = None\n",
    "    def init(self):\n",
    "        self.run_name: str = f\"attn-{self.embedding_dim}-dim-bce-prelu\"\n",
    "        self.notebook_persit_dp = os.path.abspath(f\"data/{self.experiment_name}/{self.run_name}\")\n",
    "\n",
    "        if not (mlflow_uri := os.environ.get(\"MLFLOW_TRACKING_URI\")):\n",
    "            self.log_to_mlflow = False\n",
    "            logger.warning(\"MLFlow is not enabled. Turn off tracking to Mlflow.\")\n",
    "\n",
    "        if self.log_to_mlflow:\n",
    "            logger.info(\n",
    "                f\"Setting up Mlflow experiment: {self.experiment_name}, run_name: {self.run_name}\"\n",
    "            )\n",
    "\n",
    "            self._mlf_logger = MLFlowLogger(\n",
    "                experiment_name=self.experiment_name,\n",
    "                run_name=self.run_name,\n",
    "                tracking_uri=mlflow_uri,\n",
    "                log_model=False,\n",
    "            )\n",
    "\n",
    "        if not self.testing:\n",
    "            os.makedirs(self.notebook_persit_dp, exist_ok=True)\n",
    "        return self\n",
    "    \n",
    "args = Args().init()\n",
    "print(args.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata embedding\n",
    "metadata_embedding_matrix = np.load(\"../data_for_ai/interim/metadata_title_embedding.npy\")  # shape (4817, 898)\n",
    "\n",
    "# add 2 more vector for padding and start token \n",
    "metadata_embedding_matrix = np.concatenate(\n",
    "    [np.zeros((2, metadata_embedding_matrix.shape[1])), metadata_embedding_matrix], axis=0\n",
    ")\n",
    "metadata_embedding_tensor = torch.tensor(metadata_embedding_matrix, dtype=torch.float32)\n",
    "metadata_embedding_layer = nn.Embedding.from_pretrained(\n",
    "    embeddings=metadata_embedding_tensor,\n",
    "    freeze=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata embedding shape: torch.Size([4819, 384])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Metadata embedding shape: {metadata_embedding_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(n_users, n_items, embedding_dim, dropout, item_embedding=None,\n",
    "               user_embedding_dim=None,use_user_embedding=False,\n",
    "               use_metadata=False, metadata_embedding=None,\n",
    "               metadata_embedding_dim=898, metadata_fc_dim=256):\n",
    "    return SequenceRatingPrediction(\n",
    "        item_embedding=item_embedding,\n",
    "        num_users=n_users,\n",
    "        num_items=n_items,\n",
    "        embedding_dim=embedding_dim,\n",
    "        dropout=dropout,\n",
    "        user_embedding_dim=user_embedding_dim,\n",
    "        use_user_embedding=use_user_embedding,\n",
    "        use_metadata=use_metadata,\n",
    "        metadata_embedding=metadata_embedding,\n",
    "        metadata_embedding_dim=metadata_embedding_dim,\n",
    "        metadata_fc_dim=metadata_fc_dim,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-26 20:38:48.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.sequence.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mStart token used: 4, Padding token used: 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4067]], grad_fn=<MaskedFillBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceRatingPrediction(\n",
       "  (item_embedding): Embedding(6, 32, padding_idx=5)\n",
       "  (encoder_layer): TransformerEncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (linear2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.3, inplace=False)\n",
       "    (dropout2): Dropout(p=0.3, inplace=False)\n",
       "    (activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "        (activation): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (prelu1): PReLU(num_parameters=1)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (metadata_embedding): Embedding(5, 32)\n",
       "  (metadata_fc): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (metadata_prelu): PReLU(num_parameters=1)\n",
       "  (item_tower_fc): Linear(in_features=48, out_features=32, bias=True)\n",
       "  (user_embedding): Embedding(3, 64)\n",
       "  (user_tower_fc): Linear(in_features=96, out_features=32, bias=True)\n",
       "  (final_fc): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (score_fc): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 32\n",
    "user_embedding_dim = 64\n",
    "batch_size = 2\n",
    "\n",
    "# Mock data\n",
    "user_indices = [0, 0, 1, 2, 2]\n",
    "item_indices = [0, 1, 2, 3, 4]\n",
    "timestamps = [0, 1, 2, 3, 4]\n",
    "ratings = [0, 3, 1, 3, 0]\n",
    "# item_sequences = [\n",
    "#     [2, 3, -1, -1],\n",
    "#     [2, 4, -1, -1],\n",
    "#     [1, 3, -1, -1],\n",
    "#     [2, 1, -1, -1],\n",
    "#     [4, 1, -1, -1],\n",
    "# ]\n",
    "\n",
    "item_sequences = [\n",
    "    [-1, -1, 2, 3],\n",
    "    [-1, -1, 2, 4],\n",
    "    [-1, -1, 1, 3],\n",
    "    [-1, -1, 2, 1],\n",
    "    [-1, -1, 4, 1],\n",
    "]\n",
    "\n",
    "\n",
    "n_users = len(set(user_indices))\n",
    "\n",
    "n_items = len(set(item_indices))\n",
    "\n",
    "train_df = pd.DataFrame(\n",
    "    {\n",
    "        \"user_indice\": user_indices,\n",
    "        \"item_indice\": item_indices,\n",
    "        args.timestamp_col: timestamps,\n",
    "        args.rating_col: ratings,\n",
    "        \"item_sequence\": item_sequences,\n",
    "    }\n",
    ")\n",
    "# Mock metadata embedding (giả sử mỗi item có 32 chiều metadata embedding)\n",
    "mock_metadata_embedding_matrix = np.random.randn(n_items, embedding_dim).astype(np.float32)\n",
    "mock_metadata_embedding_layer = nn.Embedding.from_pretrained(\n",
    "    embeddings=torch.tensor(mock_metadata_embedding_matrix),\n",
    "    freeze=True)\n",
    "\n",
    "model = init_model(n_users, \n",
    "                   n_items, \n",
    "                   embedding_dim, \n",
    "                   args.dropout,\n",
    "                   user_embedding_dim=user_embedding_dim,\n",
    "                   use_user_embedding=args.use_user_embedding,\n",
    "                   use_metadata=args.use_metadata,\n",
    "                   metadata_embedding=mock_metadata_embedding_layer,\n",
    "                   metadata_embedding_dim=embedding_dim,\n",
    "                   metadata_fc_dim=16,)\n",
    "\n",
    "# Example forward pass\n",
    "model.eval()\n",
    "user = torch.tensor([0])\n",
    "item_sequence = torch.tensor([[-0, 1, -1, -1]])\n",
    "target_item = torch.tensor([2])\n",
    "target_metadata = torch.tensor([2])  # giả sử metadata index trùng với item index\n",
    "predictions = model(user, item_sequence, target_item, target_metadata)\n",
    "print(predictions)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset = UserItemBinaryRatingDFDataset(\n",
    "    train_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col,\"item_sequence\"\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    rating_dataset, batch_size=batch_size, shuffle=False, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': tensor([0, 0]), 'item': tensor([0, 1]), 'rating': tensor([0., 1.]), 'item_sequence': tensor([[-1, -1,  2,  3],\n",
      "        [-1, -1,  2,  4]], dtype=torch.int32)}\n",
      "{'user': tensor([1, 2]), 'item': tensor([2, 3]), 'rating': tensor([1., 1.]), 'item_sequence': tensor([[-1, -1,  1,  3],\n",
      "        [-1, -1,  2,  1]], dtype=torch.int32)}\n"
     ]
    }
   ],
   "source": [
    "for batch_input in train_loader:\n",
    "    print(batch_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "lit_model = SeqModellingLitModule(model, log_dir=args.notebook_persit_dp)\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=f\"{args.notebook_persit_dp}/test\",\n",
    "    max_epochs=100,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    ")\n",
    "# trainer.fit(\n",
    "#     model=lit_model, train_dataloaders=train_loader, val_dataloaders=train_loader\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5976]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "user = torch.tensor([0])\n",
    "item_sequence = torch.tensor([[-1, -1, -1, 0, 1]])\n",
    "target_item = torch.tensor([2])\n",
    "target_metadata = torch.tensor([2])  # giả sử metadata index trùng với item index\n",
    "predictions = model.predict(user, item_sequence, target_item,target_metadata)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(args.train_data_fp)\n",
    "val_df = pd.read_parquet(args.val_data_fp)\n",
    "\n",
    "assert set(val_df[args.user_col].unique()).issubset(set(train_df[args.user_col].unique())), \"Validation users must be present in training users.\"\n",
    "\n",
    "assert set(val_df[args.item_col].unique()).issubset(set(train_df[args.item_col].unique())), \"Validation items must be present in training items.\"\n",
    "assert train_df[args.timestamp_col].max() < val_df[args.timestamp_col].min(), \"Validation data must be after training data. Otherwise, its a data contamination problem.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151343</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B009RUZ7TS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:15:55.000</td>\n",
       "      <td>1412</td>\n",
       "      <td>4220</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 455...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40958</th>\n",
       "      <td>AF7KZV4NJ5GBDVFTB7PEEUN4U53A</td>\n",
       "      <td>B0BBMLD8QT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-07-29 20:38:06.000</td>\n",
       "      <td>4871</td>\n",
       "      <td>4476</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218918</th>\n",
       "      <td>AFVQ4K4KZPLQ3E2VFYSGX6HFXGNQ</td>\n",
       "      <td>B0BB6R89VF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-12-13 20:35:02.334</td>\n",
       "      <td>7616</td>\n",
       "      <td>1218</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43115</th>\n",
       "      <td>AFCLWJMGYFCOJQR7T4454OF5A5WA</td>\n",
       "      <td>B00ENFP224</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-09-06 12:09:59.000</td>\n",
       "      <td>5250</td>\n",
       "      <td>1355</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233421</th>\n",
       "      <td>AFP4PHJ6Q2RRXLDPSDSH6VXJRUTA</td>\n",
       "      <td>B07CMXS5FP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-11-23 09:44:21.734</td>\n",
       "      <td>6792</td>\n",
       "      <td>838</td>\n",
       "      <td>[-1.0, -1.0, -1.0, 1055.0, 3572.0, 3865.0, 176...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250960</th>\n",
       "      <td>AGQHC7YNLYP4QV2PSBD6URSMJSVA</td>\n",
       "      <td>B07H65KP63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-02-08 04:09:50.457</td>\n",
       "      <td>11001</td>\n",
       "      <td>3568</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, 3585.0, 1866.0, 4040....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217058</th>\n",
       "      <td>AHD65JAOVTTPDNJWOLSSGS3QVK6Q</td>\n",
       "      <td>B07DKMJ61N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-11-02 15:25:18.351</td>\n",
       "      <td>13410</td>\n",
       "      <td>4239</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61324</th>\n",
       "      <td>AF32PWYNLPCVAU4UX35IEAZOFA3Q</td>\n",
       "      <td>B011BRUOMO</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-07-18 05:42:21.000</td>\n",
       "      <td>4264</td>\n",
       "      <td>2253</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132003</th>\n",
       "      <td>AGM65FYYAPHOLESGIDMFMPUQIYNA</td>\n",
       "      <td>B0016BVDIK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010-12-16 19:59:19.000</td>\n",
       "      <td>10445</td>\n",
       "      <td>4250</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34752</th>\n",
       "      <td>AFVQ4K4KZPLQ3E2VFYSGX6HFXGNQ</td>\n",
       "      <td>B00DR0B6XK</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015-04-02 17:48:23.000</td>\n",
       "      <td>7616</td>\n",
       "      <td>1293</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254784 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id parent_asin  rating  \\\n",
       "151343  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B009RUZ7TS     0.0   \n",
       "40958   AF7KZV4NJ5GBDVFTB7PEEUN4U53A  B0BBMLD8QT     5.0   \n",
       "218918  AFVQ4K4KZPLQ3E2VFYSGX6HFXGNQ  B0BB6R89VF     0.0   \n",
       "43115   AFCLWJMGYFCOJQR7T4454OF5A5WA  B00ENFP224     5.0   \n",
       "233421  AFP4PHJ6Q2RRXLDPSDSH6VXJRUTA  B07CMXS5FP     0.0   \n",
       "...                              ...         ...     ...   \n",
       "250960  AGQHC7YNLYP4QV2PSBD6URSMJSVA  B07H65KP63     0.0   \n",
       "217058  AHD65JAOVTTPDNJWOLSSGS3QVK6Q  B07DKMJ61N     0.0   \n",
       "61324   AF32PWYNLPCVAU4UX35IEAZOFA3Q  B011BRUOMO     5.0   \n",
       "132003  AGM65FYYAPHOLESGIDMFMPUQIYNA  B0016BVDIK     0.0   \n",
       "34752   AFVQ4K4KZPLQ3E2VFYSGX6HFXGNQ  B00DR0B6XK     4.0   \n",
       "\n",
       "                     timestamp  user_indice  item_indice  \\\n",
       "151343 2014-07-17 19:15:55.000         1412         4220   \n",
       "40958  2015-07-29 20:38:06.000         4871         4476   \n",
       "218918 2017-12-13 20:35:02.334         7616         1218   \n",
       "43115  2015-09-06 12:09:59.000         5250         1355   \n",
       "233421 2018-11-23 09:44:21.734         6792          838   \n",
       "...                        ...          ...          ...   \n",
       "250960 2020-02-08 04:09:50.457        11001         3568   \n",
       "217058 2017-11-02 15:25:18.351        13410         4239   \n",
       "61324  2016-07-18 05:42:21.000         4264         2253   \n",
       "132003 2010-12-16 19:59:19.000        10445         4250   \n",
       "34752  2015-04-02 17:48:23.000         7616         1293   \n",
       "\n",
       "                                            item_sequence  \n",
       "151343  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 455...  \n",
       "40958   [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "218918  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 129...  \n",
       "43115   [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "233421  [-1.0, -1.0, -1.0, 1055.0, 3572.0, 3865.0, 176...  \n",
       "...                                                   ...  \n",
       "250960  [-1.0, -1.0, -1.0, -1.0, 3585.0, 1866.0, 4040....  \n",
       "217058  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "61324   [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "132003  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "34752   [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "\n",
       "[254784 rows x 7 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172167</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B07C1RSV9C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-08-05 16:31:49</td>\n",
       "      <td>1412</td>\n",
       "      <td>934</td>\n",
       "      <td>[-1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0, 3295.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41296</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B07C1RSV9C</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-08-05 16:31:49</td>\n",
       "      <td>1412</td>\n",
       "      <td>3276</td>\n",
       "      <td>[-1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0, 3295.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151346</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B07CB22VVJ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:19:28</td>\n",
       "      <td>1412</td>\n",
       "      <td>4599</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20475</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B07CB22VVJ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:19:28</td>\n",
       "      <td>1412</td>\n",
       "      <td>3295</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20474</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B000I23TTE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:16:43</td>\n",
       "      <td>1412</td>\n",
       "      <td>107</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151345</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B000I23TTE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:16:43</td>\n",
       "      <td>1412</td>\n",
       "      <td>4659</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151344</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0BYSP9676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:16:20</td>\n",
       "      <td>1412</td>\n",
       "      <td>3678</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20473</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0BYSP9676</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:16:20</td>\n",
       "      <td>1412</td>\n",
       "      <td>4685</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151343</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B009RUZ7TS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:15:55</td>\n",
       "      <td>1412</td>\n",
       "      <td>4220</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20472</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B009RUZ7TS</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:15:55</td>\n",
       "      <td>1412</td>\n",
       "      <td>1047</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20471</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0787JNNXH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:12:09</td>\n",
       "      <td>1412</td>\n",
       "      <td>3164</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151342</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0787JNNXH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:12:09</td>\n",
       "      <td>1412</td>\n",
       "      <td>121</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151341</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0B7FN67QT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:11:53</td>\n",
       "      <td>1412</td>\n",
       "      <td>4653</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20470</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0B7FN67QT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:11:53</td>\n",
       "      <td>1412</td>\n",
       "      <td>4443</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20469</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0BM6ZLKPL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:11:13</td>\n",
       "      <td>1412</td>\n",
       "      <td>4559</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151340</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0BM6ZLKPL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:11:13</td>\n",
       "      <td>1412</td>\n",
       "      <td>2004</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id parent_asin  rating           timestamp  \\\n",
       "172167  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B07C1RSV9C     0.0 2015-08-05 16:31:49   \n",
       "41296   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B07C1RSV9C     5.0 2015-08-05 16:31:49   \n",
       "151346  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B07CB22VVJ     0.0 2014-07-17 19:19:28   \n",
       "20475   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B07CB22VVJ     5.0 2014-07-17 19:19:28   \n",
       "20474   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B000I23TTE     5.0 2014-07-17 19:16:43   \n",
       "151345  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B000I23TTE     0.0 2014-07-17 19:16:43   \n",
       "151344  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0BYSP9676     0.0 2014-07-17 19:16:20   \n",
       "20473   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0BYSP9676     5.0 2014-07-17 19:16:20   \n",
       "151343  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B009RUZ7TS     0.0 2014-07-17 19:15:55   \n",
       "20472   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B009RUZ7TS     5.0 2014-07-17 19:15:55   \n",
       "20471   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0787JNNXH     5.0 2014-07-17 19:12:09   \n",
       "151342  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0787JNNXH     0.0 2014-07-17 19:12:09   \n",
       "151341  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0B7FN67QT     0.0 2014-07-17 19:11:53   \n",
       "20470   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0B7FN67QT     5.0 2014-07-17 19:11:53   \n",
       "20469   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0BM6ZLKPL     5.0 2014-07-17 19:11:13   \n",
       "151340  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0BM6ZLKPL     0.0 2014-07-17 19:11:13   \n",
       "\n",
       "        user_indice  item_indice  \\\n",
       "172167         1412          934   \n",
       "41296          1412         3276   \n",
       "151346         1412         4599   \n",
       "20475          1412         3295   \n",
       "20474          1412          107   \n",
       "151345         1412         4659   \n",
       "151344         1412         3678   \n",
       "20473          1412         4685   \n",
       "151343         1412         4220   \n",
       "20472          1412         1047   \n",
       "20471          1412         3164   \n",
       "151342         1412          121   \n",
       "151341         1412         4653   \n",
       "20470          1412         4443   \n",
       "20469          1412         4559   \n",
       "151340         1412         2004   \n",
       "\n",
       "                                                                    item_sequence  \n",
       "172167  [-1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0, 3295.0]  \n",
       "41296   [-1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0, 3295.0]  \n",
       "151346    [-1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0]  \n",
       "20475     [-1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0]  \n",
       "20474      [-1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0]  \n",
       "151345     [-1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0]  \n",
       "151344       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0]  \n",
       "20473        [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0]  \n",
       "151343         [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0]  \n",
       "20472          [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0]  \n",
       "20471            [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0]  \n",
       "151342           [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0]  \n",
       "151341             [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0]  \n",
       "20470              [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0]  \n",
       "20469                [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]  \n",
       "151340               [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(train_df.loc[train_df[\"user_id\"] == \"AEEV5YWQKPBTLFWHKOBBULYA2RDQ\"].sort_values(by=args.timestamp_col, ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert user_id and item_id into indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idm_path = os.path.abspath(\"../data_for_ai/interim/idm_16407u.json\")\n",
    "# idm = IDMapper().load(idm_path)\n",
    "# idm.get_user_id(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.pipe(idm.map_indices)\n",
    "# val_df = val_df.pipe(idm.map_indices)\n",
    "\n",
    "# assert idm.unknown_item_index not in train_df[\"item_indice\"].values, \"Unknown item index must be present in training data.\"\n",
    "# assert idm.unknown_user_index not in train_df[\"user_indice\"].values, \"Unknown user index must be present in training data.\"\n",
    "# assert idm.unknown_item_index not in val_df[\"item_indice\"].values, \"Unknown item index must be present in validation data.\"\n",
    "# assert idm.unknown_user_index not in val_df[\"user_indice\"].values, \"Unknown user index must be present in validation data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert train_df.groupby(args.user_col)[args.item_col].nunique().min() >= 5, \"Each user must have at least five items.\"\n",
    "# assert train_df.groupby(args.item_col)[args.user_col].nunique().min() >= 10, \"Each item must have at least ten users.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset = UserItemBinaryRatingDFDataset(\n",
    "    train_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col, \"item_sequence\"\n",
    ")\n",
    "val_rating_dataset = UserItemBinaryRatingDFDataset(\n",
    "    val_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col, \"item_sequence\"\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    rating_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_rating_dataset, batch_size=args.batch_size, shuffle=False, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the weight from SkipGram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-26 20:38:55.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mNumber of users: 16407, Number of items: 4817\u001b[0m\n",
      "\u001b[32m2025-06-26 20:38:55.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.item2vec.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mInitializing item embeddings with num items 4817, embedding dim 256\u001b[0m\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\utilities\\migration\\utils.py:56: PossibleUserWarning:\n",
      "\n",
      "The loaded checkpoint was produced with Lightning v2.5.2, which is newer than your current Lightning version: v2.5.0\n",
      "\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning:\n",
      "\n",
      "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
      "\n",
      "\u001b[32m2025-06-26 20:38:55.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.sequence.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mStart token used: 4816, Padding token used: 4817\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkipGram Item embedding shape: torch.Size([4818, 256])\n",
      "SkipGram Item embedding dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "item_indices = train_df[args.item_col].unique()\n",
    "user_indices = train_df[args.user_col].unique()\n",
    "n_items = len(item_indices)\n",
    "n_users = len(user_indices)\n",
    "\n",
    "logger.info(f\"Number of users: {n_users}, Number of items: {n_items}\")\n",
    "\n",
    "assert args.embedding_dim == 256, \"Embedding dimension must be 256\"\n",
    "best_trainer = LitSkipGram.load_from_checkpoint(\n",
    "    \"../data_for_ai/interim/best-item2vec-weight.ckpt\",\n",
    "    skipgram_model=SkipGram(n_items, args.embedding_dim).to(args.device),\n",
    ")\n",
    "skipgram_item_embedding = best_trainer.skipgram_model.embeddings.weight.data.cpu()\n",
    "print(f\"SkipGram Item embedding shape: {skipgram_item_embedding.shape}\")\n",
    "print(f\"SkipGram Item embedding dtype: {skipgram_item_embedding.dtype}\")\n",
    "# convert skipgram_item_embedding into torch.nn.Embedding and take the first n_items rows\n",
    "skipgram_item_embedding = torch.nn.Embedding.from_pretrained(\n",
    "    skipgram_item_embedding[:n_items], freeze=False\n",
    ")\n",
    "\n",
    "model = init_model(n_users, \n",
    "                   n_items, \n",
    "                   args.embedding_dim, \n",
    "                   args.dropout, \n",
    "                   item_embedding=skipgram_item_embedding,\n",
    "                   user_embedding_dim=args.user_embedding_dim,\n",
    "                   use_user_embedding=args.use_user_embedding,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4817 items in the dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AE227WAM4NWQPJI33OPN7ZARNNZQ'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idm_path = os.path.abspath(\"../data_for_ai/interim/idm_16407u.json\")\n",
    "idm = IDMapper().load(idm_path)\n",
    "idm.get_user_id(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-26 20:38:56.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.sequence.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mStart token used: 4816, Padding token used: 4817\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=5, mode=\"min\", verbose=False\n",
    ")\n",
    "\n",
    "model = init_model(n_users, n_items, args.embedding_dim, args.dropout,item_embedding=skipgram_item_embedding,\n",
    "                   user_embedding_dim=args.user_embedding_dim,\n",
    "                   use_user_embedding=args.use_user_embedding,\n",
    "                   use_metadata=args.use_metadata,\n",
    "                   metadata_embedding=metadata_embedding_layer,\n",
    "                   metadata_embedding_dim=args.metadata_embedding_dim,\n",
    "                   metadata_fc_dim=args.metadata_fc_dim,)\n",
    "\n",
    "lit_model = SeqModellingLitModule(\n",
    "    model,\n",
    "    learning_rate=args.learning_rate,\n",
    "    l2_reg=args.l2_reg,\n",
    "    log_dir=args.notebook_persit_dp,\n",
    "    accelerator=args.device,\n",
    "    idm= idm\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persit_dp}/logs/overfit\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    max_epochs=100,\n",
    "    overfit_batches=1,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "# trainer.fit(\n",
    "#     model=lit_model,\n",
    "#     train_dataloaders=train_loader,\n",
    "#     val_dataloaders=train_loader,\n",
    "# )\n",
    "# logger.info(f\"Logs available at {trainer.log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': tensor([12119, 10793, 11110, 13273,  7660,  4579,  2806, 14693, 10179,   980,\n",
      "         8080, 14022,  7576, 15564,  5175,  7660,  5714,  3689,  9416,  7027,\n",
      "        14124,  5514, 16216, 16199, 14657, 14867,  7880, 15626,  1975,  3301,\n",
      "        15084,  8294, 14744,  4567,  2157,    76, 10483,  4932,  6789,  4315,\n",
      "        12148,  6153,  2054, 15855,  3300,  1280,  1108,  2337,  1805,  1756,\n",
      "         4039,    83, 15809,  2309,  5006,   398, 15534,  5068, 15784,  6515,\n",
      "         6126, 14003, 13055,   828,  2866,  1354,  6138,  4509, 15132,  9718,\n",
      "         6161, 11376, 13304, 13998,  9867,  9000, 15820,  1837, 12982,   547,\n",
      "        12055,  9983,   634, 11948, 14155,  8491,  3169, 11425,  9439,  8357,\n",
      "         4934,  9585, 14588,  3254,  3016, 15005,  5257,  7256, 11700,  6286,\n",
      "        15893,  7531, 10029, 12606,  3391,  6438, 12762, 15287, 11680,   687,\n",
      "        12752, 16282,  8115, 12869,  8202,  8783, 11694, 15866, 14184,  7468,\n",
      "          605, 14157,  4392,  1091, 11565,  4531,  8476,  4408, 16302, 16152,\n",
      "         8190, 14197, 10416,  8889,  9361,  3081,  9767, 12060,  2498,  8483,\n",
      "        15255,  7664, 15299,  4704,  6869,  6102, 11827, 11260,  4141,  8561,\n",
      "         3947,  2425,  6090,  4296,  9310, 13936,  1918, 10321,  2678,  4597,\n",
      "          458,  6475, 12434, 14117, 12405, 14485,  7442,  9888,  6127,  9681,\n",
      "         9073, 13077, 10597, 13433, 12115, 15229, 14701,  1543,  3136,   243,\n",
      "         9371, 14384,  1877, 15560, 15914,  6517,  1886,  1121, 10099,  5661,\n",
      "         7949, 14216, 10354,  5267, 15409,  8100,  2195, 11679,  5723, 11950,\n",
      "         1764, 12200, 10042,  5819, 10729, 11696,  7078,  5771,  8033, 16311,\n",
      "         2320,  6401,  5956,  6393, 13940,  7169, 11001,  9973,  8918, 11407,\n",
      "         7310,  6647,  7773, 11131,  3291, 11311,  9484,  4927,  7237,  5646,\n",
      "         1766,  3011,  7929, 13059,  1123,  2791,  3602,  4542, 10810,  4638,\n",
      "         9051, 14354, 15901,  2767,  3944, 15808, 16130, 11055, 11739,  7980,\n",
      "         2815,  2770, 14471, 13024, 10428,  1893,  1027, 12027,  7342, 16397,\n",
      "        14811,  9087, 12726, 12778, 11569,  1829, 11741,  2196, 14074,  1293,\n",
      "        14606,  3412, 13781, 11670,  6997,  1671,  9612, 15121, 10898,  7976,\n",
      "         5579,  8130,  1070,  4683,  5258,  7052,  1839, 14639,  3952, 10810,\n",
      "         2848, 14985,  7663,  4525,  7451,  2761,  2513,  8637, 14830, 13607,\n",
      "         9792, 14480,  5615, 11946, 13371,  9618,  4895,  2977, 11783,  6270,\n",
      "        13719, 14307, 15703,  9775,  8306,  9770, 13210,  6971,  5286,   507,\n",
      "         8795,  9061,  9104,  9662,  1816,  3696,  8589,  8161,  3312,  1033,\n",
      "         4363,  8141,  2499,  8097,  4527,  4851,  7814, 11654,   659, 15519,\n",
      "        15282,  7584,   995,  4721,  8465, 14003,   110, 15436, 15242, 13818,\n",
      "         5008, 16091, 15247, 11186,  8969, 11288,  3402, 12409,  9808, 14123,\n",
      "         8173, 13138, 12810, 12641,  8290,  1402,  2439, 12911,  4861, 12494,\n",
      "         7646, 15611, 10941,  6537,  9423,  9647, 13236,  6898, 15512, 14274,\n",
      "         7796,  3309,  5794,  4113, 13325, 12704, 14970,  1994, 10133,  8891,\n",
      "         2671, 14246, 14879,  6296,  2750,  6787,   534, 15468, 12977, 14665,\n",
      "         1820, 11364,   853,  2637,  5379, 12209, 15431,   470,  2541, 16108,\n",
      "        15323,  3355,  9340,  2969, 15196, 13781, 13518,  2323, 12986,  1342,\n",
      "        11124,  7389, 12320,  8098,  9995,  1919, 15630,  3704, 14200,  7564,\n",
      "         7947,  6909,   329,  7095,  1281,  5933,  5404,  7063,  6941, 13315,\n",
      "         5145,  8472,  3045,  3497,  1684,  3832,  1006,  6349,  8799,   692,\n",
      "         6663,  3288,  2557,  6116,   946,  9892, 11346, 12799, 12493, 11108,\n",
      "         2189,  4360, 16113, 15464, 14097, 13740,  7622,  6804, 13966, 13503,\n",
      "         7666, 11041,   850,  6898, 13055, 14516,  4245,  4177,  2012,  7534,\n",
      "         4274,  9192,  5733, 12805,    46,  4633, 10974,  7728,  8215,  2375,\n",
      "        10091,  1807, 10799, 16164, 13654,  3262,  5647,  9008, 11661,  3941,\n",
      "         9791, 16283, 13993,  7749,  8005, 16395,  5486,   612, 10210,  3231,\n",
      "         8582,  5298]), 'item': tensor([4604, 3585, 3167, 4692, 1993, 3451, 3956, 4214, 1228,  791, 1991, 3443,\n",
      "         193, 4244, 4347, 3558, 3963, 3865, 1983, 1202, 4229, 4300, 4615, 2694,\n",
      "        2123, 3225, 4610, 3622,  279,  847,  926,  150, 2126, 1570, 1986, 3020,\n",
      "        4593, 2833, 1530, 3096, 3536,  523,  446, 1106, 2520, 4660, 4234,  300,\n",
      "        1769, 4431, 2558, 1935, 2665, 1571, 3585, 1066, 4330, 1844, 2613, 2425,\n",
      "        3517, 4020,  426,  336, 3723,  687, 3077,  438, 3635, 3264, 3642, 1973,\n",
      "        4109, 3489,  466,  120, 4530, 4206, 4690, 1383, 3640, 1921, 1556, 3969,\n",
      "        1421, 1403, 4396, 3188, 2596, 1263, 2683, 1189, 3678, 4167,  276, 1544,\n",
      "         823,  132, 3077, 2547, 1721,  450, 2435, 1552,  291,  169, 1426, 1067,\n",
      "        3925, 4456, 2253, 3704, 3732, 2858, 2137, 2157, 1568, 2152,  398, 1831,\n",
      "        4621, 1571, 4720, 3265, 1865,  487,  266, 2597, 2854, 3443, 2336, 2817,\n",
      "         294,  631, 3913, 3011, 2263, 3965, 4182, 2107,  250, 1479,  167, 4270,\n",
      "        3089,  620, 4659, 3602, 4125,  825, 3486, 1223, 4710, 4071, 2384,  401,\n",
      "        4244, 2619, 1863, 1377,  345, 4123, 1129,   62, 3630,  805, 2294, 3205,\n",
      "         960,  653, 1572, 3540, 4443, 3865, 3504, 2972, 1623,  442, 3014, 4621,\n",
      "         445,  549, 3628,   82, 3972, 3052, 3138, 2000, 1178, 2713, 2694, 4587,\n",
      "        4239, 1039, 3265, 1924,  794, 1236, 1522,  684, 3256, 3072, 1481, 2032,\n",
      "        1335, 2722, 4311,   22, 3132, 1011, 2410, 2811, 3146, 4591, 3454, 1250,\n",
      "        4040, 3372, 4243, 3497, 1669,  450, 4656, 4607,  198, 2390, 3937, 2276,\n",
      "        2437,  763, 2294, 1182, 2003, 4241, 3726, 1806, 2275, 3255, 4653, 1810,\n",
      "         735, 3168, 4720, 4763,  887,   69,  158, 2456, 3040, 1883, 2187, 1079,\n",
      "        3327, 1083, 1175, 1976, 4076, 1371, 4666, 4357, 3517, 4024,  887, 3436,\n",
      "         447, 3761, 2727, 4018, 2308,  210,  934, 3945, 3451,  181, 2230,  763,\n",
      "        3505, 2881,    5, 4552,  592, 4634, 1603, 1817, 2548, 3065, 3188, 4297,\n",
      "        1396, 4124,  820, 3116, 2872, 3470,  921, 2660,  308, 4712,  220, 3326,\n",
      "        2111, 3042, 4107,  433, 4530, 4575, 4444, 4250, 4546, 2258, 2612, 1570,\n",
      "        2873, 3578,  363,  426, 3350,  469, 4029, 3001,  185,  970, 3517, 2455,\n",
      "        4466, 4528, 2465, 3275,   60, 2119,  975, 1981, 3740,  446, 4703,  803,\n",
      "        4516, 3812, 1635, 1044, 3048, 4616,  367, 1783,  832,  223, 4120, 1405,\n",
      "         308,  334, 3437, 3472, 2311, 4138, 4518, 4319, 3927,  154, 4117,  128,\n",
      "        2216, 3891,  851, 2912, 4401, 1021, 1410, 3265, 2109, 3352, 1500, 2783,\n",
      "        4355, 2020, 3799, 1246, 1839,  224, 4466,  554, 3557, 1795, 2596, 4471,\n",
      "        4450, 2707, 1954, 4759, 3133, 1883, 2253,  626, 2458, 3570, 4698, 1182,\n",
      "        3771, 3873, 3578, 3455, 1937, 2163, 2613, 2694, 1298, 1885, 4118, 1138,\n",
      "        3089, 4179, 1229, 3704, 3089,  371, 2770, 3585, 4105, 1104, 2868, 4162,\n",
      "        2712, 2135, 3902, 1580, 3441,  730, 3071, 2068, 2025, 4746, 4781, 1903,\n",
      "         677,  149, 4352, 4650, 4090, 4180, 2003,  274, 3205, 3017, 3089, 1711,\n",
      "        1209, 4394, 3089, 3983, 2543, 3353, 3513, 3517, 3578, 4762,  575,  703,\n",
      "        2615, 3845, 4330, 2499, 1319, 3922, 3454, 3269, 4689, 3726, 4400, 2449,\n",
      "         368, 2841, 1547, 3494, 1173,  427, 3444, 3899, 4610, 4020, 4066, 3910,\n",
      "        1555, 4685, 3830,  426, 1495, 1651, 2001, 4307, 1420, 1776, 3926,  958,\n",
      "        4378, 1307, 4120, 4364, 4302, 4531, 3678, 4710, 1572, 2152, 2922, 1145,\n",
      "        1264, 3287, 1791, 1177,  266, 3634, 2828, 2811]), 'rating': tensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 0.]), 'item_sequence': tensor([[  -1,   -1,   -1,  ...,   -1,   -1,   -1],\n",
      "        [  -1,   -1,   -1,  ..., 3168, 1197, 3350],\n",
      "        [  -1,   -1, 3650,  ..., 2146, 2272,  707],\n",
      "        ...,\n",
      "        [  -1,   -1,   -1,  ...,  548,  954, 1042],\n",
      "        [  -1,   -1,   -1,  ..., 2942, 3744, 3891],\n",
      "        [  -1,   -1,   -1,  ..., 2655, 4471,  799]], dtype=torch.int32)}\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import lightning\n",
    "print(lightning.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-26 20:38:58.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.sequence.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mStart token used: 4816, Padding token used: 4817\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SequenceRatingPrediction(\n",
      "  (item_embedding): Embedding(4818, 256, padding_idx=4817)\n",
      "  (encoder_layer): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.3, inplace=False)\n",
      "    (dropout2): Dropout(p=0.3, inplace=False)\n",
      "    (activation): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.3, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (dropout2): Dropout(p=0.3, inplace=False)\n",
      "        (activation): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (prelu1): PReLU(num_parameters=1)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (metadata_embedding): Embedding(4819, 384)\n",
      "  (metadata_fc): Linear(in_features=384, out_features=32, bias=True)\n",
      "  (metadata_prelu): PReLU(num_parameters=1)\n",
      "  (item_tower_fc): Linear(in_features=288, out_features=256, bias=True)\n",
      "  (user_embedding): Embedding(16407, 32)\n",
      "  (user_tower_fc): Linear(in_features=288, out_features=256, bias=True)\n",
      "  (final_fc): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (score_fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:654: UserWarning:\n",
      "\n",
      "Checkpoint directory C:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\data\\pruning-sequence-modelling\\attn-256-dim-bce-prelu\\checkpoints exists and is not empty.\n",
      "\n",
      "\n",
      "  | Name               | Type                     | Params | Mode \n",
      "------------------------------------------------------------------------\n",
      "0 | model              | SequenceRatingPrediction | 4.7 M  | train\n",
      "1 | val_roc_auc_metric | BinaryAUROC              | 0      | train\n",
      "2 | val_pr_auc_metric  | BinaryAveragePrecision   | 0      | train\n",
      "------------------------------------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "1.9 M     Non-trainable params\n",
      "4.7 M     Total params\n",
      "18.769    Total estimated model params size (MB)\n",
      "38        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd56c043a7b44d3a888a6e909032e8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: PossibleUserWarning:\n",
      "\n",
      "The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: PossibleUserWarning:\n",
      "\n",
      "The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:310: PossibleUserWarning:\n",
      "\n",
      "The number of training batches (49) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1069eb09cc64b8ea1792e5e1742b8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921ca9a76221499fa2b634c6eca02828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run attn-256-dim-bce-prelu at: http://138.2.61.6:5002/#/experiments/11/runs/0b40d22ce6794d41a5398983a7a9b669\n",
      "🧪 View experiment at: http://138.2.61.6:5002/#/experiments/11\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_roc_auc\", patience=args.early_stopping_patience, mode=\"max\", verbose=False, min_delta=0.001\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{args.notebook_persit_dp}/checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_roc_auc\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "model = init_model(n_users, n_items, \n",
    "                   args.embedding_dim, \n",
    "                   args.dropout, \n",
    "                   item_embedding=skipgram_item_embedding,\n",
    "                   user_embedding_dim=args.user_embedding_dim,\n",
    "                   use_user_embedding=args.use_user_embedding,\n",
    "                   use_metadata=args.use_metadata,\n",
    "                   metadata_embedding=metadata_embedding_layer,\n",
    "                   metadata_embedding_dim=args.metadata_embedding_dim,\n",
    "                   metadata_fc_dim=args.metadata_fc_dim,)\n",
    "\n",
    "print(f\"Model: {model}\")\n",
    "lit_model = SeqModellingLitModule(\n",
    "    model,\n",
    "    learning_rate=args.learning_rate,\n",
    "    l2_reg=args.l2_reg,\n",
    "    log_dir=args.notebook_persit_dp,\n",
    "    accelerator=args.device,\n",
    "    idm= idm\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persit_dp}/logs/run\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    max_epochs=args.max_epochs,\n",
    "    callbacks=[early_stopping, checkpoint_callback],\n",
    "    logger=args._mlf_logger if args.log_to_mlflow else None,\n",
    "    # limit_train_batches=0.1    \n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    "    \n",
    ")\n",
    "\n",
    "# Change the library as a workaround for the issue in the latest Lightning release\n",
    "#https://github.com/Lightning-AI/pytorch-lightning/pull/20669/commits/429f732a0528c558e701da7ec01e51c1e2e4f32e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-26 20:39:18.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1mLoading best checkpoint from C:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\data\\pruning-sequence-modelling\\attn-256-dim-bce-prelu\\checkpoints\\best-checkpoint-v5.ckpt...\u001b[0m\n",
      "\u001b[32m2025-06-26 20:39:18.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.sequence.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mStart token used: 4816, Padding token used: 4817\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Loading best checkpoint from {checkpoint_callback.best_model_path}...\")\n",
    "args.best_checkpoint_path = checkpoint_callback.best_model_path\n",
    "\n",
    "best_trainer = SeqModellingLitModule.load_from_checkpoint(\n",
    "    checkpoint_path=checkpoint_callback.best_model_path,\n",
    "    model=init_model(n_users, \n",
    "                     n_items, \n",
    "                     args.embedding_dim, \n",
    "                     args.dropout, \n",
    "                     item_embedding=skipgram_item_embedding,\n",
    "                     user_embedding_dim=args.user_embedding_dim,\n",
    "                     use_user_embedding=args.use_user_embedding,\n",
    "                     use_metadata=args.use_metadata,\n",
    "                     metadata_embedding=metadata_embedding_layer,\n",
    "                     metadata_embedding_dim=args.metadata_embedding_dim,\n",
    "                     metadata_fc_dim=args.metadata_fc_dim,),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceRatingPrediction(\n",
       "  (item_embedding): Embedding(4818, 256, padding_idx=4817)\n",
       "  (encoder_layer): TransformerEncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.3, inplace=False)\n",
       "    (dropout2): Dropout(p=0.3, inplace=False)\n",
       "    (activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "        (activation): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (prelu1): PReLU(num_parameters=1)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (metadata_embedding): Embedding(4819, 384)\n",
       "  (metadata_fc): Linear(in_features=384, out_features=32, bias=True)\n",
       "  (metadata_prelu): PReLU(num_parameters=1)\n",
       "  (item_tower_fc): Linear(in_features=288, out_features=256, bias=True)\n",
       "  (user_embedding): Embedding(16407, 32)\n",
       "  (user_tower_fc): Linear(in_features=288, out_features=256, bias=True)\n",
       "  (final_fc): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (score_fc): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = best_trainer.model.to(args.device)\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_recs_df = val_df.sort_values(by=args.timestamp_col).drop_duplicates(subset=[args.user_col], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.start_run(run_id = trainer.logger.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_user_indices = val_df[\"user_indice\"].values\n",
    "val_item_indices = val_df[\"item_indice\"].values\n",
    "val_item_sequences = val_df[\"item_sequence\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = torch.tensor(val_user_indices, device=args.device)\n",
    "item_sequences = torch.tensor(val_item_sequences, device=args.device)\n",
    "items = torch.tensor(val_item_indices, device=args.device)\n",
    "classifications = best_model.predict(users, item_sequences, items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6958, 1])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_classification_df = val_df.assign(\n",
    "    classification_proba=classifications.cpu().detach().numpy(),\n",
    "    label=lambda df: df[args.rating_col].gt(0).astype(int),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "      <th>classification_proba</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260331</th>\n",
       "      <td>AGMJWWTZ6HMM2FBRDLFW2CWMV5DQ</td>\n",
       "      <td>B00E0ISVLI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-07-18 15:44:29.739</td>\n",
       "      <td>10483</td>\n",
       "      <td>2563</td>\n",
       "      <td>[-1, 2906, 3011, 4674, 4593, 4755, 3810, 3921,...</td>\n",
       "      <td>0.502384</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259198</th>\n",
       "      <td>AE3XVOCHEO5MTDIAIET5BZS26AJA</td>\n",
       "      <td>B07GPGVYGX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-03-12 03:28:00.854</td>\n",
       "      <td>254</td>\n",
       "      <td>3381</td>\n",
       "      <td>[-1, -1, -1, -1, 1188, 1510, 4399, 3089, 2290,...</td>\n",
       "      <td>0.418402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258841</th>\n",
       "      <td>AESPJW3GNHXNJNW5CYV7PTEX44MQ</td>\n",
       "      <td>B07GZFM1ZM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-02-09 16:08:20.512</td>\n",
       "      <td>3190</td>\n",
       "      <td>921</td>\n",
       "      <td>[-1, -1, -1, -1, -1, 2569, 2742, 2855, 2351, 346]</td>\n",
       "      <td>0.498142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id parent_asin  rating  \\\n",
       "260331  AGMJWWTZ6HMM2FBRDLFW2CWMV5DQ  B00E0ISVLI     0.0   \n",
       "259198  AE3XVOCHEO5MTDIAIET5BZS26AJA  B07GPGVYGX     0.0   \n",
       "258841  AESPJW3GNHXNJNW5CYV7PTEX44MQ  B07GZFM1ZM     0.0   \n",
       "\n",
       "                     timestamp  user_indice  item_indice  \\\n",
       "260331 2021-07-18 15:44:29.739        10483         2563   \n",
       "259198 2021-03-12 03:28:00.854          254         3381   \n",
       "258841 2021-02-09 16:08:20.512         3190          921   \n",
       "\n",
       "                                            item_sequence  \\\n",
       "260331  [-1, 2906, 3011, 4674, 4593, 4755, 3810, 3921,...   \n",
       "259198  [-1, -1, -1, -1, 1188, 1510, 4399, 3089, 2290,...   \n",
       "258841  [-1, -1, -1, -1, -1, 2569, 2742, 2855, 2351, 346]   \n",
       "\n",
       "        classification_proba  label  \n",
       "260331              0.502384      0  \n",
       "259198              0.418402      0  \n",
       "258841              0.498142      0  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classification_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report = log_classification_metrics(\n",
    "    args,\n",
    "    eval_classification_df,\n",
    "    target_col=\"label\",\n",
    "    prediction_col=\"classification_proba\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258263</th>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B004FV4ROA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-12-27 00:30:31.146</td>\n",
       "      <td>11295</td>\n",
       "      <td>3051</td>\n",
       "      <td>[1715, 2537, 3743, 506, 4490, 3479, 3908, 2723...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258264</th>\n",
       "      <td>AEHS7YR7BGGWMZS24H5UR5IP46HQ</td>\n",
       "      <td>B08F1P3BCC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-12-27 01:44:52.242</td>\n",
       "      <td>1784</td>\n",
       "      <td>3316</td>\n",
       "      <td>[-1, -1, -1, -1, -1, 3382, 4330, 423, 3167, 2677]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258265</th>\n",
       "      <td>AGAVHCK42EGMVS7DGPRX6HBCUCNQ</td>\n",
       "      <td>B09Q3NR84W</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-12-27 02:25:48.357</td>\n",
       "      <td>9042</td>\n",
       "      <td>32</td>\n",
       "      <td>[-1, -1, -1, -1, 3104, 1416, 3743, 2694, 3612,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127395</th>\n",
       "      <td>AEFVBMCJAFNULDI5V2CKKTBCPURA</td>\n",
       "      <td>B07N1L5HX1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-12-27 02:32:15.171</td>\n",
       "      <td>1542</td>\n",
       "      <td>3550</td>\n",
       "      <td>[-1, -1, -1, -1, -1, 1320, 2162, 2472, 2694, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127396</th>\n",
       "      <td>AGLXMKHBLTBNT3X2CLBAPW6QUTQA</td>\n",
       "      <td>B0BB6Y5N3M</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-12-27 03:37:22.772</td>\n",
       "      <td>10418</td>\n",
       "      <td>4471</td>\n",
       "      <td>[341, 3803, 4431, 1067, 4530, 4018, 2688, 4365...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261735</th>\n",
       "      <td>AGGDNWGN3NDJ2DI5CBSFOMUAM6XA</td>\n",
       "      <td>B083YHS7SV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-18 19:43:25.492</td>\n",
       "      <td>9711</td>\n",
       "      <td>2513</td>\n",
       "      <td>[-1, -1, -1, -1, 1019, 754, 2059, 413, 4262, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130866</th>\n",
       "      <td>AEKUF6AOVWDWFYOKPWO2CV72PEDQ</td>\n",
       "      <td>B07QN33986</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-02-19 01:32:51.519</td>\n",
       "      <td>2171</td>\n",
       "      <td>3626</td>\n",
       "      <td>[-1, -1, 2627, 4216, 4743, 1945, 2355, 1831, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130867</th>\n",
       "      <td>AFBTD25HPE4BE4LUFV3DTI2E2N2A</td>\n",
       "      <td>B07TMJ8S5Z</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-02-19 16:49:57.966</td>\n",
       "      <td>5159</td>\n",
       "      <td>3699</td>\n",
       "      <td>[-1, -1, -1, -1, 2260, 3517, 3609, 3495, 3625,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261740</th>\n",
       "      <td>AHLN6GKTKZE22AON34YAQXTGK63A</td>\n",
       "      <td>B0C682GZ5X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-19 17:28:55.519</td>\n",
       "      <td>14550</td>\n",
       "      <td>2383</td>\n",
       "      <td>[-1, -1, -1, -1, -1, 1812, 4165, 4575, 4807, 374]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261741</th>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B091K4WYD1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-19 22:08:53.253</td>\n",
       "      <td>2446</td>\n",
       "      <td>2502</td>\n",
       "      <td>[2677, 1610, 2694, 3695, 4429, 3602, 4569, 365...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2424 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id parent_asin  rating  \\\n",
       "258263  AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B004FV4ROA     0.0   \n",
       "258264  AEHS7YR7BGGWMZS24H5UR5IP46HQ  B08F1P3BCC     0.0   \n",
       "258265  AGAVHCK42EGMVS7DGPRX6HBCUCNQ  B09Q3NR84W     0.0   \n",
       "127395  AEFVBMCJAFNULDI5V2CKKTBCPURA  B07N1L5HX1     5.0   \n",
       "127396  AGLXMKHBLTBNT3X2CLBAPW6QUTQA  B0BB6Y5N3M     5.0   \n",
       "...                              ...         ...     ...   \n",
       "261735  AGGDNWGN3NDJ2DI5CBSFOMUAM6XA  B083YHS7SV     0.0   \n",
       "130866  AEKUF6AOVWDWFYOKPWO2CV72PEDQ  B07QN33986     5.0   \n",
       "130867  AFBTD25HPE4BE4LUFV3DTI2E2N2A  B07TMJ8S5Z     5.0   \n",
       "261740  AHLN6GKTKZE22AON34YAQXTGK63A  B0C682GZ5X     0.0   \n",
       "261741  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B091K4WYD1     0.0   \n",
       "\n",
       "                     timestamp  user_indice  item_indice  \\\n",
       "258263 2020-12-27 00:30:31.146        11295         3051   \n",
       "258264 2020-12-27 01:44:52.242         1784         3316   \n",
       "258265 2020-12-27 02:25:48.357         9042           32   \n",
       "127395 2020-12-27 02:32:15.171         1542         3550   \n",
       "127396 2020-12-27 03:37:22.772        10418         4471   \n",
       "...                        ...          ...          ...   \n",
       "261735 2022-02-18 19:43:25.492         9711         2513   \n",
       "130866 2022-02-19 01:32:51.519         2171         3626   \n",
       "130867 2022-02-19 16:49:57.966         5159         3699   \n",
       "261740 2022-02-19 17:28:55.519        14550         2383   \n",
       "261741 2022-02-19 22:08:53.253         2446         2502   \n",
       "\n",
       "                                            item_sequence  \n",
       "258263  [1715, 2537, 3743, 506, 4490, 3479, 3908, 2723...  \n",
       "258264  [-1, -1, -1, -1, -1, 3382, 4330, 423, 3167, 2677]  \n",
       "258265  [-1, -1, -1, -1, 3104, 1416, 3743, 2694, 3612,...  \n",
       "127395  [-1, -1, -1, -1, -1, 1320, 2162, 2472, 2694, 3...  \n",
       "127396  [341, 3803, 4431, 1067, 4530, 4018, 2688, 4365...  \n",
       "...                                                   ...  \n",
       "261735  [-1, -1, -1, -1, 1019, 754, 2059, 413, 4262, 3...  \n",
       "130866  [-1, -1, 2627, 4216, 4743, 1945, 2355, 1831, 9...  \n",
       "130867  [-1, -1, -1, -1, 2260, 3517, 3609, 3495, 3625,...  \n",
       "261740  [-1, -1, -1, -1, -1, 1812, 4165, 4575, 4807, 374]  \n",
       "261741  [2677, 1610, 2694, 3695, 4429, 3602, 4569, 365...  \n",
       "\n",
       "[2424 rows x 7 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_recs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bee873ad784f0dbd652f353840a19b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating recommendations:   0%|          | 0/364964 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[138]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m recommendations = \u001b[43mbest_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecommend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_recs_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser_indice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_recs_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mitem_sequence\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtop_K\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\..\\src\\algo\\sequence\\model.py:327\u001b[39m, in \u001b[36mSequenceRatingPrediction.recommend\u001b[39m\u001b[34m(self, users, item_sequences, k, batch_size)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# Predict scores for the batch\u001b[39;00m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_metadata \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metadata_embedding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     batch_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_users\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_items\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    329\u001b[39m     batch_scores = \u001b[38;5;28mself\u001b[39m.predict(batch_users, batch_sequences, batch_items)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\..\\src\\algo\\sequence\\model.py:264\u001b[39m, in \u001b[36mSequenceRatingPrediction.predict\u001b[39m\u001b[34m(self, user, item_sequence, target_item, target_metadata)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, user, item_sequence, target_item, target_metadata=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    252\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[33;03m    Predict the rating for a specific user and item sequence using the forward method\u001b[39;00m\n\u001b[32m    254\u001b[39m \u001b[33;03m    and applying a Sigmoid function to the output.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    262\u001b[39m \u001b[33;03m        torch.Tensor: Predicted rating after applying Sigmoid activation.\u001b[39;00m\n\u001b[32m    263\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     output_rating = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_item\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_item\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m     \u001b[38;5;66;03m# Apply sigmoid activation to the output\u001b[39;00m\n\u001b[32m    266\u001b[39m     output_rating = nn.Sigmoid()(output_rating)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\..\\src\\algo\\sequence\\model.py:169\u001b[39m, in \u001b[36mSequenceRatingPrediction.forward\u001b[39m\u001b[34m(self, user_ids, input_seq, target_item, target_metadata)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# Embed input sequence\u001b[39;00m\n\u001b[32m    167\u001b[39m embedded_seq = \u001b[38;5;28mself\u001b[39m.item_embedding(input_seq)  \u001b[38;5;66;03m# Shape: [batch_size, seq_len, embedding_dim]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m hidden_state = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43membedded_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Shape: [batch_size, seq_len, embedding_dim]\u001b[39;00m\n\u001b[32m    170\u001b[39m \u001b[38;5;66;03m# Get the last hidden state\u001b[39;00m\n\u001b[32m    171\u001b[39m hidden_state = hidden_state[:, -\u001b[32m1\u001b[39m, :]  \u001b[38;5;66;03m# Shape: [batch_size, embedding_dim]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:517\u001b[39m, in \u001b[36mTransformerEncoder.forward\u001b[39m\u001b[34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    514\u001b[39m is_causal = _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[32m    516\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     output = \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[32m    525\u001b[39m     output = output.to_padded_tensor(\u001b[32m0.0\u001b[39m, src.size())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:920\u001b[39m, in \u001b[36mTransformerEncoderLayer.forward\u001b[39m\u001b[34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    916\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m._ff_block(\u001b[38;5;28mself\u001b[39m.norm2(x))\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    918\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm1(\n\u001b[32m    919\u001b[39m         x\n\u001b[32m--> \u001b[39m\u001b[32m920\u001b[39m         + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    921\u001b[39m     )\n\u001b[32m    922\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm2(x + \u001b[38;5;28mself\u001b[39m._ff_block(x))\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:934\u001b[39m, in \u001b[36mTransformerEncoderLayer._sa_block\u001b[39m\u001b[34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    927\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sa_block\u001b[39m(\n\u001b[32m    928\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    929\u001b[39m     x: Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    932\u001b[39m     is_causal: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    933\u001b[39m ) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m934\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m    943\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dropout1(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1373\u001b[39m, in \u001b[36mMultiheadAttention.forward\u001b[39m\u001b[34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   1347\u001b[39m     attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[32m   1348\u001b[39m         query,\n\u001b[32m   1349\u001b[39m         key,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1370\u001b[39m         is_causal=is_causal,\n\u001b[32m   1371\u001b[39m     )\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1373\u001b[39m     attn_output, attn_output_weights = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m), attn_output_weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\functional.py:6230\u001b[39m, in \u001b[36mmulti_head_attention_forward\u001b[39m\u001b[34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   6226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_separate_proj_weight:\n\u001b[32m   6227\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m   6228\u001b[39m         in_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   6229\u001b[39m     ), \u001b[33m\"\u001b[39m\u001b[33muse_separate_proj_weight is False but in_proj_weight is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m6230\u001b[39m     q, k, v = \u001b[43m_in_projection_packed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6231\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6232\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m   6233\u001b[39m         q_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   6234\u001b[39m     ), \u001b[33m\"\u001b[39m\u001b[33muse_separate_proj_weight is True but q_proj_weight is None\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\functional.py:5614\u001b[39m, in \u001b[36m_in_projection_packed\u001b[39m\u001b[34m(q, k, v, w, b)\u001b[39m\n\u001b[32m   5611\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mis\u001b[39;00m v:\n\u001b[32m   5612\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m q \u001b[38;5;129;01mis\u001b[39;00m k:\n\u001b[32m   5613\u001b[39m         \u001b[38;5;66;03m# self-attention\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5614\u001b[39m         proj = \u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5615\u001b[39m         \u001b[38;5;66;03m# reshape to 3, E and not E, 3 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[39;00m\n\u001b[32m   5616\u001b[39m         proj = (\n\u001b[32m   5617\u001b[39m             proj.unflatten(-\u001b[32m1\u001b[39m, (\u001b[32m3\u001b[39m, E))\n\u001b[32m   5618\u001b[39m             .unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m   5621\u001b[39m             .contiguous()\n\u001b[32m   5622\u001b[39m         )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "recommendations = best_model.recommend(\n",
    "    torch.tensor(val_recs_df[\"user_indice\"].values, device=args.device),\n",
    "    torch.tensor(val_recs_df[\"item_sequence\"].values.tolist(), device=args.device),\n",
    "    k=args.top_K,\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_indice</th>\n",
       "      <th>recommendation</th>\n",
       "      <th>score</th>\n",
       "      <th>rec_ranking</th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11295</td>\n",
       "      <td>3032</td>\n",
       "      <td>0.834206</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B074F3M2W8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11295</td>\n",
       "      <td>3188</td>\n",
       "      <td>0.830017</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B0791TX5P5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11295</td>\n",
       "      <td>3472</td>\n",
       "      <td>0.829827</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B07HZLHPKP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11295</td>\n",
       "      <td>3915</td>\n",
       "      <td>0.829290</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B08D7JPKLZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11295</td>\n",
       "      <td>3983</td>\n",
       "      <td>0.825969</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B08N5TC2Z3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242395</th>\n",
       "      <td>2446</td>\n",
       "      <td>3200</td>\n",
       "      <td>0.825623</td>\n",
       "      <td>96.0</td>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B0795DP124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242396</th>\n",
       "      <td>2446</td>\n",
       "      <td>2998</td>\n",
       "      <td>0.824843</td>\n",
       "      <td>97.0</td>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B072KGYYKX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242397</th>\n",
       "      <td>2446</td>\n",
       "      <td>3476</td>\n",
       "      <td>0.824502</td>\n",
       "      <td>98.0</td>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B07J2FGZSM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242398</th>\n",
       "      <td>2446</td>\n",
       "      <td>3659</td>\n",
       "      <td>0.823378</td>\n",
       "      <td>99.0</td>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B07RR6HQKX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242399</th>\n",
       "      <td>2446</td>\n",
       "      <td>3381</td>\n",
       "      <td>0.822749</td>\n",
       "      <td>100.0</td>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B07F4P3JH7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242400 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_indice  recommendation     score  rec_ranking  \\\n",
       "0             11295            3032  0.834206          1.0   \n",
       "1             11295            3188  0.830017          2.0   \n",
       "2             11295            3472  0.829827          3.0   \n",
       "3             11295            3915  0.829290          4.0   \n",
       "4             11295            3983  0.825969          5.0   \n",
       "...             ...             ...       ...          ...   \n",
       "242395         2446            3200  0.825623         96.0   \n",
       "242396         2446            2998  0.824843         97.0   \n",
       "242397         2446            3476  0.824502         98.0   \n",
       "242398         2446            3659  0.823378         99.0   \n",
       "242399         2446            3381  0.822749        100.0   \n",
       "\n",
       "                             user_id parent_asin  \n",
       "0       AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B074F3M2W8  \n",
       "1       AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B0791TX5P5  \n",
       "2       AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B07HZLHPKP  \n",
       "3       AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B08D7JPKLZ  \n",
       "4       AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B08N5TC2Z3  \n",
       "...                              ...         ...  \n",
       "242395  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B0795DP124  \n",
       "242396  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B072KGYYKX  \n",
       "242397  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B07J2FGZSM  \n",
       "242398  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B07RR6HQKX  \n",
       "242399  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B07F4P3JH7  \n",
       "\n",
       "[242400 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_df = pd.DataFrame(recommendations).pipe(\n",
    "    create_rec_df, idm, args.user_col, args.item_col\n",
    ")\n",
    "recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128912</th>\n",
       "      <td>AG2EMAD6UILFF4ITMMKH2NEFTYHA</td>\n",
       "      <td>B0BZJGGX2T</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127943</th>\n",
       "      <td>AHPI7N36W4JJYOAA6MBAGWTDF3FA</td>\n",
       "      <td>B072MKFNV6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129406</th>\n",
       "      <td>AGOBLEZGF5OSPDVTIMA3DPWAENGA</td>\n",
       "      <td>B07H65KP63</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130173</th>\n",
       "      <td>AFXRWTDGQJIDOTGMCIZKH5QPK5KA</td>\n",
       "      <td>B00PKTU83U</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128534</th>\n",
       "      <td>AHWDVLU5PTXMLD6PSJ2Z5Q3JP4OA</td>\n",
       "      <td>B0719SNR5N</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386737</th>\n",
       "      <td>AEN2KQVSR5TWRXNQS3OTFT4EZQCA</td>\n",
       "      <td>B0BRT7XFM5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388052</th>\n",
       "      <td>AFKERAMSXU4MWO3H53R7DEFOHUVQ</td>\n",
       "      <td>B07G5YXYFL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388051</th>\n",
       "      <td>AFKERAMSXU4MWO3H53R7DEFOHUVQ</td>\n",
       "      <td>B07G5YXYFL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387885</th>\n",
       "      <td>AFKERAMSXU4MWO3H53R7DEFOHUVQ</td>\n",
       "      <td>B07ZZVX1F2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387886</th>\n",
       "      <td>AFKERAMSXU4MWO3H53R7DEFOHUVQ</td>\n",
       "      <td>B07ZZVX1F2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10437 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id parent_asin  rating  rating_rank\n",
       "128912  AG2EMAD6UILFF4ITMMKH2NEFTYHA  B0BZJGGX2T     5.0          1.0\n",
       "127943  AHPI7N36W4JJYOAA6MBAGWTDF3FA  B072MKFNV6     4.0          1.0\n",
       "129406  AGOBLEZGF5OSPDVTIMA3DPWAENGA  B07H65KP63     5.0          1.0\n",
       "130173  AFXRWTDGQJIDOTGMCIZKH5QPK5KA  B00PKTU83U     5.0          1.0\n",
       "128534  AHWDVLU5PTXMLD6PSJ2Z5Q3JP4OA  B0719SNR5N     3.0          1.0\n",
       "...                              ...         ...     ...          ...\n",
       "386737  AEN2KQVSR5TWRXNQS3OTFT4EZQCA  B0BRT7XFM5     0.0         27.0\n",
       "388052  AFKERAMSXU4MWO3H53R7DEFOHUVQ  B07G5YXYFL     0.0         27.0\n",
       "388051  AFKERAMSXU4MWO3H53R7DEFOHUVQ  B07G5YXYFL     0.0         28.0\n",
       "387885  AFKERAMSXU4MWO3H53R7DEFOHUVQ  B07ZZVX1F2     0.0         29.0\n",
       "387886  AFKERAMSXU4MWO3H53R7DEFOHUVQ  B07ZZVX1F2     0.0         30.0\n",
       "\n",
       "[10437 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = create_label_df(\n",
    "    val_df,\n",
    "    user_col=args.user_col,\n",
    "    item_col=args.item_col,\n",
    "    rating_col=args.rating_col,\n",
    "    timestamp_col=args.timestamp_col,\n",
    ")\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_indice</th>\n",
       "      <th>recommendation</th>\n",
       "      <th>score</th>\n",
       "      <th>rec_ranking</th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3251.0</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>1</td>\n",
       "      <td>AE24AB4DW5KYK3F5DYOT5VPW2VLA</td>\n",
       "      <td>B07BPKL2D2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4669.0</td>\n",
       "      <td>0.908320</td>\n",
       "      <td>2</td>\n",
       "      <td>AE24AB4DW5KYK3F5DYOT5VPW2VLA</td>\n",
       "      <td>B0BXP3P132</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4365.0</td>\n",
       "      <td>0.907467</td>\n",
       "      <td>3</td>\n",
       "      <td>AE24AB4DW5KYK3F5DYOT5VPW2VLA</td>\n",
       "      <td>B09ZMQWGCG</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4785.0</td>\n",
       "      <td>0.904956</td>\n",
       "      <td>4</td>\n",
       "      <td>AE24AB4DW5KYK3F5DYOT5VPW2VLA</td>\n",
       "      <td>B0C6PRR41P</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>0.904170</td>\n",
       "      <td>5</td>\n",
       "      <td>AE24AB4DW5KYK3F5DYOT5VPW2VLA</td>\n",
       "      <td>B07CG2PGY6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252360</th>\n",
       "      <td>16403.0</td>\n",
       "      <td>3550.0</td>\n",
       "      <td>0.787922</td>\n",
       "      <td>99</td>\n",
       "      <td>AHZZM7BCJAF2UEMMBHZCLXBB2SVA</td>\n",
       "      <td>B07N1L5HX1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252390</th>\n",
       "      <td>16403.0</td>\n",
       "      <td>3903.0</td>\n",
       "      <td>0.787658</td>\n",
       "      <td>100</td>\n",
       "      <td>AHZZM7BCJAF2UEMMBHZCLXBB2SVA</td>\n",
       "      <td>B08BZSCHZ3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252328</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>AHZZM7BCJAF2UEMMBHZCLXBB2SVA</td>\n",
       "      <td>B075QC3TZY</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252329</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>AHZZM7BCJAF2UEMMBHZCLXBB2SVA</td>\n",
       "      <td>B075QC3TZY</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252330</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>AHZZM7BCJAF2UEMMBHZCLXBB2SVA</td>\n",
       "      <td>B075QC3TZY</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252421 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_indice  recommendation     score  rec_ranking  \\\n",
       "26              8.0          3251.0  0.912598            1   \n",
       "96              8.0          4669.0  0.908320            2   \n",
       "72              8.0          4365.0  0.907467            3   \n",
       "102             8.0          4785.0  0.904956            4   \n",
       "27              8.0          3300.0  0.904170            5   \n",
       "...             ...             ...       ...          ...   \n",
       "252360      16403.0          3550.0  0.787922           99   \n",
       "252390      16403.0          3903.0  0.787658          100   \n",
       "252328          NaN             NaN       NaN          101   \n",
       "252329          NaN             NaN       NaN          101   \n",
       "252330          NaN             NaN       NaN          101   \n",
       "\n",
       "                             user_id parent_asin  rating  rating_rank  \n",
       "26      AE24AB4DW5KYK3F5DYOT5VPW2VLA  B07BPKL2D2       0          NaN  \n",
       "96      AE24AB4DW5KYK3F5DYOT5VPW2VLA  B0BXP3P132       0          NaN  \n",
       "72      AE24AB4DW5KYK3F5DYOT5VPW2VLA  B09ZMQWGCG       0          NaN  \n",
       "102     AE24AB4DW5KYK3F5DYOT5VPW2VLA  B0C6PRR41P       0          NaN  \n",
       "27      AE24AB4DW5KYK3F5DYOT5VPW2VLA  B07CG2PGY6       0          NaN  \n",
       "...                              ...         ...     ...          ...  \n",
       "252360  AHZZM7BCJAF2UEMMBHZCLXBB2SVA  B07N1L5HX1       0          NaN  \n",
       "252390  AHZZM7BCJAF2UEMMBHZCLXBB2SVA  B08BZSCHZ3       0          NaN  \n",
       "252328  AHZZM7BCJAF2UEMMBHZCLXBB2SVA  B075QC3TZY       1          1.0  \n",
       "252329  AHZZM7BCJAF2UEMMBHZCLXBB2SVA  B075QC3TZY       0          2.0  \n",
       "252330  AHZZM7BCJAF2UEMMBHZCLXBB2SVA  B075QC3TZY       0          3.0  \n",
       "\n",
       "[252421 rows x 8 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = merge_recs_with_target(\n",
    "    recommendations_df,\n",
    "    label_df,\n",
    "    k=args.top_K,\n",
    "    user_col=args.user_col,\n",
    "    item_col=args.item_col,\n",
    "    rating_col=args.rating_col,\n",
    ")\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_report = log_ranking_metrics(args, eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run attn-256-dim-bce-prelu at: http://138.2.61.6:5002/#/experiments/11/runs/da482c273d6249f89f5573cbe3bfc997\n",
      "🧪 View experiment at: http://138.2.61.6:5002/#/experiments/11\n"
     ]
    },
    {
     "ename": "RestException",
     "evalue": "INVALID_PARAMETER_VALUE: The run da482c273d6249f89f5573cbe3bfc997 must be in the 'active' state. Current state is deleted.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRestException\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[100]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:519\u001b[39m, in \u001b[36mend_run\u001b[39m\u001b[34m(status)\u001b[39m\n\u001b[32m    517\u001b[39m last_active_run_id = run.info.run_id\n\u001b[32m    518\u001b[39m _last_active_run_id.set(last_active_run_id)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_terminated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_active_run_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m last_active_run_id \u001b[38;5;129;01min\u001b[39;00m run_id_to_system_metrics_monitor:\n\u001b[32m    521\u001b[39m     system_metrics_monitor = run_id_to_system_metrics_monitor.pop(last_active_run_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\mlflow\\tracking\\client.py:3351\u001b[39m, in \u001b[36mMlflowClient.set_terminated\u001b[39m\u001b[34m(self, run_id, status, end_time)\u001b[39m\n\u001b[32m   3306\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_terminated\u001b[39m(\n\u001b[32m   3307\u001b[39m     \u001b[38;5;28mself\u001b[39m, run_id: \u001b[38;5;28mstr\u001b[39m, status: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m, end_time: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3308\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3309\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Set a run's status to terminated.\u001b[39;00m\n\u001b[32m   3310\u001b[39m \n\u001b[32m   3311\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3349\u001b[39m \n\u001b[32m   3350\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3351\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tracking_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_terminated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:1030\u001b[39m, in \u001b[36mTrackingServiceClient.set_terminated\u001b[39m\u001b[34m(self, run_id, status, end_time)\u001b[39m\n\u001b[32m   1028\u001b[39m \u001b[38;5;28mself\u001b[39m.store.shut_down_async_logging()\n\u001b[32m   1029\u001b[39m \u001b[38;5;28mself\u001b[39m._log_url(run_id)\n\u001b[32m-> \u001b[39m\u001b[32m1030\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_run_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_status\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRunStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m    \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:191\u001b[39m, in \u001b[36mRestStore.update_run_info\u001b[39m\u001b[34m(self, run_id, run_status, end_time, run_name)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Updates the metadata of the specified run.\"\"\"\u001b[39;00m\n\u001b[32m    182\u001b[39m req_body = message_to_json(\n\u001b[32m    183\u001b[39m     UpdateRun(\n\u001b[32m    184\u001b[39m         run_uuid=run_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m    189\u001b[39m     )\n\u001b[32m    190\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m response_proto = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mUpdateRun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m RunInfo.from_proto(response_proto.run_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:90\u001b[39m, in \u001b[36mRestStore._call_endpoint\u001b[39m\u001b[34m(self, api, json_body, endpoint)\u001b[39m\n\u001b[32m     88\u001b[39m     endpoint, method = _METHOD_TO_INFO[api]\n\u001b[32m     89\u001b[39m response_proto = api.Response()\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:392\u001b[39m, in \u001b[36mcall_endpoint\u001b[39m\u001b[34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001b[39m\n\u001b[32m    389\u001b[39m     call_kwargs[\u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m] = json_body\n\u001b[32m    390\u001b[39m     response = http_request(**call_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m response = \u001b[43mverify_rest_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    393\u001b[39m response_to_parse = response.text\n\u001b[32m    394\u001b[39m js_dict = json.loads(response_to_parse)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:249\u001b[39m, in \u001b[36mverify_rest_response\u001b[39m\u001b[34m(response, endpoint)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _can_parse_as_json_object(response.text):\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m RestException(json.loads(response.text))\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    251\u001b[39m         base_msg = (\n\u001b[32m    252\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfailed with error code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m != 200\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    254\u001b[39m         )\n",
      "\u001b[31mRestException\u001b[39m: INVALID_PARAMETER_VALUE: The run da482c273d6249f89f5573cbe3bfc997 must be in the 'active' state. Current state is deleted."
     ]
    }
   ],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run 006-sequence-modelling-attn-256-dim-bce-prelu at: http://138.2.61.6:5002/#/experiments/2/runs/2a81df7b8a4d4fbaba79e8ff0d416664\n",
      "🧪 View experiment at: http://138.2.61.6:5002/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "all_params = [args]\n",
    "\n",
    "if args.log_to_mlflow:\n",
    "    run_id = trainer.logger.run_id\n",
    "\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        for params in all_params:\n",
    "            params_dict = params.model_dump()\n",
    "            params_ = dict()\n",
    "            for k, v in params_dict.items():\n",
    "                if k == \"top_K\":\n",
    "                    k = \"top_big_K\"\n",
    "                if k == \"top_k\":\n",
    "                    k = \"top_small_k\"\n",
    "                params_[f\"{params.__repr_name__()}.{k}\"] = v\n",
    "            mlflow.log_params(params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hm-scalablerecs-QHnDFvap-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
