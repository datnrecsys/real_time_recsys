{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydantic import BaseModel\n",
    "import sys\n",
    "import os\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from loguru import logger\n",
    "from load_dotenv import load_dotenv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import mlflow\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src.utils.embedding_id_mapper import IDMapper\n",
    "from src.algo.sequence.model import SequenceRatingPrediction\n",
    "from src.algo.sequence.dataset import UserItemBinaryRatingDFDataset\n",
    "from src.algo.sequence.trainer import SeqModellingLitModule\n",
    "from src.algo.item2vec.trainer import LitSkipGram\n",
    "from src.algo.item2vec.model import SkipGram\n",
    "from src.eval.utils import create_rec_df, create_label_df, merge_recs_with_target\n",
    "from src.eval.log_metrics import log_ranking_metrics, log_classification_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-26 20:51:54.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mSetting up Mlflow experiment: pruning-sequence-modelling, run_name: attn-256-dim-bce-prelu\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"testing\": false,\n",
      "  \"log_to_mlflow\": true,\n",
      "  \"experiment_name\": \"pruning-sequence-modelling\",\n",
      "  \"notebook_persit_dp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\notebooks\\\\data\\\\pruning-sequence-modelling\\\\attn-256-dim-bce-prelu\",\n",
      "  \"run_name\": \"attn-256-dim-bce-prelu\",\n",
      "  \"user_col\": \"user_id\",\n",
      "  \"item_col\": \"parent_asin\",\n",
      "  \"rating_col\": \"rating\",\n",
      "  \"timestamp_col\": \"timestamp\",\n",
      "  \"group_name\": \"seq-modelling\",\n",
      "  \"top_K\": 100,\n",
      "  \"top_k\": 10,\n",
      "  \"batch_size\": 512,\n",
      "  \"learning_rate\": 0.001,\n",
      "  \"l2_reg\": 1e-6,\n",
      "  \"early_stopping_patience\": 10,\n",
      "  \"device\": \"cpu\",\n",
      "  \"max_epochs\": 1,\n",
      "  \"dropout\": 0.3,\n",
      "  \"embedding_dim\": 256,\n",
      "  \"use_user_embedding\": true,\n",
      "  \"user_embedding_dim\": 32,\n",
      "  \"use_metadata\": false,\n",
      "  \"metadata_embedding_dim\": 384,\n",
      "  \"metadata_fc_dim\": 128,\n",
      "  \"train_data_fp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\data_for_ai\\\\interim\\\\train_sample_interactions_16407u_neg_seq.parquet\",\n",
      "  \"val_data_fp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\data_for_ai\\\\interim\\\\val_sample_interactions_16407u_neg_seq.parquet\",\n",
      "  \"best_checkpoint_path\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Args(BaseModel):\n",
    "    testing: bool = False\n",
    "    log_to_mlflow: bool = True\n",
    "    experiment_name: str = \"pruning-sequence-modelling\"\n",
    "    notebook_persit_dp: str = None\n",
    "    \n",
    "    run_name: str = None\n",
    "\n",
    "    user_col: str = \"user_id\"\n",
    "    item_col: str = \"parent_asin\"\n",
    "    rating_col: str = \"rating\"\n",
    "    timestamp_col: str = \"timestamp\"\n",
    "    group_name: str = \"seq-modelling\"\n",
    "\n",
    "    top_K: int = 100\n",
    "    top_k: int = 10\n",
    "\n",
    "    batch_size: int = 512\n",
    "    learning_rate: float = 0.001\n",
    "    l2_reg: float = 1e-6\n",
    "    early_stopping_patience: int = 10\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    max_epochs: int = 100\n",
    "\n",
    "    # TwoTower specific\n",
    "    dropout: float = 0.3\n",
    "    embedding_dim: int = 256\n",
    "    use_user_embedding: bool = True\n",
    "    user_embedding_dim: int = 32\n",
    "\n",
    "    use_metadata: bool = True\n",
    "    metadata_embedding_dim: int = 384\n",
    "    metadata_fc_dim: int = 32\n",
    "\n",
    "\n",
    "    train_data_fp: str = os.path.abspath(\"../data_for_ai/interim/train_sample_interactions_16407u_neg_seq.parquet\")\n",
    "    val_data_fp: str = os.path.abspath(\"../data_for_ai/interim/val_sample_interactions_16407u_neg_seq.parquet\")\n",
    "\n",
    "    best_checkpoint_path: str = None\n",
    "    def init(self):\n",
    "        self.run_name: str = f\"attn-{self.embedding_dim}-dim-bce-prelu\"\n",
    "        self.notebook_persit_dp = os.path.abspath(f\"data/{self.experiment_name}/{self.run_name}\")\n",
    "\n",
    "        if not (mlflow_uri := os.environ.get(\"MLFLOW_TRACKING_URI\")):\n",
    "            self.log_to_mlflow = False\n",
    "            logger.warning(\"MLFlow is not enabled. Turn off tracking to Mlflow.\")\n",
    "\n",
    "        if self.log_to_mlflow:\n",
    "            logger.info(\n",
    "                f\"Setting up Mlflow experiment: {self.experiment_name}, run_name: {self.run_name}\"\n",
    "            )\n",
    "\n",
    "            self._mlf_logger = MLFlowLogger(\n",
    "                experiment_name=self.experiment_name,\n",
    "                run_name=self.run_name,\n",
    "                tracking_uri=mlflow_uri,\n",
    "                log_model=False,\n",
    "            )\n",
    "\n",
    "        if not self.testing:\n",
    "            os.makedirs(self.notebook_persit_dp, exist_ok=True)\n",
    "        return self\n",
    "    \n",
    "args = Args().init()\n",
    "print(args.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata embedding\n",
    "metadata_embedding_matrix = np.load(\"../data_for_ai/interim/metadata_alltext_embedding.npy\")  # shape (4817, 898)\n",
    "\n",
    "# add 2 more vector for padding and start token \n",
    "metadata_embedding_matrix = np.concatenate(\n",
    "    [np.zeros((2, metadata_embedding_matrix.shape[1])), metadata_embedding_matrix], axis=0\n",
    ")\n",
    "metadata_embedding_tensor = torch.tensor(metadata_embedding_matrix, dtype=torch.float32)\n",
    "metadata_embedding_layer = nn.Embedding.from_pretrained(\n",
    "    embeddings=metadata_embedding_tensor,\n",
    "    freeze=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata embedding shape: torch.Size([4819, 384])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Metadata embedding shape: {metadata_embedding_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(n_users, n_items, embedding_dim, dropout, item_embedding=None,\n",
    "               user_embedding_dim=None,use_user_embedding=False,\n",
    "               use_metadata=False, metadata_embedding=None,\n",
    "               metadata_embedding_dim=898, metadata_fc_dim=256):\n",
    "    return SequenceRatingPrediction(\n",
    "        item_embedding=item_embedding,\n",
    "        num_users=n_users,\n",
    "        num_items=n_items,\n",
    "        embedding_dim=embedding_dim,\n",
    "        dropout=dropout,\n",
    "        user_embedding_dim=user_embedding_dim,\n",
    "        use_user_embedding=use_user_embedding,\n",
    "        use_metadata=use_metadata,\n",
    "        metadata_embedding=metadata_embedding,\n",
    "        metadata_embedding_dim=metadata_embedding_dim,\n",
    "        metadata_fc_dim=metadata_fc_dim,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning:\n",
      "\n",
      "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
      "\n",
      "\u001b[32m2025-06-26 20:51:56.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.sequence.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mStart token used: 4, Padding token used: 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1564]], grad_fn=<MaskedFillBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceRatingPrediction(\n",
       "  (item_embedding): Embedding(6, 32, padding_idx=5)\n",
       "  (encoder_layer): TransformerEncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (linear2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.3, inplace=False)\n",
       "    (dropout2): Dropout(p=0.3, inplace=False)\n",
       "    (activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "        (activation): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (prelu1): PReLU(num_parameters=1)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (metadata_embedding): Embedding(5, 32)\n",
       "  (item_tower_fc): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (user_embedding): Embedding(3, 64)\n",
       "  (user_tower_fc): Linear(in_features=96, out_features=32, bias=True)\n",
       "  (final_fc): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (score_fc): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 32\n",
    "user_embedding_dim = 64\n",
    "batch_size = 2\n",
    "\n",
    "# Mock data\n",
    "user_indices = [0, 0, 1, 2, 2]\n",
    "item_indices = [0, 1, 2, 3, 4]\n",
    "timestamps = [0, 1, 2, 3, 4]\n",
    "ratings = [0, 3, 1, 3, 0]\n",
    "# item_sequences = [\n",
    "#     [2, 3, -1, -1],\n",
    "#     [2, 4, -1, -1],\n",
    "#     [1, 3, -1, -1],\n",
    "#     [2, 1, -1, -1],\n",
    "#     [4, 1, -1, -1],\n",
    "# ]\n",
    "\n",
    "item_sequences = [\n",
    "    [-1, -1, 2, 3],\n",
    "    [-1, -1, 2, 4],\n",
    "    [-1, -1, 1, 3],\n",
    "    [-1, -1, 2, 1],\n",
    "    [-1, -1, 4, 1],\n",
    "]\n",
    "\n",
    "\n",
    "n_users = len(set(user_indices))\n",
    "\n",
    "n_items = len(set(item_indices))\n",
    "\n",
    "train_df = pd.DataFrame(\n",
    "    {\n",
    "        \"user_indice\": user_indices,\n",
    "        \"item_indice\": item_indices,\n",
    "        args.timestamp_col: timestamps,\n",
    "        args.rating_col: ratings,\n",
    "        \"item_sequence\": item_sequences,\n",
    "    }\n",
    ")\n",
    "# Mock metadata embedding (giả sử mỗi item có 32 chiều metadata embedding)\n",
    "mock_metadata_embedding_matrix = np.random.randn(n_items, embedding_dim).astype(np.float32)\n",
    "mock_metadata_embedding_layer = nn.Embedding.from_pretrained(\n",
    "    embeddings=torch.tensor(mock_metadata_embedding_matrix),\n",
    "    freeze=True)\n",
    "\n",
    "model = init_model(n_users, \n",
    "                   n_items, \n",
    "                   embedding_dim, \n",
    "                   args.dropout,\n",
    "                   user_embedding_dim=user_embedding_dim,\n",
    "                   use_user_embedding=args.use_user_embedding,\n",
    "                   use_metadata=args.use_metadata,\n",
    "                   metadata_embedding=mock_metadata_embedding_layer,\n",
    "                   metadata_embedding_dim=embedding_dim,\n",
    "                   metadata_fc_dim=16,)\n",
    "\n",
    "# Example forward pass\n",
    "model.eval()\n",
    "user = torch.tensor([0])\n",
    "item_sequence = torch.tensor([[-0, 1, -1, -1]])\n",
    "target_item = torch.tensor([2])\n",
    "target_metadata = torch.tensor([2])  # giả sử metadata index trùng với item index\n",
    "predictions = model(user, item_sequence, target_item, target_metadata)\n",
    "print(predictions)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset = UserItemBinaryRatingDFDataset(\n",
    "    train_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col,\"item_sequence\"\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    rating_dataset, batch_size=batch_size, shuffle=False, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': tensor([0, 0]), 'item': tensor([0, 1]), 'rating': tensor([0., 1.]), 'item_sequence': tensor([[-1, -1,  2,  3],\n",
      "        [-1, -1,  2,  4]], dtype=torch.int32)}\n",
      "{'user': tensor([1, 2]), 'item': tensor([2, 3]), 'rating': tensor([1., 1.]), 'item_sequence': tensor([[-1, -1,  1,  3],\n",
      "        [-1, -1,  2,  1]], dtype=torch.int32)}\n"
     ]
    }
   ],
   "source": [
    "for batch_input in train_loader:\n",
    "    print(batch_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "lit_model = SeqModellingLitModule(model, log_dir=args.notebook_persit_dp)\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=f\"{args.notebook_persit_dp}/test\",\n",
    "    max_epochs=100,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    ")\n",
    "# trainer.fit(\n",
    "#     model=lit_model, train_dataloaders=train_loader, val_dataloaders=train_loader\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5408]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "user = torch.tensor([0])\n",
    "item_sequence = torch.tensor([[-1, -1, -1, 0, 1]])\n",
    "target_item = torch.tensor([2])\n",
    "target_metadata = torch.tensor([2])  # giả sử metadata index trùng với item index\n",
    "predictions = model.predict(user, item_sequence, target_item,target_metadata)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(args.train_data_fp)\n",
    "val_df = pd.read_parquet(args.val_data_fp)\n",
    "\n",
    "assert set(val_df[args.user_col].unique()).issubset(set(train_df[args.user_col].unique())), \"Validation users must be present in training users.\"\n",
    "\n",
    "assert set(val_df[args.item_col].unique()).issubset(set(train_df[args.item_col].unique())), \"Validation items must be present in training items.\"\n",
    "assert train_df[args.timestamp_col].max() < val_df[args.timestamp_col].min(), \"Validation data must be after training data. Otherwise, its a data contamination problem.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151343</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B009RUZ7TS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:15:55.000</td>\n",
       "      <td>1412</td>\n",
       "      <td>4220</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 455...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40958</th>\n",
       "      <td>AF7KZV4NJ5GBDVFTB7PEEUN4U53A</td>\n",
       "      <td>B0BBMLD8QT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-07-29 20:38:06.000</td>\n",
       "      <td>4871</td>\n",
       "      <td>4476</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218918</th>\n",
       "      <td>AFVQ4K4KZPLQ3E2VFYSGX6HFXGNQ</td>\n",
       "      <td>B0BB6R89VF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-12-13 20:35:02.334</td>\n",
       "      <td>7616</td>\n",
       "      <td>1218</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43115</th>\n",
       "      <td>AFCLWJMGYFCOJQR7T4454OF5A5WA</td>\n",
       "      <td>B00ENFP224</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-09-06 12:09:59.000</td>\n",
       "      <td>5250</td>\n",
       "      <td>1355</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233421</th>\n",
       "      <td>AFP4PHJ6Q2RRXLDPSDSH6VXJRUTA</td>\n",
       "      <td>B07CMXS5FP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-11-23 09:44:21.734</td>\n",
       "      <td>6792</td>\n",
       "      <td>838</td>\n",
       "      <td>[-1.0, -1.0, -1.0, 1055.0, 3572.0, 3865.0, 176...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250960</th>\n",
       "      <td>AGQHC7YNLYP4QV2PSBD6URSMJSVA</td>\n",
       "      <td>B07H65KP63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-02-08 04:09:50.457</td>\n",
       "      <td>11001</td>\n",
       "      <td>3568</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, 3585.0, 1866.0, 4040....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217058</th>\n",
       "      <td>AHD65JAOVTTPDNJWOLSSGS3QVK6Q</td>\n",
       "      <td>B07DKMJ61N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-11-02 15:25:18.351</td>\n",
       "      <td>13410</td>\n",
       "      <td>4239</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61324</th>\n",
       "      <td>AF32PWYNLPCVAU4UX35IEAZOFA3Q</td>\n",
       "      <td>B011BRUOMO</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-07-18 05:42:21.000</td>\n",
       "      <td>4264</td>\n",
       "      <td>2253</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132003</th>\n",
       "      <td>AGM65FYYAPHOLESGIDMFMPUQIYNA</td>\n",
       "      <td>B0016BVDIK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010-12-16 19:59:19.000</td>\n",
       "      <td>10445</td>\n",
       "      <td>4250</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34752</th>\n",
       "      <td>AFVQ4K4KZPLQ3E2VFYSGX6HFXGNQ</td>\n",
       "      <td>B00DR0B6XK</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015-04-02 17:48:23.000</td>\n",
       "      <td>7616</td>\n",
       "      <td>1293</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254784 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id parent_asin  rating  \\\n",
       "151343  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B009RUZ7TS     0.0   \n",
       "40958   AF7KZV4NJ5GBDVFTB7PEEUN4U53A  B0BBMLD8QT     5.0   \n",
       "218918  AFVQ4K4KZPLQ3E2VFYSGX6HFXGNQ  B0BB6R89VF     0.0   \n",
       "43115   AFCLWJMGYFCOJQR7T4454OF5A5WA  B00ENFP224     5.0   \n",
       "233421  AFP4PHJ6Q2RRXLDPSDSH6VXJRUTA  B07CMXS5FP     0.0   \n",
       "...                              ...         ...     ...   \n",
       "250960  AGQHC7YNLYP4QV2PSBD6URSMJSVA  B07H65KP63     0.0   \n",
       "217058  AHD65JAOVTTPDNJWOLSSGS3QVK6Q  B07DKMJ61N     0.0   \n",
       "61324   AF32PWYNLPCVAU4UX35IEAZOFA3Q  B011BRUOMO     5.0   \n",
       "132003  AGM65FYYAPHOLESGIDMFMPUQIYNA  B0016BVDIK     0.0   \n",
       "34752   AFVQ4K4KZPLQ3E2VFYSGX6HFXGNQ  B00DR0B6XK     4.0   \n",
       "\n",
       "                     timestamp  user_indice  item_indice  \\\n",
       "151343 2014-07-17 19:15:55.000         1412         4220   \n",
       "40958  2015-07-29 20:38:06.000         4871         4476   \n",
       "218918 2017-12-13 20:35:02.334         7616         1218   \n",
       "43115  2015-09-06 12:09:59.000         5250         1355   \n",
       "233421 2018-11-23 09:44:21.734         6792          838   \n",
       "...                        ...          ...          ...   \n",
       "250960 2020-02-08 04:09:50.457        11001         3568   \n",
       "217058 2017-11-02 15:25:18.351        13410         4239   \n",
       "61324  2016-07-18 05:42:21.000         4264         2253   \n",
       "132003 2010-12-16 19:59:19.000        10445         4250   \n",
       "34752  2015-04-02 17:48:23.000         7616         1293   \n",
       "\n",
       "                                            item_sequence  \n",
       "151343  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 455...  \n",
       "40958   [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "218918  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 129...  \n",
       "43115   [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "233421  [-1.0, -1.0, -1.0, 1055.0, 3572.0, 3865.0, 176...  \n",
       "...                                                   ...  \n",
       "250960  [-1.0, -1.0, -1.0, -1.0, 3585.0, 1866.0, 4040....  \n",
       "217058  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "61324   [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "132003  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "34752   [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "\n",
       "[254784 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172167</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B07C1RSV9C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-08-05 16:31:49</td>\n",
       "      <td>1412</td>\n",
       "      <td>934</td>\n",
       "      <td>[-1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0, 3295.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41296</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B07C1RSV9C</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-08-05 16:31:49</td>\n",
       "      <td>1412</td>\n",
       "      <td>3276</td>\n",
       "      <td>[-1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0, 3295.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151346</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B07CB22VVJ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:19:28</td>\n",
       "      <td>1412</td>\n",
       "      <td>4599</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20475</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B07CB22VVJ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:19:28</td>\n",
       "      <td>1412</td>\n",
       "      <td>3295</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20474</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B000I23TTE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:16:43</td>\n",
       "      <td>1412</td>\n",
       "      <td>107</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151345</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B000I23TTE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:16:43</td>\n",
       "      <td>1412</td>\n",
       "      <td>4659</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151344</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0BYSP9676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:16:20</td>\n",
       "      <td>1412</td>\n",
       "      <td>3678</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20473</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0BYSP9676</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:16:20</td>\n",
       "      <td>1412</td>\n",
       "      <td>4685</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151343</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B009RUZ7TS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:15:55</td>\n",
       "      <td>1412</td>\n",
       "      <td>4220</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20472</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B009RUZ7TS</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:15:55</td>\n",
       "      <td>1412</td>\n",
       "      <td>1047</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20471</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0787JNNXH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:12:09</td>\n",
       "      <td>1412</td>\n",
       "      <td>3164</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151342</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0787JNNXH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:12:09</td>\n",
       "      <td>1412</td>\n",
       "      <td>121</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151341</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0B7FN67QT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:11:53</td>\n",
       "      <td>1412</td>\n",
       "      <td>4653</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20470</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0B7FN67QT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:11:53</td>\n",
       "      <td>1412</td>\n",
       "      <td>4443</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20469</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0BM6ZLKPL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:11:13</td>\n",
       "      <td>1412</td>\n",
       "      <td>4559</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151340</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0BM6ZLKPL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:11:13</td>\n",
       "      <td>1412</td>\n",
       "      <td>2004</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id parent_asin  rating           timestamp  \\\n",
       "172167  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B07C1RSV9C     0.0 2015-08-05 16:31:49   \n",
       "41296   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B07C1RSV9C     5.0 2015-08-05 16:31:49   \n",
       "151346  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B07CB22VVJ     0.0 2014-07-17 19:19:28   \n",
       "20475   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B07CB22VVJ     5.0 2014-07-17 19:19:28   \n",
       "20474   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B000I23TTE     5.0 2014-07-17 19:16:43   \n",
       "151345  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B000I23TTE     0.0 2014-07-17 19:16:43   \n",
       "151344  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0BYSP9676     0.0 2014-07-17 19:16:20   \n",
       "20473   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0BYSP9676     5.0 2014-07-17 19:16:20   \n",
       "151343  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B009RUZ7TS     0.0 2014-07-17 19:15:55   \n",
       "20472   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B009RUZ7TS     5.0 2014-07-17 19:15:55   \n",
       "20471   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0787JNNXH     5.0 2014-07-17 19:12:09   \n",
       "151342  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0787JNNXH     0.0 2014-07-17 19:12:09   \n",
       "151341  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0B7FN67QT     0.0 2014-07-17 19:11:53   \n",
       "20470   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0B7FN67QT     5.0 2014-07-17 19:11:53   \n",
       "20469   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0BM6ZLKPL     5.0 2014-07-17 19:11:13   \n",
       "151340  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0BM6ZLKPL     0.0 2014-07-17 19:11:13   \n",
       "\n",
       "        user_indice  item_indice  \\\n",
       "172167         1412          934   \n",
       "41296          1412         3276   \n",
       "151346         1412         4599   \n",
       "20475          1412         3295   \n",
       "20474          1412          107   \n",
       "151345         1412         4659   \n",
       "151344         1412         3678   \n",
       "20473          1412         4685   \n",
       "151343         1412         4220   \n",
       "20472          1412         1047   \n",
       "20471          1412         3164   \n",
       "151342         1412          121   \n",
       "151341         1412         4653   \n",
       "20470          1412         4443   \n",
       "20469          1412         4559   \n",
       "151340         1412         2004   \n",
       "\n",
       "                                                                    item_sequence  \n",
       "172167  [-1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0, 3295.0]  \n",
       "41296   [-1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0, 3295.0]  \n",
       "151346    [-1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0]  \n",
       "20475     [-1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0]  \n",
       "20474      [-1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0]  \n",
       "151345     [-1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0]  \n",
       "151344       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0]  \n",
       "20473        [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0]  \n",
       "151343         [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0]  \n",
       "20472          [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0]  \n",
       "20471            [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0]  \n",
       "151342           [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0]  \n",
       "151341             [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0]  \n",
       "20470              [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0]  \n",
       "20469                [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]  \n",
       "151340               [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(train_df.loc[train_df[\"user_id\"] == \"AEEV5YWQKPBTLFWHKOBBULYA2RDQ\"].sort_values(by=args.timestamp_col, ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert user_id and item_id into indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idm_path = os.path.abspath(\"../data_for_ai/interim/idm_16407u.json\")\n",
    "# idm = IDMapper().load(idm_path)\n",
    "# idm.get_user_id(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.pipe(idm.map_indices)\n",
    "# val_df = val_df.pipe(idm.map_indices)\n",
    "\n",
    "# assert idm.unknown_item_index not in train_df[\"item_indice\"].values, \"Unknown item index must be present in training data.\"\n",
    "# assert idm.unknown_user_index not in train_df[\"user_indice\"].values, \"Unknown user index must be present in training data.\"\n",
    "# assert idm.unknown_item_index not in val_df[\"item_indice\"].values, \"Unknown item index must be present in validation data.\"\n",
    "# assert idm.unknown_user_index not in val_df[\"user_indice\"].values, \"Unknown user index must be present in validation data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert train_df.groupby(args.user_col)[args.item_col].nunique().min() >= 5, \"Each user must have at least five items.\"\n",
    "# assert train_df.groupby(args.item_col)[args.user_col].nunique().min() >= 10, \"Each item must have at least ten users.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset = UserItemBinaryRatingDFDataset(\n",
    "    train_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col, \"item_sequence\"\n",
    ")\n",
    "val_rating_dataset = UserItemBinaryRatingDFDataset(\n",
    "    val_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col, \"item_sequence\"\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    rating_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_rating_dataset, batch_size=args.batch_size, shuffle=False, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the weight from SkipGram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-26 20:52:07.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mNumber of users: 16407, Number of items: 4817\u001b[0m\n",
      "\u001b[32m2025-06-26 20:52:07.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.item2vec.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mInitializing item embeddings with num items 4817, embedding dim 256\u001b[0m\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\utilities\\migration\\utils.py:56: PossibleUserWarning:\n",
      "\n",
      "The loaded checkpoint was produced with Lightning v2.5.2, which is newer than your current Lightning version: v2.5.0\n",
      "\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning:\n",
      "\n",
      "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
      "\n",
      "\u001b[32m2025-06-26 20:52:09.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.sequence.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mStart token used: 4816, Padding token used: 4817\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkipGram Item embedding shape: torch.Size([4818, 256])\n",
      "SkipGram Item embedding dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "item_indices = train_df[args.item_col].unique()\n",
    "user_indices = train_df[args.user_col].unique()\n",
    "n_items = len(item_indices)\n",
    "n_users = len(user_indices)\n",
    "\n",
    "logger.info(f\"Number of users: {n_users}, Number of items: {n_items}\")\n",
    "\n",
    "assert args.embedding_dim == 256, \"Embedding dimension must be 256\"\n",
    "best_trainer = LitSkipGram.load_from_checkpoint(\n",
    "    \"../data_for_ai/interim/best-item2vec-weight.ckpt\",\n",
    "    skipgram_model=SkipGram(n_items, args.embedding_dim).to(args.device),\n",
    ")\n",
    "skipgram_item_embedding = best_trainer.skipgram_model.embeddings.weight.data.cpu()\n",
    "print(f\"SkipGram Item embedding shape: {skipgram_item_embedding.shape}\")\n",
    "print(f\"SkipGram Item embedding dtype: {skipgram_item_embedding.dtype}\")\n",
    "# convert skipgram_item_embedding into torch.nn.Embedding and take the first n_items rows\n",
    "skipgram_item_embedding = torch.nn.Embedding.from_pretrained(\n",
    "    skipgram_item_embedding[:n_items], freeze=False\n",
    ")\n",
    "\n",
    "model = init_model(n_users, \n",
    "                   n_items, \n",
    "                   args.embedding_dim, \n",
    "                   args.dropout, \n",
    "                   item_embedding=skipgram_item_embedding,\n",
    "                   user_embedding_dim=args.user_embedding_dim,\n",
    "                   use_user_embedding=args.use_user_embedding,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4817 items in the dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AE227WAM4NWQPJI33OPN7ZARNNZQ'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idm_path = os.path.abspath(\"../data_for_ai/interim/idm_16407u.json\")\n",
    "idm = IDMapper().load(idm_path)\n",
    "idm.get_user_id(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-26 20:52:10.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.sequence.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mStart token used: 4816, Padding token used: 4817\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=5, mode=\"min\", verbose=False\n",
    ")\n",
    "\n",
    "model = init_model(n_users, n_items, args.embedding_dim, args.dropout,item_embedding=skipgram_item_embedding,\n",
    "                   user_embedding_dim=args.user_embedding_dim,\n",
    "                   use_user_embedding=args.use_user_embedding,\n",
    "                   use_metadata=args.use_metadata,\n",
    "                   metadata_embedding=metadata_embedding_layer,\n",
    "                   metadata_embedding_dim=args.metadata_embedding_dim,\n",
    "                   metadata_fc_dim=args.metadata_fc_dim,)\n",
    "\n",
    "lit_model = SeqModellingLitModule(\n",
    "    model,\n",
    "    learning_rate=args.learning_rate,\n",
    "    l2_reg=args.l2_reg,\n",
    "    log_dir=args.notebook_persit_dp,\n",
    "    accelerator=args.device,\n",
    "    idm= idm\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persit_dp}/logs/overfit\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    max_epochs=100,\n",
    "    overfit_batches=1,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "# trainer.fit(\n",
    "#     model=lit_model,\n",
    "#     train_dataloaders=train_loader,\n",
    "#     val_dataloaders=train_loader,\n",
    "# )\n",
    "# logger.info(f\"Logs available at {trainer.log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': tensor([  404,  7781, 13601,  2365,  4590, 13702, 13298, 13238, 10182,  5072,\n",
      "        12267,  3841,  5071, 14263,  1872,  4242,  8127, 12850, 14142,  2277,\n",
      "        13445,  4639, 16142,  8514,  8464,  9227,  2553, 14989,  7729, 12898,\n",
      "         6050, 16333,  1576,   139,  2534,  3410, 14188,  9469,  3147, 15208,\n",
      "        14637,  1928,  8115,  3967,  8232, 14667,  7958,  4082,  1744,  8785,\n",
      "        14680, 13386, 11802, 16228,  5564,  6959,  1300,   310,  8391,  2109,\n",
      "        11622, 10332, 14022, 12172,  2042,  3513, 11967,  7908, 15914,  5533,\n",
      "        11343,  6118, 10279,  2956,   781,  9465, 15654, 13885, 10182, 15342,\n",
      "         7964,  6050,   525,  1490,   881,  9757,  5414,  2479,  7033,   175,\n",
      "        13111, 14951, 15762, 12638, 15868,  2155, 14997, 10274, 15379,  6800,\n",
      "         7237, 15522, 15265, 13696,  7008, 15961, 11439,  6290, 14276,   955,\n",
      "        13875,  5517,  9687,  3518,    26, 10341, 13466,  1414,   517, 13748,\n",
      "          138,  5509,  3422, 14229,  8454, 13175, 15599, 12096, 15599, 10715,\n",
      "         4960, 15933,  2240, 10120,  8172,  9016,   903,  6328,  6506,  3835,\n",
      "        14314,  5158, 11909, 14891,  7622, 14299,  1472, 11281, 11509, 14418,\n",
      "          796, 14807,  7540, 14097,  8260,  3371, 16101, 16218, 14197, 14821,\n",
      "          863, 16271, 14295,   741,  6544, 12898,  6009,  8493,   141, 15367,\n",
      "        15531, 15643, 11487,  9852,   749, 12835,  2227, 11489,  9986,  5368,\n",
      "        12455,  2756, 13991, 13664, 10587, 11513,  7689,  9790,  9190, 13254,\n",
      "        13593,  3095,  9603,  3728,  4369,   516,   910, 13556, 12357,  1667,\n",
      "         7385,  4350,  6498, 12774,  2524, 16325,  8672,  6619,  3823,  8502,\n",
      "         4384,  1248, 10697,  8250,  2525, 15247,  7414,  7226, 15573, 15876,\n",
      "         7338,  1719,  7696,  2024,  7674, 11991,  7032, 10161, 16052,  7250,\n",
      "         2779,  1773,  6907,  2467,  2579,  2707,  3061,   130, 12960, 13064,\n",
      "        13847,  5448, 10133, 15573,  9724, 13985, 15322,  8852,  7714,  7578,\n",
      "         8462, 16318,  5919,  5821,  6069, 12497, 15687,  3026, 12144, 11269,\n",
      "        10155,  5851, 10861,  7113,  1146,  2122,  2737,   952, 14207,  5967,\n",
      "         1687, 10384,  1948, 11652,  7907, 13295,  6567,  5601,  2903,  8209,\n",
      "         2143, 13503, 11858, 11817, 10800,  2202,  1082, 16245, 13018,   959,\n",
      "         7369,   851,  6550,  1785, 10369, 14047,   165, 14542,  2316,  1408,\n",
      "         7298,   592,  1515,  3931,  6675, 12348,  5440, 11977, 10135,  6224,\n",
      "        14893,   137, 10340,  7756,  1898,  4183,  3656, 12494,  7126, 14603,\n",
      "          142,  6653,  5004,  1762,  5079,  5862,   476,  5425, 11742, 12422,\n",
      "         9312, 15825,  7545, 12150, 10465,  1659,  1689,  4704,  9178, 11437,\n",
      "         7896,  7957, 15439,  5234,   597,  4495,  6625, 11972, 10851,  6287,\n",
      "        13729, 15320, 12923, 13967,   760,  1475,  1349,  6060, 16352,  5438,\n",
      "         7413,  7495,  6751,   257, 14951,   251,  9046,  3105,  5402, 11638,\n",
      "         2756,  7169,  9366,  3823,  5435,  4057,  1921,   132,  7044,  8529,\n",
      "        10550, 14126, 14989,  6906,  5478,  3421,  5186,  2347,  2021,  5820,\n",
      "         4234,   343,  8635, 11626, 13281, 12207,  6515, 14489, 15071,   617,\n",
      "        10287,  8027,  3982,  5911,  5227,  1402,  7560, 13867,  9811, 11070,\n",
      "        14071, 15176,  8645, 16078, 14454, 14308,  2139,  6631, 12991, 12835,\n",
      "        13956,  5122,  3409,  7808, 11380,  9220,  6820,   227,  1487,  9721,\n",
      "        11063,    82,  2407, 13399,  7735,  8244,  5519, 14194,  4630,  3844,\n",
      "         2886,  3368,   447, 11743,  7520, 13859, 16033, 14052,  5704,  1427,\n",
      "        15540,  8540,  2494, 11026, 16369,  4758,  5569, 10923,   640, 12320,\n",
      "         7716, 12653,  5821, 11651,  4077, 12589,  6811, 16239,  5328, 13178,\n",
      "        12590, 15320,   125,   577, 14452, 13379, 16332,  1202,  2300,  4043,\n",
      "          444, 15721,  5208,  4626,  6094,  6940,  1989,  9538, 12823,   545,\n",
      "        11747, 12197, 13372,   663, 15538,  4780,  1815,  7153,  3169,   852,\n",
      "        14382,  8550,  8960,  6684, 10308,  2971,  7023, 13742, 15606,  2351,\n",
      "        11287,  2652]), 'item': tensor([3092, 4516,  500, 4471, 3145, 3829,  419, 2332,  940, 2368, 3731, 3590,\n",
      "        4564, 3780, 1307,   99, 1768,  128, 4794, 2461, 4390,  289, 3612, 2464,\n",
      "        2864,  822, 1956,  460, 3839, 2229, 4465, 2054, 1791, 3517,  909, 1326,\n",
      "         388, 2660,  696, 3412, 3678, 4525,  592, 2137, 2007, 2371, 2477, 4720,\n",
      "        2065, 3897, 2709, 1197,  509,  685, 3538,  430, 3950, 2123,  664, 4798,\n",
      "        2336,  118,  441,  380,  360,  683, 3579,  470, 2237, 4098, 2754, 3852,\n",
      "        1655, 4757, 2665, 4566,  768, 4587, 2027, 2619, 2015, 2707,   59,  410,\n",
      "        3700, 3062, 4424, 3699, 3024, 3312,  285, 1113, 2879, 4255, 3697, 2858,\n",
      "        3323, 3066,   26, 3517, 2437, 1799, 4357, 2742,  221, 4687, 2626, 1505,\n",
      "        2973, 1244, 4251, 2844, 3164, 3381, 2045,  300, 3517, 4243,  251, 3578,\n",
      "        1103, 2410, 2418, 1853, 3031, 4628, 4311, 1474,  635, 2123, 1570,  218,\n",
      "         563, 1338, 4357, 3023,  258, 2237, 1174,  451, 1880,  225,   46, 3119,\n",
      "        3023, 2783,  883,  670,  776, 1244, 3999, 4123, 1302, 4276, 4686, 2083,\n",
      "        4006, 2816, 1727, 4055, 3062, 1980, 4337, 4746, 3585, 3503,  765,  851,\n",
      "        3344,  223, 3272, 4227, 3220, 3186, 1885, 1455, 4696,  104, 4496, 4517,\n",
      "        3542, 2946,  874, 1295, 4586, 3869, 4681, 2084,  901, 4353, 4330, 3594,\n",
      "         487, 1842, 3685, 3009,    4, 4195, 3760, 3527, 4069,  620, 1197, 3851,\n",
      "        1453, 3089,  499, 3195, 3024, 1844, 3992, 1912, 2924, 1048,  673, 2152,\n",
      "         205, 2517, 4660,  113, 1740,  423, 2312, 2594, 3115, 4276,  198, 3149,\n",
      "        3771, 1785, 2727, 4659, 3263, 2685,  666, 3188, 2493,  565, 1059, 1052,\n",
      "        1846, 3170,  224, 3806, 1348, 3625, 3143,  381, 1558, 1776, 1363, 2001,\n",
      "        1131, 3025,  190, 2082, 1113, 1270, 2983, 2840, 1839, 3844, 2766, 4378,\n",
      "        1379, 2350,  182, 2237, 1923, 4302, 1139, 4084, 3588, 4093, 4447, 3659,\n",
      "        2547, 3908, 2214, 4062, 2694, 2796, 1039, 4575, 2101,  932, 1816, 1055,\n",
      "        1885, 3090, 3923, 2362, 4610, 2007, 1103,  768, 4718, 1348, 2186, 2694,\n",
      "         122, 4057, 3643, 4162, 1002, 1839, 2022, 2488, 4366,  897,   68,  634,\n",
      "        1678,  427, 3988, 1971, 2104, 3008, 2694, 4065, 3677, 4594, 3961, 3091,\n",
      "        4390, 1650,  644, 1169, 1925,  172, 3682, 3957,  516,  364, 4249, 2172,\n",
      "        3717, 4631, 2237, 4366, 4046,  154, 4389, 1914,  954, 3003, 2305, 1605,\n",
      "        3944,  530, 1706,  867, 1244, 3089, 2498, 3221, 3330,  443, 3628,  679,\n",
      "        4033, 3992,  154, 3196, 1400, 4434, 3151, 1350,  626, 3426, 3631, 4234,\n",
      "         302, 3089, 1295, 2969, 4023, 1839, 2244, 1882, 4365, 1806, 4710, 3089,\n",
      "        1610, 2681, 2417, 1503, 4036, 3590, 4360, 2253, 2475, 2859, 1558, 2787,\n",
      "        1198,  469, 2749, 3586, 2811, 3935, 3443, 4541, 2229, 3068, 1049, 3188,\n",
      "        3844, 2040, 2283, 2737, 3025, 4654, 3539, 1995, 1528, 4396,  509, 1742,\n",
      "        2472, 1333, 2253, 3743, 2128, 3996, 4349, 4235, 2051, 3227, 2754, 4320,\n",
      "        4165,  285, 3089, 2811,  496, 3933, 4720, 4659,  154,  271, 4147, 2796,\n",
      "        1968,   69,  980, 1244,  420, 3076, 2272, 4575, 2743,  840, 1333, 3943,\n",
      "        4659, 3965, 3209, 3702, 2450, 1704, 4438,  154, 2078, 1058, 1084,    6,\n",
      "        1516, 3060, 2718, 4302, 1181, 4187, 1786, 1375, 3298, 4357, 2405, 1570,\n",
      "        1352, 1656, 2694,  235, 2350, 3443, 4575, 3454, 3856, 4602, 3076,  677,\n",
      "        4390, 4036, 1319, 1086, 1474, 2813,   10, 2466, 3088, 3274, 2763, 4713,\n",
      "        1930,  819, 2941,  601, 1725,  649, 2394, 3678]), 'rating': tensor([0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 0.]), 'item_sequence': tensor([[  -1,   -1,   -1,  ...,   -1,   -1,   -1],\n",
      "        [  -1,   -1,   -1,  ..., 4304, 4387, 4311],\n",
      "        [  -1,   -1,   -1,  ..., 2879, 1369, 3432],\n",
      "        ...,\n",
      "        [  -1,   -1,   -1,  ..., 3422, 1198, 4615],\n",
      "        [  -1,   -1,   -1,  ..., 4568,  769, 4124],\n",
      "        [  -1,   -1,   -1,  ...,   -1, 2958, 4225]], dtype=torch.int32)}\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import lightning\n",
    "print(lightning.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-26 20:52:13.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.sequence.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mStart token used: 4816, Padding token used: 4817\u001b[0m\n",
      "GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SequenceRatingPrediction(\n",
      "  (item_embedding): Embedding(4818, 256, padding_idx=4817)\n",
      "  (encoder_layer): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.3, inplace=False)\n",
      "    (dropout2): Dropout(p=0.3, inplace=False)\n",
      "    (activation): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.3, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (dropout2): Dropout(p=0.3, inplace=False)\n",
      "        (activation): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (prelu1): PReLU(num_parameters=1)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (metadata_embedding): Embedding(4819, 384)\n",
      "  (item_tower_fc): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (user_embedding): Embedding(16407, 32)\n",
      "  (user_tower_fc): Linear(in_features=288, out_features=256, bias=True)\n",
      "  (final_fc): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (score_fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:654: UserWarning:\n",
      "\n",
      "Checkpoint directory C:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\data\\pruning-sequence-modelling\\attn-256-dim-bce-prelu\\checkpoints exists and is not empty.\n",
      "\n",
      "\n",
      "  | Name               | Type                     | Params | Mode \n",
      "------------------------------------------------------------------------\n",
      "0 | model              | SequenceRatingPrediction | 4.7 M  | train\n",
      "1 | val_roc_auc_metric | BinaryAUROC              | 0      | train\n",
      "2 | val_pr_auc_metric  | BinaryAveragePrecision   | 0      | train\n",
      "------------------------------------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "1.9 M     Non-trainable params\n",
      "4.7 M     Total params\n",
      "18.687    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bdb0710d9b043679861b88bed659ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: PossibleUserWarning:\n",
      "\n",
      "The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "\n",
      "c:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\..\\src\\algo\\sequence\\dataset.py:38: UserWarning:\n",
      "\n",
      "The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:209.)\n",
      "\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: PossibleUserWarning:\n",
      "\n",
      "The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:310: PossibleUserWarning:\n",
      "\n",
      "The number of training batches (49) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15fa72a7fc14909800969b1edb9ab4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c15074ae9004ab9ba00c977a02bc77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run attn-256-dim-bce-prelu at: http://138.2.61.6:5002/#/experiments/11/runs/e9c45ba72db94e74a72c5abb303dc546\n",
      "🧪 View experiment at: http://138.2.61.6:5002/#/experiments/11\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_roc_auc\", patience=args.early_stopping_patience, mode=\"max\", verbose=False, min_delta=0.001\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{args.notebook_persit_dp}/checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_roc_auc\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "model = init_model(n_users, n_items, \n",
    "                   args.embedding_dim, \n",
    "                   args.dropout, \n",
    "                   item_embedding=skipgram_item_embedding,\n",
    "                   user_embedding_dim=args.user_embedding_dim,\n",
    "                   use_user_embedding=args.use_user_embedding,\n",
    "                   use_metadata=args.use_metadata,\n",
    "                   metadata_embedding=metadata_embedding_layer,\n",
    "                   metadata_embedding_dim=args.metadata_embedding_dim,\n",
    "                   metadata_fc_dim=args.metadata_fc_dim,)\n",
    "\n",
    "print(f\"Model: {model}\")\n",
    "lit_model = SeqModellingLitModule(\n",
    "    model,\n",
    "    learning_rate=args.learning_rate,\n",
    "    l2_reg=args.l2_reg,\n",
    "    log_dir=args.notebook_persit_dp,\n",
    "    accelerator=args.device,\n",
    "    idm= idm\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persit_dp}/logs/run\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    max_epochs=args.max_epochs,\n",
    "    callbacks=[early_stopping, checkpoint_callback],\n",
    "    logger=args._mlf_logger if args.log_to_mlflow else None,\n",
    "    # limit_train_batches=0.1    \n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    "    \n",
    ")\n",
    "\n",
    "# Change the library as a workaround for the issue in the latest Lightning release\n",
    "#https://github.com/Lightning-AI/pytorch-lightning/pull/20669/commits/429f732a0528c558e701da7ec01e51c1e2e4f32e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-26 20:52:39.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1mLoading best checkpoint from C:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\data\\pruning-sequence-modelling\\attn-256-dim-bce-prelu\\checkpoints\\best-checkpoint-v7.ckpt...\u001b[0m\n",
      "\u001b[32m2025-06-26 20:52:39.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.sequence.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mStart token used: 4816, Padding token used: 4817\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Loading best checkpoint from {checkpoint_callback.best_model_path}...\")\n",
    "args.best_checkpoint_path = checkpoint_callback.best_model_path\n",
    "\n",
    "best_trainer = SeqModellingLitModule.load_from_checkpoint(\n",
    "    checkpoint_path=checkpoint_callback.best_model_path,\n",
    "    model=init_model(n_users, \n",
    "                     n_items, \n",
    "                     args.embedding_dim, \n",
    "                     args.dropout, \n",
    "                     item_embedding=skipgram_item_embedding,\n",
    "                     user_embedding_dim=args.user_embedding_dim,\n",
    "                     use_user_embedding=args.use_user_embedding,\n",
    "                     use_metadata=args.use_metadata,\n",
    "                     metadata_embedding=metadata_embedding_layer,\n",
    "                     metadata_embedding_dim=args.metadata_embedding_dim,\n",
    "                     metadata_fc_dim=args.metadata_fc_dim,),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceRatingPrediction(\n",
       "  (item_embedding): Embedding(4818, 256, padding_idx=4817)\n",
       "  (encoder_layer): TransformerEncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.3, inplace=False)\n",
       "    (dropout2): Dropout(p=0.3, inplace=False)\n",
       "    (activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "        (activation): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (prelu1): PReLU(num_parameters=1)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (metadata_embedding): Embedding(4819, 384)\n",
       "  (item_tower_fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (user_embedding): Embedding(16407, 32)\n",
       "  (user_tower_fc): Linear(in_features=288, out_features=256, bias=True)\n",
       "  (final_fc): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (score_fc): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = best_trainer.model.to(args.device)\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_recs_df = val_df.sort_values(by=args.timestamp_col).drop_duplicates(subset=[args.user_col], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.start_run(run_id = trainer.logger.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_user_indices = val_df[\"user_indice\"].values\n",
    "val_item_indices = val_df[\"item_indice\"].values\n",
    "val_item_sequences = val_df[\"item_sequence\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trieu\\AppData\\Local\\Temp\\ipykernel_3724\\3241326139.py:2: UserWarning:\n",
      "\n",
      "Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users = torch.tensor(val_user_indices, device=args.device)\n",
    "item_sequences = torch.tensor(val_item_sequences, device=args.device)\n",
    "items = torch.tensor(val_item_indices, device=args.device)\n",
    "classifications = best_model.predict(users, item_sequences, items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6958, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_classification_df = val_df.assign(\n",
    "    classification_proba=classifications.cpu().detach().numpy(),\n",
    "    label=lambda df: df[args.rating_col].gt(0).astype(int),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "      <th>classification_proba</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260331</th>\n",
       "      <td>AGMJWWTZ6HMM2FBRDLFW2CWMV5DQ</td>\n",
       "      <td>B00E0ISVLI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-07-18 15:44:29.739</td>\n",
       "      <td>10483</td>\n",
       "      <td>2563</td>\n",
       "      <td>[-1, 2906, 3011, 4674, 4593, 4755, 3810, 3921,...</td>\n",
       "      <td>0.491368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259198</th>\n",
       "      <td>AE3XVOCHEO5MTDIAIET5BZS26AJA</td>\n",
       "      <td>B07GPGVYGX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-03-12 03:28:00.854</td>\n",
       "      <td>254</td>\n",
       "      <td>3381</td>\n",
       "      <td>[-1, -1, -1, -1, 1188, 1510, 4399, 3089, 2290,...</td>\n",
       "      <td>0.458449</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258841</th>\n",
       "      <td>AESPJW3GNHXNJNW5CYV7PTEX44MQ</td>\n",
       "      <td>B07GZFM1ZM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-02-09 16:08:20.512</td>\n",
       "      <td>3190</td>\n",
       "      <td>921</td>\n",
       "      <td>[-1, -1, -1, -1, -1, 2569, 2742, 2855, 2351, 346]</td>\n",
       "      <td>0.505125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id parent_asin  rating  \\\n",
       "260331  AGMJWWTZ6HMM2FBRDLFW2CWMV5DQ  B00E0ISVLI     0.0   \n",
       "259198  AE3XVOCHEO5MTDIAIET5BZS26AJA  B07GPGVYGX     0.0   \n",
       "258841  AESPJW3GNHXNJNW5CYV7PTEX44MQ  B07GZFM1ZM     0.0   \n",
       "\n",
       "                     timestamp  user_indice  item_indice  \\\n",
       "260331 2021-07-18 15:44:29.739        10483         2563   \n",
       "259198 2021-03-12 03:28:00.854          254         3381   \n",
       "258841 2021-02-09 16:08:20.512         3190          921   \n",
       "\n",
       "                                            item_sequence  \\\n",
       "260331  [-1, 2906, 3011, 4674, 4593, 4755, 3810, 3921,...   \n",
       "259198  [-1, -1, -1, -1, 1188, 1510, 4399, 3089, 2290,...   \n",
       "258841  [-1, -1, -1, -1, -1, 2569, 2742, 2855, 2351, 346]   \n",
       "\n",
       "        classification_proba  label  \n",
       "260331              0.491368      0  \n",
       "259198              0.458449      0  \n",
       "258841              0.505125      0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classification_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report = log_classification_metrics(\n",
    "    args,\n",
    "    eval_classification_df,\n",
    "    target_col=\"label\",\n",
    "    prediction_col=\"classification_proba\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258263</th>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B004FV4ROA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-12-27 00:30:31.146</td>\n",
       "      <td>11295</td>\n",
       "      <td>3051</td>\n",
       "      <td>[1715, 2537, 3743, 506, 4490, 3479, 3908, 2723...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258264</th>\n",
       "      <td>AEHS7YR7BGGWMZS24H5UR5IP46HQ</td>\n",
       "      <td>B08F1P3BCC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-12-27 01:44:52.242</td>\n",
       "      <td>1784</td>\n",
       "      <td>3316</td>\n",
       "      <td>[-1, -1, -1, -1, -1, 3382, 4330, 423, 3167, 2677]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258265</th>\n",
       "      <td>AGAVHCK42EGMVS7DGPRX6HBCUCNQ</td>\n",
       "      <td>B09Q3NR84W</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-12-27 02:25:48.357</td>\n",
       "      <td>9042</td>\n",
       "      <td>32</td>\n",
       "      <td>[-1, -1, -1, -1, 3104, 1416, 3743, 2694, 3612,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127395</th>\n",
       "      <td>AEFVBMCJAFNULDI5V2CKKTBCPURA</td>\n",
       "      <td>B07N1L5HX1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-12-27 02:32:15.171</td>\n",
       "      <td>1542</td>\n",
       "      <td>3550</td>\n",
       "      <td>[-1, -1, -1, -1, -1, 1320, 2162, 2472, 2694, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127396</th>\n",
       "      <td>AGLXMKHBLTBNT3X2CLBAPW6QUTQA</td>\n",
       "      <td>B0BB6Y5N3M</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-12-27 03:37:22.772</td>\n",
       "      <td>10418</td>\n",
       "      <td>4471</td>\n",
       "      <td>[341, 3803, 4431, 1067, 4530, 4018, 2688, 4365...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261735</th>\n",
       "      <td>AGGDNWGN3NDJ2DI5CBSFOMUAM6XA</td>\n",
       "      <td>B083YHS7SV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-18 19:43:25.492</td>\n",
       "      <td>9711</td>\n",
       "      <td>2513</td>\n",
       "      <td>[-1, -1, -1, -1, 1019, 754, 2059, 413, 4262, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130866</th>\n",
       "      <td>AEKUF6AOVWDWFYOKPWO2CV72PEDQ</td>\n",
       "      <td>B07QN33986</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-02-19 01:32:51.519</td>\n",
       "      <td>2171</td>\n",
       "      <td>3626</td>\n",
       "      <td>[-1, -1, 2627, 4216, 4743, 1945, 2355, 1831, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130867</th>\n",
       "      <td>AFBTD25HPE4BE4LUFV3DTI2E2N2A</td>\n",
       "      <td>B07TMJ8S5Z</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-02-19 16:49:57.966</td>\n",
       "      <td>5159</td>\n",
       "      <td>3699</td>\n",
       "      <td>[-1, -1, -1, -1, 2260, 3517, 3609, 3495, 3625,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261740</th>\n",
       "      <td>AHLN6GKTKZE22AON34YAQXTGK63A</td>\n",
       "      <td>B0C682GZ5X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-19 17:28:55.519</td>\n",
       "      <td>14550</td>\n",
       "      <td>2383</td>\n",
       "      <td>[-1, -1, -1, -1, -1, 1812, 4165, 4575, 4807, 374]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261741</th>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B091K4WYD1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-19 22:08:53.253</td>\n",
       "      <td>2446</td>\n",
       "      <td>2502</td>\n",
       "      <td>[2677, 1610, 2694, 3695, 4429, 3602, 4569, 365...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2424 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id parent_asin  rating  \\\n",
       "258263  AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B004FV4ROA     0.0   \n",
       "258264  AEHS7YR7BGGWMZS24H5UR5IP46HQ  B08F1P3BCC     0.0   \n",
       "258265  AGAVHCK42EGMVS7DGPRX6HBCUCNQ  B09Q3NR84W     0.0   \n",
       "127395  AEFVBMCJAFNULDI5V2CKKTBCPURA  B07N1L5HX1     5.0   \n",
       "127396  AGLXMKHBLTBNT3X2CLBAPW6QUTQA  B0BB6Y5N3M     5.0   \n",
       "...                              ...         ...     ...   \n",
       "261735  AGGDNWGN3NDJ2DI5CBSFOMUAM6XA  B083YHS7SV     0.0   \n",
       "130866  AEKUF6AOVWDWFYOKPWO2CV72PEDQ  B07QN33986     5.0   \n",
       "130867  AFBTD25HPE4BE4LUFV3DTI2E2N2A  B07TMJ8S5Z     5.0   \n",
       "261740  AHLN6GKTKZE22AON34YAQXTGK63A  B0C682GZ5X     0.0   \n",
       "261741  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B091K4WYD1     0.0   \n",
       "\n",
       "                     timestamp  user_indice  item_indice  \\\n",
       "258263 2020-12-27 00:30:31.146        11295         3051   \n",
       "258264 2020-12-27 01:44:52.242         1784         3316   \n",
       "258265 2020-12-27 02:25:48.357         9042           32   \n",
       "127395 2020-12-27 02:32:15.171         1542         3550   \n",
       "127396 2020-12-27 03:37:22.772        10418         4471   \n",
       "...                        ...          ...          ...   \n",
       "261735 2022-02-18 19:43:25.492         9711         2513   \n",
       "130866 2022-02-19 01:32:51.519         2171         3626   \n",
       "130867 2022-02-19 16:49:57.966         5159         3699   \n",
       "261740 2022-02-19 17:28:55.519        14550         2383   \n",
       "261741 2022-02-19 22:08:53.253         2446         2502   \n",
       "\n",
       "                                            item_sequence  \n",
       "258263  [1715, 2537, 3743, 506, 4490, 3479, 3908, 2723...  \n",
       "258264  [-1, -1, -1, -1, -1, 3382, 4330, 423, 3167, 2677]  \n",
       "258265  [-1, -1, -1, -1, 3104, 1416, 3743, 2694, 3612,...  \n",
       "127395  [-1, -1, -1, -1, -1, 1320, 2162, 2472, 2694, 3...  \n",
       "127396  [341, 3803, 4431, 1067, 4530, 4018, 2688, 4365...  \n",
       "...                                                   ...  \n",
       "261735  [-1, -1, -1, -1, 1019, 754, 2059, 413, 4262, 3...  \n",
       "130866  [-1, -1, 2627, 4216, 4743, 1945, 2355, 1831, 9...  \n",
       "130867  [-1, -1, -1, -1, 2260, 3517, 3609, 3495, 3625,...  \n",
       "261740  [-1, -1, -1, -1, -1, 1812, 4165, 4575, 4807, 374]  \n",
       "261741  [2677, 1610, 2694, 3695, 4429, 3602, 4569, 365...  \n",
       "\n",
       "[2424 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_recs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2b0069da0848d8ba71344d808e55fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating recommendations:   0%|          | 0/364964 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m recommendations = \u001b[43mbest_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecommend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_recs_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser_indice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_recs_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mitem_sequence\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtop_K\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\..\\src\\algo\\sequence\\model.py:329\u001b[39m, in \u001b[36mSequenceRatingPrediction.recommend\u001b[39m\u001b[34m(self, users, item_sequences, k, batch_size)\u001b[39m\n\u001b[32m    327\u001b[39m             batch_scores = \u001b[38;5;28mself\u001b[39m.predict(batch_users, batch_sequences, batch_items, target_metadata=batch_items)\n\u001b[32m    328\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m             batch_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_users\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_items\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m         all_scores.append(batch_scores)\n\u001b[32m    332\u001b[39m \u001b[38;5;66;03m# Concatenate all scores and reshape\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\..\\src\\algo\\sequence\\model.py:264\u001b[39m, in \u001b[36mSequenceRatingPrediction.predict\u001b[39m\u001b[34m(self, user, item_sequence, target_item, target_metadata)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, user, item_sequence, target_item, target_metadata=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    252\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[33;03m    Predict the rating for a specific user and item sequence using the forward method\u001b[39;00m\n\u001b[32m    254\u001b[39m \u001b[33;03m    and applying a Sigmoid function to the output.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    262\u001b[39m \u001b[33;03m        torch.Tensor: Predicted rating after applying Sigmoid activation.\u001b[39;00m\n\u001b[32m    263\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     output_rating = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_item\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_item\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m     \u001b[38;5;66;03m# Apply sigmoid activation to the output\u001b[39;00m\n\u001b[32m    266\u001b[39m     output_rating = nn.Sigmoid()(output_rating)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\..\\src\\algo\\sequence\\model.py:169\u001b[39m, in \u001b[36mSequenceRatingPrediction.forward\u001b[39m\u001b[34m(self, user_ids, input_seq, target_item, target_metadata)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# Embed input sequence\u001b[39;00m\n\u001b[32m    167\u001b[39m embedded_seq = \u001b[38;5;28mself\u001b[39m.item_embedding(input_seq)  \u001b[38;5;66;03m# Shape: [batch_size, seq_len, embedding_dim]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m hidden_state = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43membedded_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Shape: [batch_size, seq_len, embedding_dim]\u001b[39;00m\n\u001b[32m    170\u001b[39m \u001b[38;5;66;03m# Get the last hidden state\u001b[39;00m\n\u001b[32m    171\u001b[39m hidden_state = hidden_state[:, -\u001b[32m1\u001b[39m, :]  \u001b[38;5;66;03m# Shape: [batch_size, embedding_dim]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:517\u001b[39m, in \u001b[36mTransformerEncoder.forward\u001b[39m\u001b[34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    514\u001b[39m is_causal = _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[32m    516\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     output = \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[32m    525\u001b[39m     output = output.to_padded_tensor(\u001b[32m0.0\u001b[39m, src.size())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:920\u001b[39m, in \u001b[36mTransformerEncoderLayer.forward\u001b[39m\u001b[34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    916\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m._ff_block(\u001b[38;5;28mself\u001b[39m.norm2(x))\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    918\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm1(\n\u001b[32m    919\u001b[39m         x\n\u001b[32m--> \u001b[39m\u001b[32m920\u001b[39m         + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    921\u001b[39m     )\n\u001b[32m    922\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm2(x + \u001b[38;5;28mself\u001b[39m._ff_block(x))\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:934\u001b[39m, in \u001b[36mTransformerEncoderLayer._sa_block\u001b[39m\u001b[34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    927\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sa_block\u001b[39m(\n\u001b[32m    928\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    929\u001b[39m     x: Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    932\u001b[39m     is_causal: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    933\u001b[39m ) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m934\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m    943\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dropout1(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1373\u001b[39m, in \u001b[36mMultiheadAttention.forward\u001b[39m\u001b[34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   1347\u001b[39m     attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[32m   1348\u001b[39m         query,\n\u001b[32m   1349\u001b[39m         key,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1370\u001b[39m         is_causal=is_causal,\n\u001b[32m   1371\u001b[39m     )\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1373\u001b[39m     attn_output, attn_output_weights = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m), attn_output_weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\functional.py:6230\u001b[39m, in \u001b[36mmulti_head_attention_forward\u001b[39m\u001b[34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   6226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_separate_proj_weight:\n\u001b[32m   6227\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m   6228\u001b[39m         in_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   6229\u001b[39m     ), \u001b[33m\"\u001b[39m\u001b[33muse_separate_proj_weight is False but in_proj_weight is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m6230\u001b[39m     q, k, v = \u001b[43m_in_projection_packed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6231\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6232\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m   6233\u001b[39m         q_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   6234\u001b[39m     ), \u001b[33m\"\u001b[39m\u001b[33muse_separate_proj_weight is True but q_proj_weight is None\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\functional.py:5614\u001b[39m, in \u001b[36m_in_projection_packed\u001b[39m\u001b[34m(q, k, v, w, b)\u001b[39m\n\u001b[32m   5611\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mis\u001b[39;00m v:\n\u001b[32m   5612\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m q \u001b[38;5;129;01mis\u001b[39;00m k:\n\u001b[32m   5613\u001b[39m         \u001b[38;5;66;03m# self-attention\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5614\u001b[39m         proj = \u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5615\u001b[39m         \u001b[38;5;66;03m# reshape to 3, E and not E, 3 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[39;00m\n\u001b[32m   5616\u001b[39m         proj = (\n\u001b[32m   5617\u001b[39m             proj.unflatten(-\u001b[32m1\u001b[39m, (\u001b[32m3\u001b[39m, E))\n\u001b[32m   5618\u001b[39m             .unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m   5621\u001b[39m             .contiguous()\n\u001b[32m   5622\u001b[39m         )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "recommendations = best_model.recommend(\n",
    "    torch.tensor(val_recs_df[\"user_indice\"].values, device=args.device),\n",
    "    torch.tensor(val_recs_df[\"item_sequence\"].values.tolist(), device=args.device),\n",
    "    k=args.top_K,\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_df = pd.DataFrame(recommendations).pipe(\n",
    "    create_rec_df, idm, args.user_col, args.item_col\n",
    ")\n",
    "recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = create_label_df(\n",
    "    val_df,\n",
    "    user_col=args.user_col,\n",
    "    item_col=args.item_col,\n",
    "    rating_col=args.rating_col,\n",
    "    timestamp_col=args.timestamp_col,\n",
    ")\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = merge_recs_with_target(\n",
    "    recommendations_df,\n",
    "    label_df,\n",
    "    k=args.top_K,\n",
    "    user_col=args.user_col,\n",
    "    item_col=args.item_col,\n",
    "    rating_col=args.rating_col,\n",
    ")\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_report = log_ranking_metrics(args, eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = [args]\n",
    "\n",
    "if args.log_to_mlflow:\n",
    "    run_id = trainer.logger.run_id\n",
    "\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        for params in all_params:\n",
    "            params_dict = params.model_dump()\n",
    "            params_ = dict()\n",
    "            for k, v in params_dict.items():\n",
    "                if k == \"top_K\":\n",
    "                    k = \"top_big_K\"\n",
    "                if k == \"top_k\":\n",
    "                    k = \"top_small_k\"\n",
    "                params_[f\"{params.__repr_name__()}.{k}\"] = v\n",
    "            mlflow.log_params(params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hm-scalablerecs-QHnDFvap-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
