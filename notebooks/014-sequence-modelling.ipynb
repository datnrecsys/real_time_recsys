{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydantic import BaseModel\n",
    "import sys\n",
    "import os\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from loguru import logger\n",
    "from load_dotenv import load_dotenv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import mlflow\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src.utils.embedding_id_mapper import IDMapper\n",
    "from src.algo.sequence.model import SequenceRatingPrediction\n",
    "from src.algo.sequence.dataset import UserItemBinaryRatingDFDataset\n",
    "from src.algo.sequence.trainer import SeqModellingLitModule\n",
    "from src.algo.item2vec.trainer import LitSkipGram\n",
    "from src.algo.item2vec.model import SkipGram\n",
    "from src.eval.utils import create_rec_df, create_label_df, merge_recs_with_target\n",
    "from src.eval.log_metrics import log_ranking_metrics, log_classification_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-25 21:43:48.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mSetting up Mlflow experiment: pruning-sequence-modelling, run_name: 006-sequence-modelling-attn-256-dim-bce-prelu\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"testing\": false,\n",
      "  \"log_to_mlflow\": true,\n",
      "  \"experiment_name\": \"pruning-sequence-modelling\",\n",
      "  \"notebook_persit_dp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\notebooks\\\\data\\\\pruning-sequence-modelling\\\\006-sequence-modelling-attn-256-dim-bce-prelu\",\n",
      "  \"run_name\": \"006-sequence-modelling-attn-256-dim-bce-prelu\",\n",
      "  \"user_col\": \"user_id\",\n",
      "  \"item_col\": \"parent_asin\",\n",
      "  \"rating_col\": \"rating\",\n",
      "  \"timestamp_col\": \"timestamp\",\n",
      "  \"group_name\": \"seq-modelling\",\n",
      "  \"top_K\": 100,\n",
      "  \"top_k\": 10,\n",
      "  \"batch_size\": 512,\n",
      "  \"learning_rate\": 0.001,\n",
      "  \"l2_reg\": 1e-6,\n",
      "  \"early_stopping_patience\": 10,\n",
      "  \"device\": \"cpu\",\n",
      "  \"max_epochs\": 100,\n",
      "  \"dropout\": 0.3,\n",
      "  \"embedding_dim\": 256,\n",
      "  \"use_user_embedding\": true,\n",
      "  \"user_embedding_dim\": 32,\n",
      "  \"use_metadata\": true,\n",
      "  \"metadata_embedding_dim\": 898,\n",
      "  \"metadata_fc_dim\": 64,\n",
      "  \"train_data_fp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\data_for_ai\\\\interim\\\\train_sample_interactions_16407u_neg_seq.parquet\",\n",
      "  \"val_data_fp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\data_for_ai\\\\interim\\\\val_sample_interactions_16407u_neg_seq.parquet\",\n",
      "  \"best_checkpoint_path\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Args(BaseModel):\n",
    "    testing: bool = False\n",
    "    log_to_mlflow: bool = True\n",
    "    experiment_name: str = \"pruning-sequence-modelling\"\n",
    "    notebook_persit_dp: str = None\n",
    "    \n",
    "    run_name: str = None\n",
    "\n",
    "    user_col: str = \"user_id\"\n",
    "    item_col: str = \"parent_asin\"\n",
    "    rating_col: str = \"rating\"\n",
    "    timestamp_col: str = \"timestamp\"\n",
    "    group_name: str = \"seq-modelling\"\n",
    "\n",
    "    top_K: int = 100\n",
    "    top_k: int = 10\n",
    "\n",
    "    batch_size: int = 512\n",
    "    learning_rate: float = 0.001\n",
    "    l2_reg: float = 1e-6\n",
    "    early_stopping_patience: int = 10\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    max_epochs: int = 100\n",
    "\n",
    "    # TwoTower specific\n",
    "    dropout: float = 0.3\n",
    "    embedding_dim: int = 256\n",
    "    use_user_embedding: bool = True\n",
    "    user_embedding_dim: int = 32\n",
    "\n",
    "    use_metadata: bool = True\n",
    "    metadata_embedding_dim: int = 898\n",
    "    metadata_fc_dim: int = 64\n",
    "\n",
    "\n",
    "    train_data_fp: str = os.path.abspath(\"../data_for_ai/interim/train_sample_interactions_16407u_neg_seq.parquet\")\n",
    "    val_data_fp: str = os.path.abspath(\"../data_for_ai/interim/val_sample_interactions_16407u_neg_seq.parquet\")\n",
    "\n",
    "    best_checkpoint_path: str = None\n",
    "    def init(self):\n",
    "        self.run_name: str = f\"006-sequence-modelling-attn-{self.embedding_dim}-dim-bce-prelu\"\n",
    "        self.notebook_persit_dp = os.path.abspath(f\"data/{self.experiment_name}/{self.run_name}\")\n",
    "\n",
    "        if not (mlflow_uri := os.environ.get(\"MLFLOW_TRACKING_URI\")):\n",
    "            self.log_to_mlflow = False\n",
    "            logger.warning(\"MLFlow is not enabled. Turn off tracking to Mlflow.\")\n",
    "\n",
    "        if self.log_to_mlflow:\n",
    "            logger.info(\n",
    "                f\"Setting up Mlflow experiment: {self.experiment_name}, run_name: {self.run_name}\"\n",
    "            )\n",
    "\n",
    "            self._mlf_logger = MLFlowLogger(\n",
    "                experiment_name=self.experiment_name,\n",
    "                run_name=self.run_name,\n",
    "                tracking_uri=mlflow_uri,\n",
    "                log_model=False,\n",
    "            )\n",
    "\n",
    "        if not self.testing:\n",
    "            os.makedirs(self.notebook_persit_dp, exist_ok=True)\n",
    "        return self\n",
    "    \n",
    "args = Args().init()\n",
    "print(args.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata embedding\n",
    "metadata_embedding_matrix = np.load(\"../data_for_ai/interim/item_embeddings.npy\")  # shape (4817, 898)\n",
    "metadata_embedding_tensor = torch.tensor(metadata_embedding_matrix, dtype=torch.float32)\n",
    "metadata_embedding_layer = nn.Embedding.from_pretrained(\n",
    "    embeddings=metadata_embedding_tensor,\n",
    "    freeze=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata embedding shape: torch.Size([4817, 898])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Metadata embedding shape: {metadata_embedding_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(n_users, n_items, embedding_dim, dropout, item_embedding=None,\n",
    "               user_embedding_dim=None,use_user_embedding=False,\n",
    "               use_metadata=False, metadata_embedding=None,\n",
    "               metadata_embedding_dim=898, metadata_fc_dim=256):\n",
    "    return SequenceRatingPrediction(\n",
    "        item_embedding=item_embedding,\n",
    "        num_users=n_users,\n",
    "        num_items=n_items,\n",
    "        embedding_dim=embedding_dim,\n",
    "        dropout=dropout,\n",
    "        user_embedding_dim=user_embedding_dim,\n",
    "        use_user_embedding=use_user_embedding,\n",
    "        use_metadata=use_metadata,\n",
    "        metadata_embedding=metadata_embedding,\n",
    "        metadata_embedding_dim=metadata_embedding_dim,\n",
    "        metadata_fc_dim=metadata_fc_dim,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning:\n",
      "\n",
      "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
      "\n",
      "\u001b[32m2025-06-25 21:43:50.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.sequence.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mStart token used: 4, Padding token used: 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1869]], grad_fn=<MaskedFillBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceRatingPrediction(\n",
       "  (item_embedding): Embedding(6, 32, padding_idx=5)\n",
       "  (encoder_layer): TransformerEncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (linear2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.3, inplace=False)\n",
       "    (dropout2): Dropout(p=0.3, inplace=False)\n",
       "    (activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "        (activation): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (prelu1): PReLU(num_parameters=1)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (metadata_embedding): Embedding(5, 32)\n",
       "  (metadata_fc): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (metadata_prelu): PReLU(num_parameters=1)\n",
       "  (item_tower_fc): Linear(in_features=48, out_features=32, bias=True)\n",
       "  (user_embedding): Embedding(3, 64)\n",
       "  (user_tower_fc): Linear(in_features=96, out_features=32, bias=True)\n",
       "  (final_fc): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (score_fc): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 32\n",
    "user_embedding_dim = 64\n",
    "batch_size = 2\n",
    "\n",
    "# Mock data\n",
    "user_indices = [0, 0, 1, 2, 2]\n",
    "item_indices = [0, 1, 2, 3, 4]\n",
    "timestamps = [0, 1, 2, 3, 4]\n",
    "ratings = [0, 3, 1, 3, 0]\n",
    "# item_sequences = [\n",
    "#     [2, 3, -1, -1],\n",
    "#     [2, 4, -1, -1],\n",
    "#     [1, 3, -1, -1],\n",
    "#     [2, 1, -1, -1],\n",
    "#     [4, 1, -1, -1],\n",
    "# ]\n",
    "\n",
    "item_sequences = [\n",
    "    [-1, -1, 2, 3],\n",
    "    [-1, -1, 2, 4],\n",
    "    [-1, -1, 1, 3],\n",
    "    [-1, -1, 2, 1],\n",
    "    [-1, -1, 4, 1],\n",
    "]\n",
    "\n",
    "\n",
    "n_users = len(set(user_indices))\n",
    "\n",
    "n_items = len(set(item_indices))\n",
    "\n",
    "train_df = pd.DataFrame(\n",
    "    {\n",
    "        \"user_indice\": user_indices,\n",
    "        \"item_indice\": item_indices,\n",
    "        args.timestamp_col: timestamps,\n",
    "        args.rating_col: ratings,\n",
    "        \"item_sequence\": item_sequences,\n",
    "    }\n",
    ")\n",
    "# Mock metadata embedding (giả sử mỗi item có 32 chiều metadata embedding)\n",
    "mock_metadata_embedding_matrix = np.random.randn(n_items, embedding_dim).astype(np.float32)\n",
    "mock_metadata_embedding_layer = nn.Embedding.from_pretrained(\n",
    "    embeddings=torch.tensor(mock_metadata_embedding_matrix),\n",
    "    freeze=True)\n",
    "\n",
    "model = init_model(n_users, \n",
    "                   n_items, \n",
    "                   embedding_dim, \n",
    "                   args.dropout,\n",
    "                   user_embedding_dim=user_embedding_dim,\n",
    "                   use_user_embedding=args.use_user_embedding,\n",
    "                   use_metadata=args.use_metadata,\n",
    "                   metadata_embedding=mock_metadata_embedding_layer,\n",
    "                   metadata_embedding_dim=embedding_dim,\n",
    "                   metadata_fc_dim=16,)\n",
    "\n",
    "# Example forward pass\n",
    "model.eval()\n",
    "user = torch.tensor([0])\n",
    "item_sequence = torch.tensor([[-0, 1, -1, -1]])\n",
    "target_item = torch.tensor([2])\n",
    "target_metadata = torch.tensor([2])  # giả sử metadata index trùng với item index\n",
    "predictions = model(user, item_sequence, target_item, target_metadata)\n",
    "print(predictions)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset = UserItemBinaryRatingDFDataset(\n",
    "    train_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col,\"item_sequence\"\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    rating_dataset, batch_size=batch_size, shuffle=False, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': tensor([0, 0]), 'item': tensor([0, 1]), 'rating': tensor([0., 1.]), 'item_sequence': tensor([[-1, -1,  2,  3],\n",
      "        [-1, -1,  2,  4]], dtype=torch.int32)}\n",
      "{'user': tensor([1, 2]), 'item': tensor([2, 3]), 'rating': tensor([1., 1.]), 'item_sequence': tensor([[-1, -1,  1,  3],\n",
      "        [-1, -1,  2,  1]], dtype=torch.int32)}\n"
     ]
    }
   ],
   "source": [
    "for batch_input in train_loader:\n",
    "    print(batch_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "lit_model = SeqModellingLitModule(model, log_dir=args.notebook_persit_dp)\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=f\"{args.notebook_persit_dp}/test\",\n",
    "    max_epochs=100,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    ")\n",
    "# trainer.fit(\n",
    "#     model=lit_model, train_dataloaders=train_loader, val_dataloaders=train_loader\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5266]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "user = torch.tensor([0])\n",
    "item_sequence = torch.tensor([[-1, -1, -1, 0, 1]])\n",
    "target_item = torch.tensor([2])\n",
    "target_metadata = torch.tensor([2])  # giả sử metadata index trùng với item index\n",
    "predictions = model.predict(user, item_sequence, target_item,target_metadata)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(args.train_data_fp)\n",
    "val_df = pd.read_parquet(args.val_data_fp)\n",
    "\n",
    "assert set(val_df[args.user_col].unique()).issubset(set(train_df[args.user_col].unique())), \"Validation users must be present in training users.\"\n",
    "\n",
    "assert set(val_df[args.item_col].unique()).issubset(set(train_df[args.item_col].unique())), \"Validation items must be present in training items.\"\n",
    "assert train_df[args.timestamp_col].max() < val_df[args.timestamp_col].min(), \"Validation data must be after training data. Otherwise, its a data contamination problem.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151343</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B009RUZ7TS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:15:55.000</td>\n",
       "      <td>1412</td>\n",
       "      <td>4220</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 455...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40958</th>\n",
       "      <td>AF7KZV4NJ5GBDVFTB7PEEUN4U53A</td>\n",
       "      <td>B0BBMLD8QT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-07-29 20:38:06.000</td>\n",
       "      <td>4871</td>\n",
       "      <td>4476</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218918</th>\n",
       "      <td>AFVQ4K4KZPLQ3E2VFYSGX6HFXGNQ</td>\n",
       "      <td>B0BB6R89VF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-12-13 20:35:02.334</td>\n",
       "      <td>7616</td>\n",
       "      <td>1218</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43115</th>\n",
       "      <td>AFCLWJMGYFCOJQR7T4454OF5A5WA</td>\n",
       "      <td>B00ENFP224</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-09-06 12:09:59.000</td>\n",
       "      <td>5250</td>\n",
       "      <td>1355</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233421</th>\n",
       "      <td>AFP4PHJ6Q2RRXLDPSDSH6VXJRUTA</td>\n",
       "      <td>B07CMXS5FP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-11-23 09:44:21.734</td>\n",
       "      <td>6792</td>\n",
       "      <td>838</td>\n",
       "      <td>[-1.0, -1.0, -1.0, 1055.0, 3572.0, 3865.0, 176...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250960</th>\n",
       "      <td>AGQHC7YNLYP4QV2PSBD6URSMJSVA</td>\n",
       "      <td>B07H65KP63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-02-08 04:09:50.457</td>\n",
       "      <td>11001</td>\n",
       "      <td>3568</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, 3585.0, 1866.0, 4040....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217058</th>\n",
       "      <td>AHD65JAOVTTPDNJWOLSSGS3QVK6Q</td>\n",
       "      <td>B07DKMJ61N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-11-02 15:25:18.351</td>\n",
       "      <td>13410</td>\n",
       "      <td>4239</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61324</th>\n",
       "      <td>AF32PWYNLPCVAU4UX35IEAZOFA3Q</td>\n",
       "      <td>B011BRUOMO</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-07-18 05:42:21.000</td>\n",
       "      <td>4264</td>\n",
       "      <td>2253</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132003</th>\n",
       "      <td>AGM65FYYAPHOLESGIDMFMPUQIYNA</td>\n",
       "      <td>B0016BVDIK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010-12-16 19:59:19.000</td>\n",
       "      <td>10445</td>\n",
       "      <td>4250</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34752</th>\n",
       "      <td>AFVQ4K4KZPLQ3E2VFYSGX6HFXGNQ</td>\n",
       "      <td>B00DR0B6XK</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015-04-02 17:48:23.000</td>\n",
       "      <td>7616</td>\n",
       "      <td>1293</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254784 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id parent_asin  rating  \\\n",
       "151343  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B009RUZ7TS     0.0   \n",
       "40958   AF7KZV4NJ5GBDVFTB7PEEUN4U53A  B0BBMLD8QT     5.0   \n",
       "218918  AFVQ4K4KZPLQ3E2VFYSGX6HFXGNQ  B0BB6R89VF     0.0   \n",
       "43115   AFCLWJMGYFCOJQR7T4454OF5A5WA  B00ENFP224     5.0   \n",
       "233421  AFP4PHJ6Q2RRXLDPSDSH6VXJRUTA  B07CMXS5FP     0.0   \n",
       "...                              ...         ...     ...   \n",
       "250960  AGQHC7YNLYP4QV2PSBD6URSMJSVA  B07H65KP63     0.0   \n",
       "217058  AHD65JAOVTTPDNJWOLSSGS3QVK6Q  B07DKMJ61N     0.0   \n",
       "61324   AF32PWYNLPCVAU4UX35IEAZOFA3Q  B011BRUOMO     5.0   \n",
       "132003  AGM65FYYAPHOLESGIDMFMPUQIYNA  B0016BVDIK     0.0   \n",
       "34752   AFVQ4K4KZPLQ3E2VFYSGX6HFXGNQ  B00DR0B6XK     4.0   \n",
       "\n",
       "                     timestamp  user_indice  item_indice  \\\n",
       "151343 2014-07-17 19:15:55.000         1412         4220   \n",
       "40958  2015-07-29 20:38:06.000         4871         4476   \n",
       "218918 2017-12-13 20:35:02.334         7616         1218   \n",
       "43115  2015-09-06 12:09:59.000         5250         1355   \n",
       "233421 2018-11-23 09:44:21.734         6792          838   \n",
       "...                        ...          ...          ...   \n",
       "250960 2020-02-08 04:09:50.457        11001         3568   \n",
       "217058 2017-11-02 15:25:18.351        13410         4239   \n",
       "61324  2016-07-18 05:42:21.000         4264         2253   \n",
       "132003 2010-12-16 19:59:19.000        10445         4250   \n",
       "34752  2015-04-02 17:48:23.000         7616         1293   \n",
       "\n",
       "                                            item_sequence  \n",
       "151343  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 455...  \n",
       "40958   [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "218918  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 129...  \n",
       "43115   [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "233421  [-1.0, -1.0, -1.0, 1055.0, 3572.0, 3865.0, 176...  \n",
       "...                                                   ...  \n",
       "250960  [-1.0, -1.0, -1.0, -1.0, 3585.0, 1866.0, 4040....  \n",
       "217058  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "61324   [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "132003  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "34752   [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "\n",
       "[254784 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172167</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B07C1RSV9C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-08-05 16:31:49</td>\n",
       "      <td>1412</td>\n",
       "      <td>934</td>\n",
       "      <td>[-1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0, 3295.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41296</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B07C1RSV9C</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-08-05 16:31:49</td>\n",
       "      <td>1412</td>\n",
       "      <td>3276</td>\n",
       "      <td>[-1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0, 3295.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151346</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B07CB22VVJ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:19:28</td>\n",
       "      <td>1412</td>\n",
       "      <td>4599</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20475</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B07CB22VVJ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:19:28</td>\n",
       "      <td>1412</td>\n",
       "      <td>3295</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20474</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B000I23TTE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:16:43</td>\n",
       "      <td>1412</td>\n",
       "      <td>107</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151345</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B000I23TTE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:16:43</td>\n",
       "      <td>1412</td>\n",
       "      <td>4659</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151344</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0BYSP9676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:16:20</td>\n",
       "      <td>1412</td>\n",
       "      <td>3678</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20473</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0BYSP9676</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:16:20</td>\n",
       "      <td>1412</td>\n",
       "      <td>4685</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151343</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B009RUZ7TS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:15:55</td>\n",
       "      <td>1412</td>\n",
       "      <td>4220</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20472</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B009RUZ7TS</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:15:55</td>\n",
       "      <td>1412</td>\n",
       "      <td>1047</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20471</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0787JNNXH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:12:09</td>\n",
       "      <td>1412</td>\n",
       "      <td>3164</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151342</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0787JNNXH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:12:09</td>\n",
       "      <td>1412</td>\n",
       "      <td>121</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151341</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0B7FN67QT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:11:53</td>\n",
       "      <td>1412</td>\n",
       "      <td>4653</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20470</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0B7FN67QT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:11:53</td>\n",
       "      <td>1412</td>\n",
       "      <td>4443</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20469</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0BM6ZLKPL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-07-17 19:11:13</td>\n",
       "      <td>1412</td>\n",
       "      <td>4559</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151340</th>\n",
       "      <td>AEEV5YWQKPBTLFWHKOBBULYA2RDQ</td>\n",
       "      <td>B0BM6ZLKPL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-07-17 19:11:13</td>\n",
       "      <td>1412</td>\n",
       "      <td>2004</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id parent_asin  rating           timestamp  \\\n",
       "172167  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B07C1RSV9C     0.0 2015-08-05 16:31:49   \n",
       "41296   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B07C1RSV9C     5.0 2015-08-05 16:31:49   \n",
       "151346  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B07CB22VVJ     0.0 2014-07-17 19:19:28   \n",
       "20475   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B07CB22VVJ     5.0 2014-07-17 19:19:28   \n",
       "20474   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B000I23TTE     5.0 2014-07-17 19:16:43   \n",
       "151345  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B000I23TTE     0.0 2014-07-17 19:16:43   \n",
       "151344  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0BYSP9676     0.0 2014-07-17 19:16:20   \n",
       "20473   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0BYSP9676     5.0 2014-07-17 19:16:20   \n",
       "151343  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B009RUZ7TS     0.0 2014-07-17 19:15:55   \n",
       "20472   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B009RUZ7TS     5.0 2014-07-17 19:15:55   \n",
       "20471   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0787JNNXH     5.0 2014-07-17 19:12:09   \n",
       "151342  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0787JNNXH     0.0 2014-07-17 19:12:09   \n",
       "151341  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0B7FN67QT     0.0 2014-07-17 19:11:53   \n",
       "20470   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0B7FN67QT     5.0 2014-07-17 19:11:53   \n",
       "20469   AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0BM6ZLKPL     5.0 2014-07-17 19:11:13   \n",
       "151340  AEEV5YWQKPBTLFWHKOBBULYA2RDQ  B0BM6ZLKPL     0.0 2014-07-17 19:11:13   \n",
       "\n",
       "        user_indice  item_indice  \\\n",
       "172167         1412          934   \n",
       "41296          1412         3276   \n",
       "151346         1412         4599   \n",
       "20475          1412         3295   \n",
       "20474          1412          107   \n",
       "151345         1412         4659   \n",
       "151344         1412         3678   \n",
       "20473          1412         4685   \n",
       "151343         1412         4220   \n",
       "20472          1412         1047   \n",
       "20471          1412         3164   \n",
       "151342         1412          121   \n",
       "151341         1412         4653   \n",
       "20470          1412         4443   \n",
       "20469          1412         4559   \n",
       "151340         1412         2004   \n",
       "\n",
       "                                                                    item_sequence  \n",
       "172167  [-1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0, 3295.0]  \n",
       "41296   [-1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0, 3295.0]  \n",
       "151346    [-1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0]  \n",
       "20475     [-1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0, 107.0]  \n",
       "20474      [-1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0]  \n",
       "151345     [-1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0, 4685.0]  \n",
       "151344       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0]  \n",
       "20473        [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0, 1047.0]  \n",
       "151343         [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0]  \n",
       "20472          [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0, 3164.0]  \n",
       "20471            [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0]  \n",
       "151342           [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0, 4443.0]  \n",
       "151341             [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0]  \n",
       "20470              [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4559.0]  \n",
       "20469                [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]  \n",
       "151340               [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(train_df.loc[train_df[\"user_id\"] == \"AEEV5YWQKPBTLFWHKOBBULYA2RDQ\"].sort_values(by=args.timestamp_col, ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert user_id and item_id into indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idm_path = os.path.abspath(\"../data_for_ai/interim/idm_16407u.json\")\n",
    "# idm = IDMapper().load(idm_path)\n",
    "# idm.get_user_id(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.pipe(idm.map_indices)\n",
    "# val_df = val_df.pipe(idm.map_indices)\n",
    "\n",
    "# assert idm.unknown_item_index not in train_df[\"item_indice\"].values, \"Unknown item index must be present in training data.\"\n",
    "# assert idm.unknown_user_index not in train_df[\"user_indice\"].values, \"Unknown user index must be present in training data.\"\n",
    "# assert idm.unknown_item_index not in val_df[\"item_indice\"].values, \"Unknown item index must be present in validation data.\"\n",
    "# assert idm.unknown_user_index not in val_df[\"user_indice\"].values, \"Unknown user index must be present in validation data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert train_df.groupby(args.user_col)[args.item_col].nunique().min() >= 5, \"Each user must have at least five items.\"\n",
    "# assert train_df.groupby(args.item_col)[args.user_col].nunique().min() >= 10, \"Each item must have at least ten users.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset = UserItemBinaryRatingDFDataset(\n",
    "    train_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col, \"item_sequence\"\n",
    ")\n",
    "val_rating_dataset = UserItemBinaryRatingDFDataset(\n",
    "    val_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col, \"item_sequence\"\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    rating_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_rating_dataset, batch_size=args.batch_size, shuffle=False, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the weight from SkipGram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-25 21:43:57.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mNumber of users: 16407, Number of items: 4817\u001b[0m\n",
      "\u001b[32m2025-06-25 21:43:57.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.item2vec.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mInitializing item embeddings with num items 4817, embedding dim 256\u001b[0m\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\utilities\\migration\\utils.py:56: PossibleUserWarning:\n",
      "\n",
      "The loaded checkpoint was produced with Lightning v2.5.2, which is newer than your current Lightning version: v2.5.0\n",
      "\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning:\n",
      "\n",
      "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
      "\n",
      "\u001b[32m2025-06-25 21:43:58.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.sequence.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mStart token used: 4816, Padding token used: 4817\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkipGram Item embedding shape: torch.Size([4818, 256])\n",
      "SkipGram Item embedding dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "item_indices = train_df[args.item_col].unique()\n",
    "user_indices = train_df[args.user_col].unique()\n",
    "n_items = len(item_indices)\n",
    "n_users = len(user_indices)\n",
    "\n",
    "logger.info(f\"Number of users: {n_users}, Number of items: {n_items}\")\n",
    "\n",
    "assert args.embedding_dim == 256, \"Embedding dimension must be 256\"\n",
    "best_trainer = LitSkipGram.load_from_checkpoint(\n",
    "    \"../data_for_ai/interim/best-item2vec-weight.ckpt\",\n",
    "    skipgram_model=SkipGram(n_items, args.embedding_dim).to(args.device),\n",
    ")\n",
    "skipgram_item_embedding = best_trainer.skipgram_model.embeddings.weight.data.cpu()\n",
    "print(f\"SkipGram Item embedding shape: {skipgram_item_embedding.shape}\")\n",
    "print(f\"SkipGram Item embedding dtype: {skipgram_item_embedding.dtype}\")\n",
    "# convert skipgram_item_embedding into torch.nn.Embedding and take the first n_items rows\n",
    "skipgram_item_embedding = torch.nn.Embedding.from_pretrained(\n",
    "    skipgram_item_embedding[:n_items], freeze=False\n",
    ")\n",
    "\n",
    "model = init_model(n_users, \n",
    "                   n_items, \n",
    "                   args.embedding_dim, \n",
    "                   args.dropout, \n",
    "                   item_embedding=skipgram_item_embedding,\n",
    "                   user_embedding_dim=args.user_embedding_dim,\n",
    "                   use_user_embedding=args.use_user_embedding,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4817 items in the dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AE227WAM4NWQPJI33OPN7ZARNNZQ'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idm_path = os.path.abspath(\"../data_for_ai/interim/idm_16407u.json\")\n",
    "idm = IDMapper().load(idm_path)\n",
    "idm.get_user_id(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-25 21:43:59.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.sequence.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mStart token used: 4816, Padding token used: 4817\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n",
      "\n",
      "  | Name               | Type                     | Params | Mode \n",
      "------------------------------------------------------------------------\n",
      "0 | model              | SequenceRatingPrediction | 7.2 M  | train\n",
      "1 | val_roc_auc_metric | BinaryAUROC              | 0      | train\n",
      "2 | val_pr_auc_metric  | BinaryAveragePrecision   | 0      | train\n",
      "------------------------------------------------------------------------\n",
      "2.9 M     Trainable params\n",
      "4.3 M     Non-trainable params\n",
      "7.2 M     Total params\n",
      "28.884    Total estimated model params size (MB)\n",
      "38        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1554ababc17a4acdbb4bae4352ad3c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:252: UserWarning:\n",
      "\n",
      "You requested to overfit but enabled val dataloader shuffling. We are turning off the val dataloader shuffling for you.\n",
      "\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: PossibleUserWarning:\n",
      "\n",
      "The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:252: UserWarning:\n",
      "\n",
      "You requested to overfit but enabled train dataloader shuffling. We are turning off the train dataloader shuffling for you.\n",
      "\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: PossibleUserWarning:\n",
      "\n",
      "The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:310: PossibleUserWarning:\n",
      "\n",
      "The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c472038dea41b99c57c39a077e809a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193f2c43543a4115ae41d2783b1d3f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff767d55d1f417f92f508f5a7938de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31097b2ec0094be1a99a621ec2b60250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf8d062594f49f684eacd8f4fe8037f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a98f9ca39f4812837481d5c1d59e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95670e1a74e4ff594445add0eb90c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2e961e2991402d962224560961a22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e4a70387134f01a85555800b15faa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b9b620e1914d40b49fe24b4309923a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b91b69d865409cb5ae26aca0dc2e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c26a27767b1441190c4b2d6c746899f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8539201e78e4987a5191d4211d2eb52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026ef7c552794db1b77e97a1dd4743a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d842fe58835d46ce85422f85ef86aeb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f760843912643389c234fc65b584841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccaf3e40c794282ab1ef954fc68bdad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cdca42643042b7a7088615c00311d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb754be2b4347cab355b8ba250afa57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731faa1b46264ebfa3e794a597d29a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099b240c866846e6b3fa78b277c39f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4615f93adba14f7aa0a208ab4d964a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:47\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:575\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    569\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    570\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    571\u001b[39m     ckpt_path,\n\u001b[32m    572\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    573\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    574\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:982\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m    979\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m    980\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m    986\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1026\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:150\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:282\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    281\u001b[39m dataloader_iter = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m batch, _, __ = \u001b[38;5;28mnext\u001b[39m(data_fetcher)\n\u001b[32m    283\u001b[39m \u001b[38;5;66;03m# TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# fetcher state so that the batch_idx is correct after restarting\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\fetchers.py:134\u001b[39m, in \u001b[36m_PrefetchDataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done:\n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     batch = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\fetchers.py:61\u001b[39m, in \u001b[36m_DataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     batch = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterator)\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\utilities\\combined_loader.py:341\u001b[39m, in \u001b[36mCombinedLoader.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m out = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m._iterator)\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._iterator, _Sequential):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\utilities\\combined_loader.py:78\u001b[39m, in \u001b[36m_MaxSizeCycle.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     out[i] = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterators[i])\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    763\u001b[39m index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\..\\src\\algo\\sequence\\dataset.py:38\u001b[39m, in \u001b[36mUserItemRatingDFDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     32\u001b[39m item_sequence = \u001b[38;5;28mself\u001b[39m.df[\u001b[38;5;28mself\u001b[39m.item_seq_col].iloc[idx] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.item_seq_col \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m     35\u001b[39m     user=torch.as_tensor(user),\n\u001b[32m     36\u001b[39m     item=torch.as_tensor(item),\n\u001b[32m     37\u001b[39m     rating=torch.as_tensor(rating),\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     item_sequence=\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem_sequence\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m item_sequence \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     39\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[32m     25\u001b[39m trainer = L.Trainer(\n\u001b[32m     26\u001b[39m     default_root_dir=log_dir,\n\u001b[32m     27\u001b[39m     accelerator=args.device \u001b[38;5;28;01mif\u001b[39;00m args.device \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     callbacks=[early_stopping],\n\u001b[32m     31\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLogs available at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.log_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:539\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28mself\u001b[39m.state.status = TrainerStatus.RUNNING\n\u001b[32m    538\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:64\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     63\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     67\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=5, mode=\"min\", verbose=False\n",
    ")\n",
    "\n",
    "model = init_model(n_users, n_items, args.embedding_dim, args.dropout,item_embedding=skipgram_item_embedding,\n",
    "                   user_embedding_dim=args.user_embedding_dim,\n",
    "                   use_user_embedding=args.use_user_embedding,\n",
    "                   use_metadata=args.use_metadata,\n",
    "                   metadata_embedding=metadata_embedding_layer,\n",
    "                   metadata_embedding_dim=args.metadata_embedding_dim,\n",
    "                   metadata_fc_dim=args.metadata_fc_dim,)\n",
    "\n",
    "lit_model = SeqModellingLitModule(\n",
    "    model,\n",
    "    learning_rate=args.learning_rate,\n",
    "    l2_reg=args.l2_reg,\n",
    "    log_dir=args.notebook_persit_dp,\n",
    "    accelerator=args.device,\n",
    "    idm= idm\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persit_dp}/logs/overfit\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    max_epochs=100,\n",
    "    overfit_batches=1,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=train_loader,\n",
    ")\n",
    "logger.info(f\"Logs available at {trainer.log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': tensor([ 4370, 13216, 16170,  2135,   129, 15561, 15435, 14387,  9348,  5133,\n",
      "         8751,  4228, 14588,  9103,  1698,  4685, 10937, 13298,  3041,  5409,\n",
      "        10391,  3393, 12080, 10371, 14551,  1273,  4031,  9985,  1274, 16074,\n",
      "         2357,  7172,  7804,   126, 13949, 11546,  1916,  4193,  3398,  5041,\n",
      "         5960,  1233,  9317, 10240, 10098, 16269,  3631, 11147,  2731,  4282,\n",
      "        16024, 11205,   158,  7136, 11180,  7812,  3997,  6685, 13818, 16206,\n",
      "         2568, 13927,  3869,  6671,   794, 12310, 13313, 11553, 12476,  1635,\n",
      "         4632,  1355,  2099,  5032, 10526,  9409,  9389,  5650,  8826,  2841,\n",
      "        11812,  9467, 13315,  6020, 14166, 12567,  7949,  3147,  2232,  1150,\n",
      "          432, 15161,  4045, 11867, 15038, 10019, 10430,  7720,  7722, 11151,\n",
      "         1554,  2741,  2908,  2503,  9664, 16095,    88, 13082, 12950,  2362,\n",
      "         2087,  8687, 16155,  8329, 16206, 11907,  7273,  5945, 13895, 15737,\n",
      "        13809,  1363,  3169,  2588, 11634,  1181,  6886, 15929,  7624,   148,\n",
      "         1966,  8482, 11985, 13474,  1625, 10857, 10423,  6183, 10832,  9137,\n",
      "         1554, 12819,   246,   617, 14571, 14732,  4363,  5635, 14938, 12376,\n",
      "         3477,  9987, 11692,  5453,  4226,  9448,  1260, 15876, 10876, 12383,\n",
      "         1153,  2943,  5255,  2014,  4095,  8347, 15500,  7853,   136,  4800,\n",
      "         5943,  8208, 14864, 15694,  7605,  4743,  9191, 10903,   131,  3407,\n",
      "          766,  5241,  1754, 10778,  5046,  4417,  4358, 14276, 16320,  1182,\n",
      "         4813,  8216,  3724, 10946, 15449,  6130, 11849,  3576,   240,  3764,\n",
      "         3262,  8144,   793,  7406,  7245, 10586,  4362, 15119,  9740,  1140,\n",
      "         3006,  9362, 10256,  6127,   777, 15995,  7675,  5736,  7671,  3283,\n",
      "        10287,  3505,  3338, 10570,   186,  4225, 13800,  6134, 14925,  9899,\n",
      "         8157,  8984, 15764, 12158,  8684, 13196,  1700,  1354, 13399,  5928,\n",
      "         8490,   552, 11199,  6153,  1515,  2365,  1602, 11747,  3568,  1640,\n",
      "         4268,   884,  7539,  9542,  4574, 10456, 11032, 15751,  7778,  6946,\n",
      "        13199,  4583,  1030, 11700,   821, 14999, 14263,  9393,  5056,  3335,\n",
      "         6275,  5829,   120, 14909, 13324,  9828, 15512, 14319,  8890,  3591,\n",
      "        12077,  9297,  9212,  5172,  3192, 13250, 14988,  7382,  7146, 10279,\n",
      "         4847,  7159,  8661, 14053, 16308,  6034, 10256,  2414,  7070,  9404,\n",
      "         6116,  6453, 10858, 15673, 14066,  8930, 12472, 12380,  6022,  1387,\n",
      "        11595,  5607,  5410,  6334, 15486, 13065, 13948,  9184,  7949,  3197,\n",
      "         1353,  4933,  8094,  5762, 14307,  4023, 11577,  5588, 16007, 15198,\n",
      "         5538,  7158,  7518,  9363, 15472,  1848,  2443, 10110,  8653,  6670,\n",
      "        13539,  7758, 11784,  8466,  9214,  6323,  4971, 15332,  4103,  2380,\n",
      "         3377,  4003,  9349,  3771,  7052, 14778,  5303, 10694,  9182,  7675,\n",
      "         2368,  2821,   351,  2265, 12124, 14234, 13185,  1618, 12463, 16182,\n",
      "        13007, 13588,  6010, 11285, 15681, 14441,  5254,  9149,  3832, 15275,\n",
      "         8435,  9041, 13150, 12329, 11081,  8198,  7439,  5613,  9251,  5893,\n",
      "         8055,  9579, 13022,  4439,  1031,    74,  7243, 11623,  6018, 11802,\n",
      "         9211,    64, 11257,  7559,  3091,  6531,  4624, 10465,  7904,  5463,\n",
      "         7973,  4191,  2133, 14704, 12174,  6116,  9618,  7198, 14062, 13862,\n",
      "        15382, 10716, 13643, 16110, 10769,   734, 11619,   879,  1049,  2291,\n",
      "         3335,  8617,  4636, 15153,  9966, 15673,  1797, 11993,    35, 11080,\n",
      "         4009, 13515,  9521,  8177, 10887,  8749,  3610,  3385,  6855,   654,\n",
      "        15098, 10685,  8700, 11412,  6666, 15203, 12356, 11374,   896,  2442,\n",
      "         4603, 10164, 14428,  5443,  6610, 12463,  2747,  5937, 12160, 11665,\n",
      "         1188,  4027,  2506,  1792,  8092, 13108, 10590, 13112,  2053,  3039,\n",
      "         2513,  3958,  1637,  3788,  6259,  6695,  4234, 12497,  4518, 16224,\n",
      "         2087, 11213, 11156,  3965, 12799,  9465,  8965,  3889, 13170,  5134,\n",
      "         5626,   368,  7868, 13800, 11553, 12819,  5370, 15455,  8492, 13386,\n",
      "        15404, 10079]), 'item': tensor([3573, 3352, 1195, 4298,  269, 3089,  869, 4599, 3805, 1981, 3776, 3607,\n",
      "        2694, 1068, 4441,  327, 1014,  419, 1628, 2226, 1873, 1942, 2454, 1145,\n",
      "        4740, 3957, 4320, 4304, 1545,  886, 2599, 1510, 4671, 1033, 3016, 4457,\n",
      "        2253, 2786, 3716,  502,  922, 2017, 1907, 1141, 1919, 1791, 1222, 3820,\n",
      "        3877,  908, 3198, 4369, 1671,  538, 4031, 4692, 3822, 2375,  334, 1126,\n",
      "        1382, 4531, 1691, 1469, 4098, 1248, 2253, 3868, 3726, 4616, 2319, 1173,\n",
      "        4255, 4475, 2225, 2746, 4692, 3839, 3443, 4084, 4054, 2614,  977, 4159,\n",
      "        2756, 1612, 2392, 1728,  760,  388, 4224, 1084, 1968, 2845, 4477, 1196,\n",
      "         820, 3232, 3558, 2427, 1326, 4808,  130,  587, 1181, 4289, 3089, 1571,\n",
      "        1590, 1558, 1904, 1710,  337, 3704, 4685, 4126, 2969, 4200, 4108,  517,\n",
      "        4304, 1972, 4615, 2174, 2939, 1218, 2251, 3137, 3292, 1728,  687,  774,\n",
      "        4531, 1714, 2619, 2537, 3945, 4568, 4320, 1859, 3440, 2690, 2858, 4634,\n",
      "        2022, 2134, 3076, 3872, 4686, 3917, 2394, 4615, 1048, 3151, 2085, 4623,\n",
      "          40, 1398, 1571, 3245, 2477, 4411,  660, 4621, 3483, 2699, 3645, 2281,\n",
      "        1082, 4176, 1355, 4511, 2229, 4250, 2378,  567, 4703,  335, 4259, 3636,\n",
      "        2978, 4573, 3637, 4288, 3429, 3024,  954, 3090, 2922, 2296, 2553, 3272,\n",
      "        1113, 1496,  311, 2137, 3365, 2325,  845, 2237, 2496, 2795, 2495, 4750,\n",
      "         224, 2391, 3891,  645, 3089, 1456, 3634, 3089, 4199,  814, 4501,   73,\n",
      "        3005, 1250, 1644,  846, 1768, 2742, 3945, 2487, 3908, 1779, 2795, 3188,\n",
      "        1885, 4395, 3019, 4466, 2003, 2480, 2279, 2721, 2596,  498,  285, 2709,\n",
      "         853,  818, 4491, 2770,  388, 4359, 3345, 4654, 3709, 1727, 4794,  255,\n",
      "         652,  456, 1268, 2897, 1986, 4575, 1361, 3255, 3678, 1044, 4120, 3419,\n",
      "         954,  132,  839, 1712, 1511, 3870, 4797, 4357, 4809, 2427, 1925, 2312,\n",
      "        3370, 2137, 4179, 2758, 1039, 3694, 3574, 1185, 3740, 4288, 3504,  132,\n",
      "        2227, 4016,  479, 1674, 4146, 2050, 3026,  292, 2757, 2152, 2436, 2368,\n",
      "        2253, 4288, 2695, 4255, 4733, 4719, 2906, 3023, 3029, 3946, 2859, 4095,\n",
      "        4689, 1122, 4200, 4232, 3678, 3440, 4575,  267, 3717,   46, 1173, 4289,\n",
      "        1587, 3003, 2462, 2477, 3723, 4746,  317, 2365, 3285,  340,  954, 4063,\n",
      "        2770, 2659, 3345, 2381, 2811, 2165, 4798, 4466, 4032, 4516, 1129, 3086,\n",
      "        1314, 1031,  667, 3566, 4276,  219, 4241, 3107,  711, 3950,  856, 2713,\n",
      "        4420, 2729, 3795, 4203, 3697, 1496, 4359, 1339, 4599, 1419, 1915, 3702,\n",
      "        4565, 4250, 3076, 3161, 4377, 2572, 3753, 3189, 2764, 2490, 4314,  729,\n",
      "        3580, 1434, 4137, 2945,  877, 2858, 3005, 4039, 4617, 2799,  201, 1495,\n",
      "        4113,  626,  191, 1619, 3264,  707, 3718, 2646,  154, 1121, 3739,  299,\n",
      "        3720, 3265,  138,  342, 3743, 2822, 2308,  998, 1533, 4055, 4617, 1016,\n",
      "        1780, 1479, 4250, 2686, 1433, 2231, 4468, 3031, 3455, 3877, 3254, 3344,\n",
      "        3454, 2694, 2677, 3381, 1049, 2694, 2513, 2580, 4275, 1768, 1062, 1275,\n",
      "        1640, 4176, 1559, 3109,  920, 4805, 1149, 4516, 3065, 2237, 3789, 2493,\n",
      "         314, 1234, 3493,  726, 1223,  232, 2902, 1780, 2152, 2006, 4212, 3708,\n",
      "        2552, 2694, 4311, 2248, 4243, 1875,  627, 3569,  436, 2163, 2536,  943,\n",
      "        4665, 3469, 1335, 4211, 3683, 2199, 2635, 1438, 4564, 3848, 2822,  235,\n",
      "        3702, 1172, 1479, 1050, 3307, 2872, 3227, 1935, 4546, 3334, 2911, 4496,\n",
      "        1678, 2926, 2975, 3514, 1079, 4468, 2237, 3089]), 'rating': tensor([1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 1.]), 'item_sequence': tensor([[  -1,   -1,   -1,  ...,   -1,   -1, 1714],\n",
      "        [  -1,   -1,   -1,  ..., 4159,   89, 1706],\n",
      "        [  -1,   -1,   -1,  ...,   -1,   -1,   -1],\n",
      "        ...,\n",
      "        [  -1,   -1,   -1,  ...,   -1,   -1,   -1],\n",
      "        [1244, 4575,  797,  ..., 1225, 1487, 4523],\n",
      "        [  -1,   -1,   -1,  ...,   -1, 4276, 3047]], dtype=torch.int32)}\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import lightning\n",
    "print(lightning.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-25 21:44:51.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.sequence.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mStart token used: 4816, Padding token used: 4817\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SequenceRatingPrediction(\n",
      "  (item_embedding): Embedding(4818, 256, padding_idx=4817)\n",
      "  (encoder_layer): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.3, inplace=False)\n",
      "    (dropout2): Dropout(p=0.3, inplace=False)\n",
      "    (activation): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.3, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (dropout2): Dropout(p=0.3, inplace=False)\n",
      "        (activation): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (prelu1): PReLU(num_parameters=1)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (metadata_embedding): Embedding(4817, 898)\n",
      "  (metadata_fc): Linear(in_features=898, out_features=64, bias=True)\n",
      "  (metadata_prelu): PReLU(num_parameters=1)\n",
      "  (item_tower_fc): Linear(in_features=320, out_features=256, bias=True)\n",
      "  (user_embedding): Embedding(16407, 32)\n",
      "  (user_tower_fc): Linear(in_features=288, out_features=256, bias=True)\n",
      "  (final_fc): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (score_fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name               | Type                     | Params | Mode \n",
      "------------------------------------------------------------------------\n",
      "0 | model              | SequenceRatingPrediction | 7.2 M  | train\n",
      "1 | val_roc_auc_metric | BinaryAUROC              | 0      | train\n",
      "2 | val_pr_auc_metric  | BinaryAveragePrecision   | 0      | train\n",
      "------------------------------------------------------------------------\n",
      "2.9 M     Trainable params\n",
      "4.3 M     Non-trainable params\n",
      "7.2 M     Total params\n",
      "28.884    Total estimated model params size (MB)\n",
      "38        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c365de661b441b7bb5f5f08af727b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\..\\src\\algo\\sequence\\dataset.py:38: UserWarning:\n",
      "\n",
      "The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:209.)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae20b916cf941499401cbd92cc3df65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run 006-sequence-modelling-attn-256-dim-bce-prelu at: http://138.2.61.6:5002/#/experiments/11/runs/ff8051419ee149de9bfb156d357078d2\n",
      "🧪 View experiment at: http://138.2.61.6:5002/#/experiments/11\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:47\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:575\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    569\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    570\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    571\u001b[39m     ckpt_path,\n\u001b[32m    572\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    573\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    574\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:982\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m    979\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m    980\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m    986\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1026\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:150\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:320\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer.lightning_module.automatic_optimization:\n\u001b[32m    319\u001b[39m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m     batch_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mautomatic_optimization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:192\u001b[39m, in \u001b[36m_AutomaticOptimization.run\u001b[39m\u001b[34m(self, optimizer, batch_idx, kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m result = closure.consume_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:270\u001b[39m, in \u001b[36m_AutomaticOptimization._optimizer_step\u001b[39m\u001b[34m(self, batch_idx, train_step_and_backward_closure)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moptimizer_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:171\u001b[39m, in \u001b[36m_call_lightning_module_hook\u001b[39m\u001b[34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\core\\module.py:1302\u001b[39m, in \u001b[36mLightningModule.optimizer_step\u001b[39m\u001b[34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[39m\n\u001b[32m   1278\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[32m   1279\u001b[39m \u001b[33;03mthe optimizer.\u001b[39;00m\n\u001b[32m   1280\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1300\u001b[39m \n\u001b[32m   1301\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1302\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\core\\optimizer.py:154\u001b[39m, in \u001b[36mLightningOptimizer.step\u001b[39m\u001b[34m(self, closure, **kwargs)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m._on_after_step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:239\u001b[39m, in \u001b[36mStrategy.optimizer_step\u001b[39m\u001b[34m(self, optimizer, closure, model, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl.LightningModule)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecision_plugin\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision.py:123\u001b[39m, in \u001b[36mPrecision.optimizer_step\u001b[39m\u001b[34m(self, optimizer, model, closure, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m closure = partial(\u001b[38;5;28mself\u001b[39m._wrap_closure, model, optimizer, closure)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\optim\\optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\optim\\adam.py:223\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.enable_grad():\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m         loss = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.param_groups:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision.py:109\u001b[39m, in \u001b[36mPrecision._wrap_closure\u001b[39m\u001b[34m(self, model, optimizer, closure)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03mhook is called.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \n\u001b[32m    108\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m closure_result = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[38;5;28mself\u001b[39m._after_closure(model, optimizer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:146\u001b[39m, in \u001b[36mClosure.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> Optional[Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28mself\u001b[39m._result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result.loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:140\u001b[39m, in \u001b[36mClosure.closure\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m step_output.closure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_output\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclosure_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:241\u001b[39m, in \u001b[36m_AutomaticOptimization._make_backward_fn.<locals>.backward_fn\u001b[39m\u001b[34m(loss)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackward_fn\u001b[39m(loss: Tensor) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackward\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:323\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:213\u001b[39m, in \u001b[36mStrategy.backward\u001b[39m\u001b[34m(self, closure_loss, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    211\u001b[39m closure_loss = \u001b[38;5;28mself\u001b[39m.precision_plugin.pre_backward(closure_loss, \u001b[38;5;28mself\u001b[39m.lightning_module)\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecision_plugin\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m closure_loss = \u001b[38;5;28mself\u001b[39m.precision_plugin.post_backward(closure_loss, \u001b[38;5;28mself\u001b[39m.lightning_module)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision.py:73\u001b[39m, in \u001b[36mPrecision.backward\u001b[39m\u001b[34m(self, tensor, model, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Performs the actual backpropagation.\u001b[39;00m\n\u001b[32m     63\u001b[39m \n\u001b[32m     64\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     71\u001b[39m \n\u001b[32m     72\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\core\\module.py:1097\u001b[39m, in \u001b[36mLightningModule.backward\u001b[39m\u001b[34m(self, loss, *args, **kwargs)\u001b[39m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1097\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[32m     37\u001b[39m trainer = L.Trainer(\n\u001b[32m     38\u001b[39m     default_root_dir=log_dir,\n\u001b[32m     39\u001b[39m     accelerator=args.device \u001b[38;5;28;01mif\u001b[39;00m args.device \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m \n\u001b[32m     46\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \n\u001b[32m     53\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Change the library as a workaround for the issue in the latest Lightning release\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m#https://github.com/Lightning-AI/pytorch-lightning/pull/20669/commits/429f732a0528c558e701da7ec01e51c1e2e4f32e\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:539\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28mself\u001b[39m.state.status = TrainerStatus.RUNNING\n\u001b[32m    538\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:64\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     63\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     67\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_roc_auc\", patience=args.early_stopping_patience, mode=\"max\", verbose=False, min_delta=0.001\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{args.notebook_persit_dp}/checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_roc_auc\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "model = init_model(n_users, n_items, \n",
    "                   args.embedding_dim, \n",
    "                   args.dropout, \n",
    "                   item_embedding=skipgram_item_embedding,\n",
    "                   user_embedding_dim=args.user_embedding_dim,\n",
    "                   use_user_embedding=args.use_user_embedding,\n",
    "                   use_metadata=args.use_metadata,\n",
    "                   metadata_embedding=metadata_embedding_layer,\n",
    "                   metadata_embedding_dim=args.metadata_embedding_dim,\n",
    "                   metadata_fc_dim=args.metadata_fc_dim,)\n",
    "\n",
    "print(f\"Model: {model}\")\n",
    "lit_model = SeqModellingLitModule(\n",
    "    model,\n",
    "    learning_rate=args.learning_rate,\n",
    "    l2_reg=args.l2_reg,\n",
    "    log_dir=args.notebook_persit_dp,\n",
    "    accelerator=args.device,\n",
    "    idm= idm\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persit_dp}/logs/run\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    max_epochs=args.max_epochs,\n",
    "    callbacks=[early_stopping, checkpoint_callback],\n",
    "    logger=args._mlf_logger if args.log_to_mlflow else None,\n",
    "    # limit_train_batches=0.1\n",
    "    \n",
    "    \n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    "    \n",
    ")\n",
    "\n",
    "# Change the library as a workaround for the issue in the latest Lightning release\n",
    "#https://github.com/Lightning-AI/pytorch-lightning/pull/20669/commits/429f732a0528c558e701da7ec01e51c1e2e4f32e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-21 21:41:45.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1mLoading best checkpoint from /home/dinhln/Desktop/real_time_recsys/notebooks/data/first-attempt/006-sequence-modelling-attn-256-dim-bce-prelu/checkpoints/best-checkpoint-v17.ckpt...\u001b[0m\n",
      "/home/dinhln/Desktop/real_time_recsys/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:385: UserWarning:\n",
      "\n",
      "enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
      "\n",
      "\u001b[32m2025-06-21 21:41:45.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.sequence.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m118\u001b[0m - \u001b[1mStart token used: 4816, Padding token used: 4817\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Loading best checkpoint from {checkpoint_callback.best_model_path}...\")\n",
    "args.best_checkpoint_path = checkpoint_callback.best_model_path\n",
    "\n",
    "best_trainer = SeqModellingLitModule.load_from_checkpoint(\n",
    "    checkpoint_path=checkpoint_callback.best_model_path,\n",
    "    model=init_model(n_users, \n",
    "                     n_items, \n",
    "                     args.embedding_dim, \n",
    "                     args.dropout, \n",
    "                     item_embedding=skipgram_item_embedding,\n",
    "                     user_embedding_dim=args.user_embedding_dim,\n",
    "                     use_user_embedding=args.use_user_embedding,\n",
    "                     use_metadata=args.use_metadata,\n",
    "                     metadata_embedding=metadata_embedding_layer,\n",
    "                     metadata_embedding_dim=args.metadata_embedding_dim,\n",
    "                     metadata_fc_dim=args.metadata_fc_dim,),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceRatingPrediction(\n",
       "  (item_embedding): Embedding(4818, 256, padding_idx=4817)\n",
       "  (encoder_layer): TransformerEncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.3, inplace=False)\n",
       "    (dropout2): Dropout(p=0.3, inplace=False)\n",
       "    (activation): PReLU(num_parameters=1)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "        (activation): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (prelu1): PReLU(num_parameters=1)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (user_embedding): Embedding(16407, 256)\n",
       "  (final_fc): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (score_fc): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = best_trainer.model.to(args.device)\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_recs_df = val_df.sort_values(by=args.timestamp_col).drop_duplicates(subset=[args.user_col], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.start_run(run_id = trainer.logger.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_user_indices = val_df[\"user_indice\"].values\n",
    "val_item_indices = val_df[\"item_indice\"].values\n",
    "val_item_sequences = val_df[\"item_sequence\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_431539/3241326139.py:2: UserWarning:\n",
      "\n",
      "Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users = torch.tensor(val_user_indices, device=args.device)\n",
    "item_sequences = torch.tensor(val_item_sequences, device=args.device)\n",
    "items = torch.tensor(val_item_indices, device=args.device)\n",
    "classifications = best_model.predict(users, item_sequences, items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10437, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_classification_df = val_df.assign(\n",
    "    classification_proba=classifications.cpu().detach().numpy(),\n",
    "    label=lambda df: df[args.rating_col].gt(0).astype(int),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "      <th>classification_proba</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129609</th>\n",
       "      <td>AGYYEQ2BPGILFTNVVZGEEK4AP5QA</td>\n",
       "      <td>B0854CTL5N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2021-08-10 01:19:51.147</td>\n",
       "      <td>12109</td>\n",
       "      <td>3857</td>\n",
       "      <td>[-1, -1, 2822, 3056, 4462, 2519, 1791, 1396, 2...</td>\n",
       "      <td>0.922151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391795</th>\n",
       "      <td>AFSU64CATRPYNY6C6PCI6FGKCJ4Q</td>\n",
       "      <td>B0C1Z2FM57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-12-24 19:34:06.504</td>\n",
       "      <td>7275</td>\n",
       "      <td>3944</td>\n",
       "      <td>[-1, 394, 3954, 1498, 2648, 3731, 4611, 1682, ...</td>\n",
       "      <td>0.351367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128128</th>\n",
       "      <td>AHP6PY4J6DB72JLOALVFWIOZ6EHA</td>\n",
       "      <td>B0B4SWZTZ1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-02-23 00:36:06.416</td>\n",
       "      <td>15029</td>\n",
       "      <td>4413</td>\n",
       "      <td>[-1, -1, -1, 1280, 2811, 3304, 3153, 3188, 478...</td>\n",
       "      <td>0.842930</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id parent_asin  rating  \\\n",
       "129609  AGYYEQ2BPGILFTNVVZGEEK4AP5QA  B0854CTL5N     5.0   \n",
       "391795  AFSU64CATRPYNY6C6PCI6FGKCJ4Q  B0C1Z2FM57     0.0   \n",
       "128128  AHP6PY4J6DB72JLOALVFWIOZ6EHA  B0B4SWZTZ1     1.0   \n",
       "\n",
       "                     timestamp  user_indice  item_indice  \\\n",
       "129609 2021-08-10 01:19:51.147        12109         3857   \n",
       "391795 2021-12-24 19:34:06.504         7275         3944   \n",
       "128128 2021-02-23 00:36:06.416        15029         4413   \n",
       "\n",
       "                                            item_sequence  \\\n",
       "129609  [-1, -1, 2822, 3056, 4462, 2519, 1791, 1396, 2...   \n",
       "391795  [-1, 394, 3954, 1498, 2648, 3731, 4611, 1682, ...   \n",
       "128128  [-1, -1, -1, 1280, 2811, 3304, 3153, 3188, 478...   \n",
       "\n",
       "        classification_proba  label  \n",
       "129609              0.922151      1  \n",
       "391795              0.351367      0  \n",
       "128128              0.842930      1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classification_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report = log_classification_metrics(\n",
    "    args,\n",
    "    eval_classification_df,\n",
    "    target_col=\"label\",\n",
    "    prediction_col=\"classification_proba\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127392</th>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B004FV4ROA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-12-27 00:30:31.146</td>\n",
       "      <td>11295</td>\n",
       "      <td>528</td>\n",
       "      <td>[1715, 2537, 3743, 506, 4490, 3479, 3908, 2723...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385658</th>\n",
       "      <td>AEHS7YR7BGGWMZS24H5UR5IP46HQ</td>\n",
       "      <td>B08F1P3BCC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-12-27 01:44:52.242</td>\n",
       "      <td>1784</td>\n",
       "      <td>4451</td>\n",
       "      <td>[-1, -1, -1, -1, -1, 3382, 4330, 423, 3167, 2677]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385660</th>\n",
       "      <td>AGAVHCK42EGMVS7DGPRX6HBCUCNQ</td>\n",
       "      <td>B09Q3NR84W</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-12-27 02:25:48.357</td>\n",
       "      <td>9042</td>\n",
       "      <td>4650</td>\n",
       "      <td>[-1, -1, -1, -1, 3104, 1416, 3743, 2694, 3612,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385662</th>\n",
       "      <td>AEFVBMCJAFNULDI5V2CKKTBCPURA</td>\n",
       "      <td>B07N1L5HX1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-12-27 02:32:15.171</td>\n",
       "      <td>1542</td>\n",
       "      <td>2677</td>\n",
       "      <td>[-1, -1, -1, -1, -1, 1320, 2162, 2472, 2694, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385664</th>\n",
       "      <td>AGLXMKHBLTBNT3X2CLBAPW6QUTQA</td>\n",
       "      <td>B0BB6Y5N3M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-12-27 03:37:22.772</td>\n",
       "      <td>10418</td>\n",
       "      <td>1230</td>\n",
       "      <td>[341, 3803, 4431, 1067, 4530, 4018, 2688, 4365...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130864</th>\n",
       "      <td>AGGDNWGN3NDJ2DI5CBSFOMUAM6XA</td>\n",
       "      <td>B083YHS7SV</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022-02-18 19:43:25.492</td>\n",
       "      <td>9711</td>\n",
       "      <td>3844</td>\n",
       "      <td>[-1, -1, -1, -1, 1019, 754, 2059, 413, 4262, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392604</th>\n",
       "      <td>AEKUF6AOVWDWFYOKPWO2CV72PEDQ</td>\n",
       "      <td>B07QN33986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-19 01:32:51.519</td>\n",
       "      <td>2171</td>\n",
       "      <td>1860</td>\n",
       "      <td>[-1, -1, 2627, 4216, 4743, 1945, 2355, 1831, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392606</th>\n",
       "      <td>AFBTD25HPE4BE4LUFV3DTI2E2N2A</td>\n",
       "      <td>B07TMJ8S5Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-19 16:49:57.966</td>\n",
       "      <td>5159</td>\n",
       "      <td>3411</td>\n",
       "      <td>[-1, -1, -1, -1, 2260, 3517, 3609, 3495, 3625,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392609</th>\n",
       "      <td>AHLN6GKTKZE22AON34YAQXTGK63A</td>\n",
       "      <td>B0C682GZ5X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-19 17:28:55.519</td>\n",
       "      <td>14550</td>\n",
       "      <td>4201</td>\n",
       "      <td>[-1, -1, -1, -1, -1, 1812, 4165, 4575, 4807, 374]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392611</th>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B091K4WYD1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-19 22:08:53.253</td>\n",
       "      <td>2446</td>\n",
       "      <td>768</td>\n",
       "      <td>[2677, 1610, 2694, 3695, 4429, 3602, 4569, 365...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2424 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id parent_asin  rating  \\\n",
       "127392  AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B004FV4ROA     1.0   \n",
       "385658  AEHS7YR7BGGWMZS24H5UR5IP46HQ  B08F1P3BCC     0.0   \n",
       "385660  AGAVHCK42EGMVS7DGPRX6HBCUCNQ  B09Q3NR84W     0.0   \n",
       "385662  AEFVBMCJAFNULDI5V2CKKTBCPURA  B07N1L5HX1     0.0   \n",
       "385664  AGLXMKHBLTBNT3X2CLBAPW6QUTQA  B0BB6Y5N3M     0.0   \n",
       "...                              ...         ...     ...   \n",
       "130864  AGGDNWGN3NDJ2DI5CBSFOMUAM6XA  B083YHS7SV     4.0   \n",
       "392604  AEKUF6AOVWDWFYOKPWO2CV72PEDQ  B07QN33986     0.0   \n",
       "392606  AFBTD25HPE4BE4LUFV3DTI2E2N2A  B07TMJ8S5Z     0.0   \n",
       "392609  AHLN6GKTKZE22AON34YAQXTGK63A  B0C682GZ5X     0.0   \n",
       "392611  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B091K4WYD1     0.0   \n",
       "\n",
       "                     timestamp  user_indice  item_indice  \\\n",
       "127392 2020-12-27 00:30:31.146        11295          528   \n",
       "385658 2020-12-27 01:44:52.242         1784         4451   \n",
       "385660 2020-12-27 02:25:48.357         9042         4650   \n",
       "385662 2020-12-27 02:32:15.171         1542         2677   \n",
       "385664 2020-12-27 03:37:22.772        10418         1230   \n",
       "...                        ...          ...          ...   \n",
       "130864 2022-02-18 19:43:25.492         9711         3844   \n",
       "392604 2022-02-19 01:32:51.519         2171         1860   \n",
       "392606 2022-02-19 16:49:57.966         5159         3411   \n",
       "392609 2022-02-19 17:28:55.519        14550         4201   \n",
       "392611 2022-02-19 22:08:53.253         2446          768   \n",
       "\n",
       "                                            item_sequence  \n",
       "127392  [1715, 2537, 3743, 506, 4490, 3479, 3908, 2723...  \n",
       "385658  [-1, -1, -1, -1, -1, 3382, 4330, 423, 3167, 2677]  \n",
       "385660  [-1, -1, -1, -1, 3104, 1416, 3743, 2694, 3612,...  \n",
       "385662  [-1, -1, -1, -1, -1, 1320, 2162, 2472, 2694, 3...  \n",
       "385664  [341, 3803, 4431, 1067, 4530, 4018, 2688, 4365...  \n",
       "...                                                   ...  \n",
       "130864  [-1, -1, -1, -1, 1019, 754, 2059, 413, 4262, 3...  \n",
       "392604  [-1, -1, 2627, 4216, 4743, 1945, 2355, 1831, 9...  \n",
       "392606  [-1, -1, -1, -1, 2260, 3517, 3609, 3495, 3625,...  \n",
       "392609  [-1, -1, -1, -1, -1, 1812, 4165, 4575, 4807, 374]  \n",
       "392611  [2677, 1610, 2694, 3695, 4429, 3602, 4569, 365...  \n",
       "\n",
       "[2424 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_recs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad496c41f0e40ccb2496e163b36aead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating recommendations:   0%|          | 0/364964 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recommendations = best_model.recommend(\n",
    "    torch.tensor(val_recs_df[\"user_indice\"].values, device=args.device),\n",
    "    torch.tensor(val_recs_df[\"item_sequence\"].values.tolist(), device=args.device),\n",
    "    k=args.top_K,\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_indice</th>\n",
       "      <th>recommendation</th>\n",
       "      <th>score</th>\n",
       "      <th>rec_ranking</th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11295</td>\n",
       "      <td>3032</td>\n",
       "      <td>0.834206</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B074F3M2W8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11295</td>\n",
       "      <td>3188</td>\n",
       "      <td>0.830017</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B0791TX5P5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11295</td>\n",
       "      <td>3472</td>\n",
       "      <td>0.829827</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B07HZLHPKP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11295</td>\n",
       "      <td>3915</td>\n",
       "      <td>0.829290</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B08D7JPKLZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11295</td>\n",
       "      <td>3983</td>\n",
       "      <td>0.825969</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B08N5TC2Z3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242395</th>\n",
       "      <td>2446</td>\n",
       "      <td>3200</td>\n",
       "      <td>0.825623</td>\n",
       "      <td>96.0</td>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B0795DP124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242396</th>\n",
       "      <td>2446</td>\n",
       "      <td>2998</td>\n",
       "      <td>0.824843</td>\n",
       "      <td>97.0</td>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B072KGYYKX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242397</th>\n",
       "      <td>2446</td>\n",
       "      <td>3476</td>\n",
       "      <td>0.824502</td>\n",
       "      <td>98.0</td>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B07J2FGZSM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242398</th>\n",
       "      <td>2446</td>\n",
       "      <td>3659</td>\n",
       "      <td>0.823378</td>\n",
       "      <td>99.0</td>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B07RR6HQKX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242399</th>\n",
       "      <td>2446</td>\n",
       "      <td>3381</td>\n",
       "      <td>0.822749</td>\n",
       "      <td>100.0</td>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B07F4P3JH7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242400 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_indice  recommendation     score  rec_ranking  \\\n",
       "0             11295            3032  0.834206          1.0   \n",
       "1             11295            3188  0.830017          2.0   \n",
       "2             11295            3472  0.829827          3.0   \n",
       "3             11295            3915  0.829290          4.0   \n",
       "4             11295            3983  0.825969          5.0   \n",
       "...             ...             ...       ...          ...   \n",
       "242395         2446            3200  0.825623         96.0   \n",
       "242396         2446            2998  0.824843         97.0   \n",
       "242397         2446            3476  0.824502         98.0   \n",
       "242398         2446            3659  0.823378         99.0   \n",
       "242399         2446            3381  0.822749        100.0   \n",
       "\n",
       "                             user_id parent_asin  \n",
       "0       AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B074F3M2W8  \n",
       "1       AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B0791TX5P5  \n",
       "2       AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B07HZLHPKP  \n",
       "3       AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B08D7JPKLZ  \n",
       "4       AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B08N5TC2Z3  \n",
       "...                              ...         ...  \n",
       "242395  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B0795DP124  \n",
       "242396  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B072KGYYKX  \n",
       "242397  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B07J2FGZSM  \n",
       "242398  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B07RR6HQKX  \n",
       "242399  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B07F4P3JH7  \n",
       "\n",
       "[242400 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_df = pd.DataFrame(recommendations).pipe(\n",
    "    create_rec_df, idm, args.user_col, args.item_col\n",
    ")\n",
    "recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128912</th>\n",
       "      <td>AG2EMAD6UILFF4ITMMKH2NEFTYHA</td>\n",
       "      <td>B0BZJGGX2T</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127943</th>\n",
       "      <td>AHPI7N36W4JJYOAA6MBAGWTDF3FA</td>\n",
       "      <td>B072MKFNV6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129406</th>\n",
       "      <td>AGOBLEZGF5OSPDVTIMA3DPWAENGA</td>\n",
       "      <td>B07H65KP63</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130173</th>\n",
       "      <td>AFXRWTDGQJIDOTGMCIZKH5QPK5KA</td>\n",
       "      <td>B00PKTU83U</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128534</th>\n",
       "      <td>AHWDVLU5PTXMLD6PSJ2Z5Q3JP4OA</td>\n",
       "      <td>B0719SNR5N</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386737</th>\n",
       "      <td>AEN2KQVSR5TWRXNQS3OTFT4EZQCA</td>\n",
       "      <td>B0BRT7XFM5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388052</th>\n",
       "      <td>AFKERAMSXU4MWO3H53R7DEFOHUVQ</td>\n",
       "      <td>B07G5YXYFL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388051</th>\n",
       "      <td>AFKERAMSXU4MWO3H53R7DEFOHUVQ</td>\n",
       "      <td>B07G5YXYFL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387885</th>\n",
       "      <td>AFKERAMSXU4MWO3H53R7DEFOHUVQ</td>\n",
       "      <td>B07ZZVX1F2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387886</th>\n",
       "      <td>AFKERAMSXU4MWO3H53R7DEFOHUVQ</td>\n",
       "      <td>B07ZZVX1F2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10437 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id parent_asin  rating  rating_rank\n",
       "128912  AG2EMAD6UILFF4ITMMKH2NEFTYHA  B0BZJGGX2T     5.0          1.0\n",
       "127943  AHPI7N36W4JJYOAA6MBAGWTDF3FA  B072MKFNV6     4.0          1.0\n",
       "129406  AGOBLEZGF5OSPDVTIMA3DPWAENGA  B07H65KP63     5.0          1.0\n",
       "130173  AFXRWTDGQJIDOTGMCIZKH5QPK5KA  B00PKTU83U     5.0          1.0\n",
       "128534  AHWDVLU5PTXMLD6PSJ2Z5Q3JP4OA  B0719SNR5N     3.0          1.0\n",
       "...                              ...         ...     ...          ...\n",
       "386737  AEN2KQVSR5TWRXNQS3OTFT4EZQCA  B0BRT7XFM5     0.0         27.0\n",
       "388052  AFKERAMSXU4MWO3H53R7DEFOHUVQ  B07G5YXYFL     0.0         27.0\n",
       "388051  AFKERAMSXU4MWO3H53R7DEFOHUVQ  B07G5YXYFL     0.0         28.0\n",
       "387885  AFKERAMSXU4MWO3H53R7DEFOHUVQ  B07ZZVX1F2     0.0         29.0\n",
       "387886  AFKERAMSXU4MWO3H53R7DEFOHUVQ  B07ZZVX1F2     0.0         30.0\n",
       "\n",
       "[10437 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = create_label_df(\n",
    "    val_df,\n",
    "    user_col=args.user_col,\n",
    "    item_col=args.item_col,\n",
    "    rating_col=args.rating_col,\n",
    "    timestamp_col=args.timestamp_col,\n",
    ")\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_indice</th>\n",
       "      <th>recommendation</th>\n",
       "      <th>score</th>\n",
       "      <th>rec_ranking</th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3251.0</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>1</td>\n",
       "      <td>AE24AB4DW5KYK3F5DYOT5VPW2VLA</td>\n",
       "      <td>B07BPKL2D2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4669.0</td>\n",
       "      <td>0.908320</td>\n",
       "      <td>2</td>\n",
       "      <td>AE24AB4DW5KYK3F5DYOT5VPW2VLA</td>\n",
       "      <td>B0BXP3P132</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4365.0</td>\n",
       "      <td>0.907467</td>\n",
       "      <td>3</td>\n",
       "      <td>AE24AB4DW5KYK3F5DYOT5VPW2VLA</td>\n",
       "      <td>B09ZMQWGCG</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4785.0</td>\n",
       "      <td>0.904956</td>\n",
       "      <td>4</td>\n",
       "      <td>AE24AB4DW5KYK3F5DYOT5VPW2VLA</td>\n",
       "      <td>B0C6PRR41P</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>0.904170</td>\n",
       "      <td>5</td>\n",
       "      <td>AE24AB4DW5KYK3F5DYOT5VPW2VLA</td>\n",
       "      <td>B07CG2PGY6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252360</th>\n",
       "      <td>16403.0</td>\n",
       "      <td>3550.0</td>\n",
       "      <td>0.787922</td>\n",
       "      <td>99</td>\n",
       "      <td>AHZZM7BCJAF2UEMMBHZCLXBB2SVA</td>\n",
       "      <td>B07N1L5HX1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252390</th>\n",
       "      <td>16403.0</td>\n",
       "      <td>3903.0</td>\n",
       "      <td>0.787658</td>\n",
       "      <td>100</td>\n",
       "      <td>AHZZM7BCJAF2UEMMBHZCLXBB2SVA</td>\n",
       "      <td>B08BZSCHZ3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252328</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>AHZZM7BCJAF2UEMMBHZCLXBB2SVA</td>\n",
       "      <td>B075QC3TZY</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252329</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>AHZZM7BCJAF2UEMMBHZCLXBB2SVA</td>\n",
       "      <td>B075QC3TZY</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252330</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>AHZZM7BCJAF2UEMMBHZCLXBB2SVA</td>\n",
       "      <td>B075QC3TZY</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252421 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_indice  recommendation     score  rec_ranking  \\\n",
       "26              8.0          3251.0  0.912598            1   \n",
       "96              8.0          4669.0  0.908320            2   \n",
       "72              8.0          4365.0  0.907467            3   \n",
       "102             8.0          4785.0  0.904956            4   \n",
       "27              8.0          3300.0  0.904170            5   \n",
       "...             ...             ...       ...          ...   \n",
       "252360      16403.0          3550.0  0.787922           99   \n",
       "252390      16403.0          3903.0  0.787658          100   \n",
       "252328          NaN             NaN       NaN          101   \n",
       "252329          NaN             NaN       NaN          101   \n",
       "252330          NaN             NaN       NaN          101   \n",
       "\n",
       "                             user_id parent_asin  rating  rating_rank  \n",
       "26      AE24AB4DW5KYK3F5DYOT5VPW2VLA  B07BPKL2D2       0          NaN  \n",
       "96      AE24AB4DW5KYK3F5DYOT5VPW2VLA  B0BXP3P132       0          NaN  \n",
       "72      AE24AB4DW5KYK3F5DYOT5VPW2VLA  B09ZMQWGCG       0          NaN  \n",
       "102     AE24AB4DW5KYK3F5DYOT5VPW2VLA  B0C6PRR41P       0          NaN  \n",
       "27      AE24AB4DW5KYK3F5DYOT5VPW2VLA  B07CG2PGY6       0          NaN  \n",
       "...                              ...         ...     ...          ...  \n",
       "252360  AHZZM7BCJAF2UEMMBHZCLXBB2SVA  B07N1L5HX1       0          NaN  \n",
       "252390  AHZZM7BCJAF2UEMMBHZCLXBB2SVA  B08BZSCHZ3       0          NaN  \n",
       "252328  AHZZM7BCJAF2UEMMBHZCLXBB2SVA  B075QC3TZY       1          1.0  \n",
       "252329  AHZZM7BCJAF2UEMMBHZCLXBB2SVA  B075QC3TZY       0          2.0  \n",
       "252330  AHZZM7BCJAF2UEMMBHZCLXBB2SVA  B075QC3TZY       0          3.0  \n",
       "\n",
       "[252421 rows x 8 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = merge_recs_with_target(\n",
    "    recommendations_df,\n",
    "    label_df,\n",
    "    k=args.top_K,\n",
    "    user_col=args.user_col,\n",
    "    item_col=args.item_col,\n",
    "    rating_col=args.rating_col,\n",
    ")\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_report = log_ranking_metrics(args, eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run 006-sequence-modelling-attn-256-dim-bce-prelu at: http://138.2.61.6:5002/#/experiments/2/runs/2a81df7b8a4d4fbaba79e8ff0d416664\n",
      "🧪 View experiment at: http://138.2.61.6:5002/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run 006-sequence-modelling-attn-256-dim-bce-prelu at: http://138.2.61.6:5002/#/experiments/2/runs/2a81df7b8a4d4fbaba79e8ff0d416664\n",
      "🧪 View experiment at: http://138.2.61.6:5002/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "all_params = [args]\n",
    "\n",
    "if args.log_to_mlflow:\n",
    "    run_id = trainer.logger.run_id\n",
    "\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        for params in all_params:\n",
    "            params_dict = params.model_dump()\n",
    "            params_ = dict()\n",
    "            for k, v in params_dict.items():\n",
    "                if k == \"top_K\":\n",
    "                    k = \"top_big_K\"\n",
    "                if k == \"top_k\":\n",
    "                    k = \"top_small_k\"\n",
    "                params_[f\"{params.__repr_name__()}.{k}\"] = v\n",
    "            mlflow.log_params(params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hm-scalablerecs-QHnDFvap-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
