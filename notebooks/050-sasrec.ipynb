{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d6defc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "52b77b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydantic import BaseModel\n",
    "import sys\n",
    "import os\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from loguru import logger\n",
    "from load_dotenv import load_dotenv\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import mlflow\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src.utils.embedding_id_mapper import IDMapper\n",
    "from src.algo.gSASRec.model import SASRec\n",
    "from src.algo.gSASRec.dataset import SASRecDataset\n",
    "from src.algo.gSASRec.trainer import SASRecLitModule\n",
    "from src.eval.utils import create_rec_df, create_label_df, merge_recs_with_target\n",
    "from src.eval.log_metrics import log_ranking_metrics, log_classification_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "737a8749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c1ace436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-01 14:44:06.323\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m42\u001b[0m - \u001b[33m\u001b[1mMLFlow is not enabled. Turn off tracking to Mlflow.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"testing\": false,\n",
      "  \"log_to_mlflow\": false,\n",
      "  \"experiment_name\": \"first-attempt\",\n",
      "  \"run_name\": \"018-sasrec\",\n",
      "  \"notebook_persit_dp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\notebooks\\\\data\\\\first-attempt\\\\018-sasrec\",\n",
      "  \"user_col\": \"user_id\",\n",
      "  \"item_col\": \"parent_asin\",\n",
      "  \"rating_col\": \"rating\",\n",
      "  \"timestamp_col\": \"timestamp\",\n",
      "  \"group_name\": \"seq-modelling\",\n",
      "  \"top_K\": 100,\n",
      "  \"top_k\": 10,\n",
      "  \"batch_size\": 256,\n",
      "  \"lr\": 0.001,\n",
      "  \"l2_emb\": 0.0001,\n",
      "  \"early_stopping_patience\": 10,\n",
      "  \"device\": \"cpu\",\n",
      "  \"num_epochs\": 100,\n",
      "  \"max_len\": 10,\n",
      "  \"dropout\": 0.3,\n",
      "  \"hidden_units\": 128,\n",
      "  \"num_blocks\": 1,\n",
      "  \"num_heads\": 2,\n",
      "  \"num_workers\": 4,\n",
      "  \"pad_token\": 4817,\n",
      "  \"train_data_fp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\data_for_ai\\\\interim\\\\train_sample_interactions_16407u_neg_seq.parquet\",\n",
      "  \"val_data_fp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\data_for_ai\\\\interim\\\\val_sample_interactions_16407u_neg_seq.parquet\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Args(BaseModel):\n",
    "    testing: bool = False\n",
    "    log_to_mlflow: bool = True\n",
    "    experiment_name: str = \"first-attempt\"\n",
    "    run_name: str = f\"018-sasrec\"\n",
    "    notebook_persit_dp: str = None\n",
    "    \n",
    "    user_col: str = \"user_id\"\n",
    "    item_col: str = \"parent_asin\"\n",
    "    rating_col: str = \"rating\"\n",
    "    timestamp_col: str = \"timestamp\"\n",
    "    group_name: str = \"seq-modelling\"\n",
    "\n",
    "    top_K: int = 100\n",
    "    top_k: int = 10\n",
    "\n",
    "    batch_size: int = 256\n",
    "    lr: float = 0.001\n",
    "    l2_emb: float = 0.0001\n",
    "    early_stopping_patience: int = 10\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    num_epochs: int = 100\n",
    "\n",
    "    # SASrec specific\n",
    "    max_len: int = 10\n",
    "    dropout: float = 0.3\n",
    "    hidden_units: int = 128\n",
    "    num_blocks: int = 1\n",
    "    num_heads: int = 2\n",
    "    num_workers: int = 4\n",
    "    pad_token: int = 4817\n",
    "    # seq_length: int = 10\n",
    "    \n",
    "    train_data_fp: str = os.path.abspath(\"../data_for_ai/interim/train_sample_interactions_16407u_neg_seq.parquet\")\n",
    "    val_data_fp: str = os.path.abspath(\"../data_for_ai/interim/val_sample_interactions_16407u_neg_seq.parquet\")\n",
    "\n",
    "    def init(self):\n",
    "        self.notebook_persit_dp = os.path.abspath(f\"data/{self.experiment_name}/{self.run_name}\")\n",
    "\n",
    "        if not (mlflow_uri := os.environ.get(\"MLFLOW_TRACKING_URI\")):\n",
    "            self.log_to_mlflow = False\n",
    "            logger.warning(\"MLFlow is not enabled. Turn off tracking to Mlflow.\")\n",
    "\n",
    "        if self.log_to_mlflow:\n",
    "            logger.info(\n",
    "                f\"Setting up Mlflow experiment: {self.experiment_name}, run_name: {self.run_name}\"\n",
    "            )\n",
    "\n",
    "            self._mlf_logger = MLFlowLogger(\n",
    "                experiment_name=self.experiment_name,\n",
    "                run_name=self.run_name,\n",
    "                tracking_uri=mlflow_uri,\n",
    "                log_model=True,\n",
    "            )\n",
    "\n",
    "        if not self.testing:\n",
    "            os.makedirs(self.notebook_persit_dp, exist_ok=True)\n",
    "        return self\n",
    "    \n",
    "args = Args().init()\n",
    "print(args.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "383bb869",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(args.train_data_fp)\n",
    "train_df[args.rating_col] = train_df[args.rating_col].apply(lambda x: 1 if x > 0 else 0)            \n",
    "\n",
    "val_df = pd.read_parquet(args.val_data_fp)\n",
    "val_df[args.rating_col] = val_df[args.rating_col].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "assert set(val_df[args.user_col].unique()).issubset(set(train_df[args.user_col].unique())), \"Validation users must be present in training users.\"\n",
    "\n",
    "assert set(val_df[args.item_col].unique()).issubset(set(train_df[args.item_col].unique())), \"Validation items must be present in training items.\"\n",
    "assert train_df[args.timestamp_col].max() < val_df[args.timestamp_col].min(), \"Validation data must be after training data. Otherwise, its a data contamination problem.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ca341b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B004FV4ROA</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-27 00:30:31.146</td>\n",
       "      <td>11295</td>\n",
       "      <td>528</td>\n",
       "      <td>[1898, 3479, 3908, 1570, 91, 2723, 2962, 106, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B07KFQFDNB</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-27 00:30:31.146</td>\n",
       "      <td>11295</td>\n",
       "      <td>3503</td>\n",
       "      <td>[3479, 3908, 1570, 91, 2723, 2962, 106, 3557, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AEHS7YR7BGGWMZS24H5UR5IP46HQ</td>\n",
       "      <td>B08F1P3BCC</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-27 01:44:52.242</td>\n",
       "      <td>1784</td>\n",
       "      <td>3925</td>\n",
       "      <td>[4319, 3382, 4330, 1173, 1330, 423, 2868, 3167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEHS7YR7BGGWMZS24H5UR5IP46HQ</td>\n",
       "      <td>B00HXT8EKE</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-27 01:44:52.242</td>\n",
       "      <td>1784</td>\n",
       "      <td>1507</td>\n",
       "      <td>[3382, 4330, 1173, 1330, 423, 2868, 3167, 1071...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGAVHCK42EGMVS7DGPRX6HBCUCNQ</td>\n",
       "      <td>B09Q3NR84W</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-27 02:25:48.357</td>\n",
       "      <td>9042</td>\n",
       "      <td>4273</td>\n",
       "      <td>[1311, 1416, 455, 3743, 1823, 2694, 3612, 3462...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6953</th>\n",
       "      <td>AEEQZRQBOFHFBFPYBX2BZ5WOI33A</td>\n",
       "      <td>B01A08E70K</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-19 16:56:53.030</td>\n",
       "      <td>1396</td>\n",
       "      <td>2441</td>\n",
       "      <td>[3451, 3827, 1839, 1347, 2504, 2694, 4546, 427...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6954</th>\n",
       "      <td>AHLN6GKTKZE22AON34YAQXTGK63A</td>\n",
       "      <td>B0C682GZ5X</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-19 17:28:55.519</td>\n",
       "      <td>14550</td>\n",
       "      <td>4772</td>\n",
       "      <td>[2950, 1812, 4735, 4165, 4575, 2440, 607, 4807...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6955</th>\n",
       "      <td>AHLN6GKTKZE22AON34YAQXTGK63A</td>\n",
       "      <td>B09SWWCN6Q</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-19 17:28:55.519</td>\n",
       "      <td>14550</td>\n",
       "      <td>4303</td>\n",
       "      <td>[1812, 4735, 4165, 4575, 2440, 607, 4807, 374,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6956</th>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B091K4WYD1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-19 22:08:53.253</td>\n",
       "      <td>2446</td>\n",
       "      <td>4086</td>\n",
       "      <td>[644, 3602, 4569, 1865, 3030, 3653, 3803, 3998...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6957</th>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B005CTKYB4</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-19 22:08:53.253</td>\n",
       "      <td>2446</td>\n",
       "      <td>654</td>\n",
       "      <td>[3602, 4569, 1865, 3030, 3653, 3803, 3998, 285...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6958 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           user_id parent_asin  rating  \\\n",
       "0     AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B004FV4ROA       1   \n",
       "1     AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B07KFQFDNB       0   \n",
       "2     AEHS7YR7BGGWMZS24H5UR5IP46HQ  B08F1P3BCC       1   \n",
       "3     AEHS7YR7BGGWMZS24H5UR5IP46HQ  B00HXT8EKE       0   \n",
       "4     AGAVHCK42EGMVS7DGPRX6HBCUCNQ  B09Q3NR84W       1   \n",
       "...                            ...         ...     ...   \n",
       "6953  AEEQZRQBOFHFBFPYBX2BZ5WOI33A  B01A08E70K       0   \n",
       "6954  AHLN6GKTKZE22AON34YAQXTGK63A  B0C682GZ5X       1   \n",
       "6955  AHLN6GKTKZE22AON34YAQXTGK63A  B09SWWCN6Q       0   \n",
       "6956  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B091K4WYD1       1   \n",
       "6957  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B005CTKYB4       0   \n",
       "\n",
       "                   timestamp  user_indice  item_indice  \\\n",
       "0    2020-12-27 00:30:31.146        11295          528   \n",
       "1    2020-12-27 00:30:31.146        11295         3503   \n",
       "2    2020-12-27 01:44:52.242         1784         3925   \n",
       "3    2020-12-27 01:44:52.242         1784         1507   \n",
       "4    2020-12-27 02:25:48.357         9042         4273   \n",
       "...                      ...          ...          ...   \n",
       "6953 2022-02-19 16:56:53.030         1396         2441   \n",
       "6954 2022-02-19 17:28:55.519        14550         4772   \n",
       "6955 2022-02-19 17:28:55.519        14550         4303   \n",
       "6956 2022-02-19 22:08:53.253         2446         4086   \n",
       "6957 2022-02-19 22:08:53.253         2446          654   \n",
       "\n",
       "                                          item_sequence  \n",
       "0     [1898, 3479, 3908, 1570, 91, 2723, 2962, 106, ...  \n",
       "1     [3479, 3908, 1570, 91, 2723, 2962, 106, 3557, ...  \n",
       "2     [4319, 3382, 4330, 1173, 1330, 423, 2868, 3167...  \n",
       "3     [3382, 4330, 1173, 1330, 423, 2868, 3167, 1071...  \n",
       "4     [1311, 1416, 455, 3743, 1823, 2694, 3612, 3462...  \n",
       "...                                                 ...  \n",
       "6953  [3451, 3827, 1839, 1347, 2504, 2694, 4546, 427...  \n",
       "6954  [2950, 1812, 4735, 4165, 4575, 2440, 607, 4807...  \n",
       "6955  [1812, 4735, 4165, 4575, 2440, 607, 4807, 374,...  \n",
       "6956  [644, 3602, 4569, 1865, 3030, 3653, 3803, 3998...  \n",
       "6957  [3602, 4569, 1865, 3030, 3653, 3803, 3998, 285...  \n",
       "\n",
       "[6958 rows x 7 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "21bc2bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFZ4EK2LJ655XQKTEUELCARO6RYA</td>\n",
       "      <td>B00002EQCW</td>\n",
       "      <td>1</td>\n",
       "      <td>2003-01-23 03:28:15</td>\n",
       "      <td>8071</td>\n",
       "      <td>4</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFZ4EK2LJ655XQKTEUELCARO6RYA</td>\n",
       "      <td>B095JX15XF</td>\n",
       "      <td>0</td>\n",
       "      <td>2003-01-23 03:28:15</td>\n",
       "      <td>8071</td>\n",
       "      <td>4132</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFY2C4YOUP2SSMM43HD2L3FIEFZA</td>\n",
       "      <td>B00008SCFL</td>\n",
       "      <td>1</td>\n",
       "      <td>2003-11-25 18:12:09</td>\n",
       "      <td>7935</td>\n",
       "      <td>36</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user_id parent_asin  rating           timestamp  \\\n",
       "0  AFZ4EK2LJ655XQKTEUELCARO6RYA  B00002EQCW       1 2003-01-23 03:28:15   \n",
       "1  AFZ4EK2LJ655XQKTEUELCARO6RYA  B095JX15XF       0 2003-01-23 03:28:15   \n",
       "2  AFY2C4YOUP2SSMM43HD2L3FIEFZA  B00008SCFL       1 2003-11-25 18:12:09   \n",
       "\n",
       "   user_indice  item_indice                                      item_sequence  \n",
       "0         8071            4  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "1         8071         4132  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "2         7935           36  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2ad41a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(n_user, n_items, dropout, hidden_units, num_blocks, num_heads):\n",
    "    \"\"\"\n",
    "    Initialize the model with the given parameters.\n",
    "    \"\"\"\n",
    "    model = SASRec(\n",
    "        user_num = n_user,\n",
    "        item_num = n_items,\n",
    "        dropout_rate = dropout,\n",
    "        hidden_units = hidden_units,\n",
    "        num_blocks = num_blocks,\n",
    "        num_heads = num_heads,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a88d3595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1449]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "hidden_units = 8\n",
    "dropout = 0.2\n",
    "num_blocks = 1\n",
    "num_heads = 2\n",
    "\n",
    "# Mock data\n",
    "user_indices = [0, 0, 1, 2, 2]\n",
    "item_indices = [0, 1, 2, 3, 4]\n",
    "timestamps = [0, 1, 2, 3, 4]\n",
    "ratings = [0, 4, 5, 3, 0]\n",
    "\n",
    "user_num = len(set(user_indices))\n",
    "item_num = len(set(item_indices))\n",
    "\n",
    "train_test_df = pd.DataFrame(\n",
    "    {\n",
    "        \"user_indice\": user_indices,\n",
    "        \"item_indice\": item_indices,\n",
    "        args.timestamp_col: timestamps,\n",
    "        args.rating_col: ratings,\n",
    "    }\n",
    ")\n",
    "\n",
    "model = init_model(user_num, item_num, dropout,hidden_units, num_blocks, num_heads)\n",
    "\n",
    "# Example forward pass\n",
    "model.eval()\n",
    "user = torch.tensor([[0]])\n",
    "seq = torch.tensor([[0,0,0,0,0,1,2,3,4,5]])\n",
    "target_item = torch.tensor([[2]])\n",
    "predictions = model.predict(user, seq, target_item)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b93c128f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4817"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"item_indice\"].max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "79c03f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset = SASRecDataset(\n",
    "    train_df, \"user_indice\", \"item_sequence\", \"item_indice\", \"rating\",args.max_len, args.pad_token, args.timestamp_col, \n",
    ")\n",
    "val_rating_dataset = SASRecDataset(\n",
    "    val_df, \"user_indice\", \"item_sequence\", \"item_indice\", \"rating\", args.max_len, args.pad_token, args.timestamp_col, \n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    rating_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_rating_dataset, batch_size=args.batch_size, shuffle=False, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c3a9b8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11295, 11295,  1784,  1784,  9042,  9042,  1542,  1542, 10418, 10418,\n",
      "         2786,  2786,  6758,  6758,  8761,  8761,  6185,  6185,  1134,  1134,\n",
      "        11437, 11437, 12823, 12823,  8666,  8666,  6710,  6710,  1590,  1590,\n",
      "         1590,  1590, 11747, 11747,  2393,  2393, 10403, 10403,  3982,  3982,\n",
      "         4098,  4098,  7417,  7417,  6394,  6394,  7293,  7293,  5421,  5421,\n",
      "        14988, 14988,  1574,  1574, 16260, 16260, 10908, 10908,  1861,  1861,\n",
      "        14374, 14374, 13038, 13038,  8429,  8429,  2164,  2164,  4053,  4053,\n",
      "         6451,  6451,  1394,  1394, 15498, 15498, 11209, 11209, 14837, 14837,\n",
      "        15761, 15761, 10092, 10092, 12914, 12914, 13467, 13467,  6383,  6383,\n",
      "         7731,  7731,  1677,  1677,  7342,  7342,  7824,  7824, 11332, 11332,\n",
      "         2189,  2189,  5829,  5829,  5942,  5942,   746,   746, 12588, 12588,\n",
      "         4263,  4263, 13562, 13562, 12115, 12115, 12115, 12115, 12115, 12115,\n",
      "        12115, 12115,  3016,  3016, 12115, 12115,  7119,  7119,  2268,  2268,\n",
      "         4516,  4516,  9878,  9878,  7433,  7433,  8044,  8044,   298,   298,\n",
      "         9744,  9744,  9744,  9744,  9362,  9362,  1666,  1666,   278,   278,\n",
      "         7366,  7366, 14336, 14336,  2563,  2563, 10118, 10118,  3755,  3755,\n",
      "         4382,  4382, 14145, 14145,   243,   243,  1701,  1701, 15554, 15554,\n",
      "          753,   753, 14310, 14310, 14310, 14310, 10716, 10716, 10716, 10716,\n",
      "         9869,  9869,  6789,  6789, 10313, 10313,  5348,  5348,  5348,  5348,\n",
      "        14586, 14586, 14620, 14620,  8965,  8965,  6957,  6957,  5942,  5942,\n",
      "         7983,  7983, 14182, 14182,  1477,  1477,  2524,  2524,  4552,  4552,\n",
      "        15715, 15715,  1907,  1907,  6329,  6329,   372,   372, 14395, 14395,\n",
      "        11174, 11174,   253,   253, 14539, 14539,  9061,  9061,  4281,  4281,\n",
      "         3156,  3156, 13897, 13897, 13897, 13897, 13897, 13897, 15961, 15961,\n",
      "        13897, 13897, 10479, 10479,   777,   777,  9538,  9538,  2176,  2176,\n",
      "        11700, 11700,  8267,  8267,  2833,  2833])\n",
      "tensor([[1898, 3479, 3908,  ...,  106, 3557, 4172],\n",
      "        [3479, 3908, 1570,  ..., 3557, 4172,  528],\n",
      "        [4319, 3382, 4330,  ..., 3167, 1071, 2677],\n",
      "        ...,\n",
      "        [4411, 3913, 1583,  ..., 3188, 3774, 4324],\n",
      "        [3647, 2694, 4398,  ..., 3195, 2694, 3800],\n",
      "        [2694, 4398, 1507,  ..., 2694, 3800, 3467]])\n",
      "tensor([ 528, 3503, 3925, 1507, 4273, 3819, 3550,   46, 4471,  212, 3590, 2003,\n",
      "        3216, 3485, 3148, 1173, 4589, 2591, 2583, 3039, 3634, 4038, 3227, 4443,\n",
      "        2800, 3443, 2237, 4595, 3723, 3453, 1860, 2993, 4124, 4445, 3682, 1039,\n",
      "        4647, 1341, 4157, 1703, 2516, 3587, 3428, 3432, 4618, 4021, 3019, 3545,\n",
      "        4047, 2788, 4291, 4422, 4565, 3578, 4786,   46, 4446, 4429,  237, 3936,\n",
      "        1872, 3082, 1666, 3925, 4018,  755, 4753, 3914, 3664, 3504, 4657, 4614,\n",
      "        4784, 4055, 3844, 3112, 3509, 4072, 4407,   46, 2886, 4777, 3983, 3723,\n",
      "         423, 4304, 4384,  890, 1221, 1479, 3089, 1292, 3504, 4568, 4251, 2612,\n",
      "        3223, 1964,  120, 4221, 4054, 4610, 4160, 1039,  285, 1306, 4235, 4618,\n",
      "         372, 3558, 3723, 2782, 2775, 3807, 1885, 3443, 4662, 2432, 3915, 1949,\n",
      "        4431, 3077, 1749, 3654, 2694, 3836, 2548, 1315, 4713, 2170, 3626, 1527,\n",
      "        4031, 2974, 1760, 2504, 3517, 1896, 4575,   30, 4086, 2969, 4268, 3891,\n",
      "        3989, 4594, 3907,  242, 4303, 1601, 3659, 3291, 2142,  282,  373, 4018,\n",
      "        4641,  875,  507, 2901, 3455, 3476, 2079, 3925, 3923, 4446, 1562, 4390,\n",
      "        4659, 3857,   72, 3736, 4401, 2194, 3743, 2848, 4323, 1604, 3852, 3899,\n",
      "        3590, 4761,   64, 3545,  287, 3923, 4249, 4089,  564,  487, 3800, 3868,\n",
      "        4276, 3202, 4720, 4086, 1044, 3723, 3039, 2694,  313,  863, 1308, 2877,\n",
      "        4473, 1080, 3265,  657, 3181, 4630, 2121, 3806, 3248, 4415, 4480, 2430,\n",
      "        3950, 3517, 2976, 3811,  557, 4565, 3067, 3070, 1787, 4054, 4586, 3578,\n",
      "        2031, 3124, 3204, 4447, 3227, 4454, 4692, 3236, 2166, 3415, 2331, 3545,\n",
      "        3472, 4700, 3818, 3039,  374, 3604, 3957, 1794, 3296, 4319, 4386, 2152,\n",
      "        4324, 3586, 3467, 4504])\n",
      "tensor([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
      "        0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "for i in val_loader:\n",
    "    print(i[\"user\"])\n",
    "    print(i[\"sequence\"])\n",
    "    print(i[\"item\"])\n",
    "    print(i[\"rating\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bf87c2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8764, 11791,  3810,  1698,  7657,  5694, 11980,  6694,  6349, 14496,\n",
      "        15097,  2119,  8156,  7260, 10062,  1871,  9245,  5886,  5896,  7455,\n",
      "        14399, 13116,  3887, 14094,  4692, 11056,  7399, 13695,   774,  7558,\n",
      "         8098,  3752,  3539, 10448, 14942,  7519, 13039, 14693, 14989,  1701,\n",
      "        16034,  8216, 16331,  2094,  4891,  5236,  2260, 10058, 12990, 16044,\n",
      "         8024,   656,  9890, 11125,  9945,  8688,  5327,  3158,  4140,  8502,\n",
      "         3256,  5543, 10498, 15323,  8203, 11943, 14939,  6804, 16037,  1146,\n",
      "        15469, 13265,  6954,   815,  8517,  3409,  5399,  6147, 11049,  6340,\n",
      "        11078, 11906,  5861, 14041,  3537,  5991,   473,  8732,  3667,  4332,\n",
      "        14393,  5055,  6763, 15848,  2682,  2194, 10789,  9596, 15559,  9195,\n",
      "         7930, 16285, 11608,  9157, 15012,  8426,  3970, 12041,  1227, 14942,\n",
      "          151, 11533,  3869, 11266, 11200,  4932,   295, 11579, 11159,  3846,\n",
      "        13533, 15895, 14985,  7893, 11735, 11424, 12135, 11675,  4684, 11039,\n",
      "          208,  9222, 14701, 15813,  6941,  7602, 14068,  2549,  9686, 14986,\n",
      "          175,  7860,  6479, 11994,  7689, 10780,  5150,  2842,  4959, 15072,\n",
      "        10115, 10935,  1863, 16357, 14172, 13275,  4131,  8183, 14740,  3667,\n",
      "         3623,  6978, 10019,  4150,  9850,  2709, 13625,  2892,  9644, 11638,\n",
      "        11513,  2092,    31, 13632, 13820, 10729,  8643,  9422,  3843, 15318,\n",
      "        14863,  7018, 10774,  6641,  8900, 11037, 15646,  8819,  5746,  7734,\n",
      "         8687,  8188,  2846,  9433,  7254,  6796, 10589,  3647, 10844,  1917,\n",
      "          489,  2164, 12841, 10759, 14616, 12816, 12771, 16139,  7479,  4822,\n",
      "         3577,  9112,  6535,    94, 11714, 11288, 12411, 14211,  7338,  8946,\n",
      "         7896,  6861, 14406,  2475,  3124, 12714, 13439, 13600,  9898,  7374,\n",
      "         3442,  8230,   211,  9424, 11012,  3663,  1345, 11651,  1684, 11411,\n",
      "        13425, 13961, 10306,  5777,  4022, 11598,  9545,  5592, 14205,  8430,\n",
      "        12514,  6028, 16206, 14793,  1520,  2257])\n",
      "tensor([[4817, 4817, 4817,  ..., 4511,  620, 4048],\n",
      "        [ 918, 4201, 1838,  ..., 4616, 4563, 3122],\n",
      "        [4817, 4817, 4817,  ..., 4817,  330, 1710],\n",
      "        ...,\n",
      "        [2799, 1728, 3312,  ...,  426,  387, 3740],\n",
      "        [4817, 4817, 4817,  ..., 4817, 4817, 4597],\n",
      "        [2201, 3571, 4425,  ...,  487, 2272, 3607]])\n",
      "tensor([4287, 2207, 2253, 3647, 4401,  371, 3642,  112, 2773, 2957,  640, 3454,\n",
      "        1039,  285, 4081, 4734, 3925, 1188,  810, 3486, 2683, 1556,  755, 1927,\n",
      "         225, 4452, 4252, 4450, 3200, 3428, 2043,  423, 2626,  285, 4808, 4053,\n",
      "        3861, 4375,  597, 3031,  864, 4121, 4204, 3494, 1049, 2874, 2531, 3333,\n",
      "        4023, 1237, 2032, 4616, 2714, 3587,  133, 1689, 2093,  161, 4080,  354,\n",
      "        3901,  856, 3555,  247, 4366,  852, 1975, 2694,  400,  561, 4516, 1456,\n",
      "        1779, 1476, 4411, 3543, 1067, 4120, 2475,  118, 1348, 1047,  154,  273,\n",
      "        2336, 3717, 1295, 2183, 4683,  449, 3965,  343, 3594, 1359, 3028,  310,\n",
      "        2735, 4018, 2446, 4755, 4194, 1862, 4658,   91, 1067, 3357, 1122, 2355,\n",
      "        4761,  378, 2213, 4266,  109, 3269, 2206, 2859, 2335, 1237,  293, 2071,\n",
      "        1741, 1434, 2437, 2443, 1370, 4615, 2547, 4479, 4135, 2694, 1691, 1791,\n",
      "        2859, 4540, 4386, 3723, 2071, 1146, 1604, 1375, 4541, 1346, 3750, 4229,\n",
      "        2109, 2387, 3830,  621, 2158, 3945, 4026, 3647, 1831, 4434, 3381, 2929,\n",
      "        3130, 4032, 3455, 4340, 4348, 3688, 3585, 4377, 3981,  770, 2198, 3635,\n",
      "        3683,  446, 4674,  533, 1839, 3850, 3790,  762, 4544, 1279, 3477, 1348,\n",
      "        4518, 2604, 1994, 1047, 1280, 4498, 2539, 4434, 4216,  489,  601, 2527,\n",
      "        3027,  905,  752,  451, 1254,  987,  485, 2509, 3717, 3478, 3739, 3678,\n",
      "        2721, 4712, 4508, 4533, 4023, 1163, 4617, 4234,  812, 1570, 2237, 2257,\n",
      "         791, 1996, 1277, 3749, 4046, 1784, 1975, 4803, 2376, 3930, 1691, 3370,\n",
      "         687, 4399, 3321, 1796, 2741, 1957, 1089, 2602, 4621, 2417, 1327, 4220,\n",
      "        1214,  917, 3472,  822, 4045, 4219, 4606, 3408, 3963, 4041, 1728, 2694,\n",
      "        3183, 3717, 3678, 3344])\n",
      "tensor([1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
      "        1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i[\"user\"])\n",
    "    print(i[\"sequence\"])\n",
    "    print(i[\"item\"])\n",
    "    print(i[\"rating\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "17f32acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-01 14:44:11.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mNumber of users: 16407, Number of items: 4817\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "item_indices = train_df[args.item_col].unique()\n",
    "user_indices = train_df[args.user_col].unique()\n",
    "n_items = len(item_indices)\n",
    "n_users = len(user_indices)\n",
    "\n",
    "logger.info(f\"Number of users: {n_users}, Number of items: {n_items}\")\n",
    "model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6a08e840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SASRec(\n",
       "  (item_emb): Embedding(4818, 128, padding_idx=4817)\n",
       "  (pos_emb): Embedding(10, 128)\n",
       "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
       "  (attention_layernorms): ModuleList(\n",
       "    (0): LayerNorm((128,), eps=1e-08, elementwise_affine=True)\n",
       "  )\n",
       "  (attention_layers): ModuleList(\n",
       "    (0): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (forward_layernorms): ModuleList(\n",
       "    (0): LayerNorm((128,), eps=1e-08, elementwise_affine=True)\n",
       "  )\n",
       "  (forward_layers): ModuleList(\n",
       "    (0): PointWiseFeedForward(\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the model parameters\n",
    "for name, param in model.named_parameters():\n",
    "    try:\n",
    "        torch.nn.init.xavier_normal_(param.data)\n",
    "    except:\n",
    "        pass  # skip if the parameter is not a tensor\n",
    "\n",
    "model.pos_emb.weight.data[0, :] = 0\n",
    "model.item_emb.weight.data[0, :] = 0\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "939d52ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AE227WAM4NWQPJI33OPN7ZARNNZQ'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idm_path = os.path.abspath(\"../data_for_ai/interim/idm_16407u.json\")\n",
    "idm = IDMapper().load(idm_path)\n",
    "idm.get_user_id(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6be76f",
   "metadata": {},
   "source": [
    "## overfit 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0675501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n",
      "\n",
      "  | Name  | Type   | Params | Mode \n",
      "-----------------------------------------\n",
      "0 | model | SASRec | 717 K  | train\n",
      "-----------------------------------------\n",
      "717 K     Trainable params\n",
      "0         Non-trainable params\n",
      "717 K     Total params\n",
      "2.871     Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad40118bc6c4f0591ad1b7c1378fe64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:252: UserWarning:\n",
      "\n",
      "You requested to overfit but enabled val dataloader shuffling. We are turning off the val dataloader shuffling for you.\n",
      "\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: PossibleUserWarning:\n",
      "\n",
      "The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:252: UserWarning:\n",
      "\n",
      "You requested to overfit but enabled train dataloader shuffling. We are turning off the train dataloader shuffling for you.\n",
      "\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: PossibleUserWarning:\n",
      "\n",
      "The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:310: PossibleUserWarning:\n",
      "\n",
      "The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef06373878ee4619920e449d9850fe61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cab67b2feb9480f9b56bdaf6464192b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231494f71a494d219fcef49fd6ed8a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d7fb7e95f9c46edad1a15895427129a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c7f5e17de84d86a90eb550467b61e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f5e25186054147887c941b0a323cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4de0d82ae4c412f9e334aed14b30dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f35b7cc1244a8b935f21fdcb95fdab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61745664a1654913a4f831194fa5b6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339d7eecc8cc477085d00e0ae1a782c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9124efca2b24bf39738e04a954d64e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588f62a2347f46409069f8078e538d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00fd609c68f4af19ef7624177c47915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dce72e1254547a59e514fc197d18a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3c8902a0c344189d34bde442995a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb4f8db39474ba9934a4e628d1353cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8abed078c32d4010a6f9ff65710f19a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4e2e3650784302a55bde0b7afeabd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960cee9e78ba45d7b311959fd6d4c04b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d914d15df14016824aec2702b8e282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58270eda7bcd4d7c8feb7b9e097ef781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34f2e18c6fe4a31b22633290adacbd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9b6c86019e45f79c366c4a5718ce92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdbd5b4172f4ea5a90116aeaacc2056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b84f060aea4392addf130a6ad0065f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd585c62634c4c2db02047fd762f5174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607a20fd1a4c4ca8b0a38539d9be80ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a869c6965d0441268dd8b4c577472b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5b9d3cec42494b940e1e0f6afb0c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e290a103a35400bb71c56e8ee278c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00682cd4bdf94dc9bb643b2821d7a8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c4ddf3ffb549e49526d6e968f2fee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae779813a1274f558066454278528c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f1c104ad7647339fd7d9d4f5bc3292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d99a27e30cd4f93adeb64d01a6308d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d68531f3a64916bac5e9ca18b96643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8930567a658f4dd89f9428f1267949a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9965bc3a3d34f98b34b890f0b47690c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccc8fd508b447c08bf4d56a0e5037eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39faf7b8cc8842f78e06110b3b3dac6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2337398cc06c408c8274983ddb6564f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04c475aecd44b9a86a6c99ff76943fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2f61d2d9ec4c3ca54612bceef36fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb94caea870f4d8ca902216cfedb9ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe04b92456f147789deb8d8bae37981b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673b0449924f4074b6061131e4e7f599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f70ed9daa394662b5c09170d39af662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55d77ed006b48ff865499fd61d92833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ac1a6a7006491a8926fbe63b4fa239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1034e0056c4936bea4855bb7d7a8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07fd30b191e485d9ac206457d4167da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869d3003fb9448f7b3414dbeef08bd56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d378c89734441882fe48e4de9e73c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925fd91f3c1a4599aa91a2cf742f8c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f34660d3bc441fd9f4b6f97b77076af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88ba1e7b26c4d7c8b38e4c370c5157a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcbf835301564aee8b4633729aed750f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "263792f798e246dda473185993a86060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81eb438cfadc48daa30a183c4d6a0ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b015acff34824a45a2ef843df81a8794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58876b7a9024bd8baaae74f71bf97b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee8bbe5bf3944af9a7b4f5ca0e007c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7c193bb4e8426e9689b34785c324b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc20c6e902e46f9854638ad4f01ca73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a82d8c7d5c74e0e8f0f3c4bd462560b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0273fbb17d6f49459e3ab8dff935df09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-01 14:44:55.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.gSASRec.trainer\u001b[0m:\u001b[36mon_fit_end\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mLogging ranking metrics...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: {'user_indice': [8071, 7935, 13705, 12730, 3735, 14832, 10069, 15786, 6742, 8061], 'recommendation': [[1204, 2004, 2, 3, 4, 3359, 2006, 3357, 2012, 9, 2013, 3350, 2014, 13, 2015, 2558, 2017, 17, 18, 19, 3344, 2018, 22, 23, 24, 25, 26, 27, 28, 2024, 30, 3340, 2027, 3339, 3338, 35, 36, 37, 3337, 2555, 40, 2029, 2030, 43, 2031, 2032, 2033, 47, 2554, 2552, 50, 3330, 2038, 3328, 3326, 55, 2551, 2040, 2550, 59, 60, 61, 62, 63, 3324, 2045, 66, 2046, 68, 69, 70, 71, 2047, 73, 2549, 2050, 2052, 2546, 78, 2057, 80, 81, 3322, 2544, 84, 85, 86, 2541, 2061, 3320, 2062, 91, 92, 2066, 3318, 95, 96, 2068, 98, 2537], [1204, 2004, 2, 3, 4, 3359, 2006, 3357, 2012, 9, 2013, 3350, 2014, 13, 2015, 2558, 2017, 17, 18, 19, 3344, 2018, 22, 23, 24, 25, 26, 27, 28, 2024, 30, 3340, 2027, 3339, 3338, 35, 36, 37, 3337, 2555, 40, 2029, 2030, 43, 2031, 2032, 2033, 47, 2554, 2552, 50, 3330, 2038, 3328, 3326, 55, 2551, 2040, 2550, 59, 60, 61, 62, 63, 3324, 2045, 66, 2046, 68, 69, 70, 71, 2047, 73, 2549, 2050, 2052, 2546, 78, 2057, 80, 81, 3322, 2544, 84, 85, 86, 2541, 2061, 3320, 2062, 91, 92, 2066, 3318, 95, 96, 2068, 98, 2537], [1204, 2004, 2, 3, 4, 3359, 2006, 3357, 2012, 9, 2013, 3350, 2014, 13, 2015, 2558, 2017, 17, 18, 19, 3344, 2018, 22, 23, 24, 25, 26, 27, 28, 2024, 30, 3340, 2027, 3339, 3338, 35, 36, 37, 3337, 2555, 40, 2029, 2030, 43, 2031, 2032, 2033, 47, 2554, 2552, 50, 3330, 2038, 3328, 3326, 55, 2551, 2040, 2550, 59, 60, 61, 62, 63, 3324, 2045, 66, 2046, 68, 69, 70, 71, 2047, 73, 2549, 2050, 2052, 2546, 78, 2057, 80, 81, 3322, 2544, 84, 85, 86, 2541, 2061, 3320, 2062, 91, 92, 2066, 3318, 95, 96, 2068, 98, 2537], [1204, 2004, 2, 3, 4, 3359, 2006, 3357, 2012, 9, 2013, 3350, 2014, 13, 2015, 2558, 2017, 17, 18, 19, 3344, 2018, 22, 23, 24, 25, 26, 27, 28, 2024, 30, 3340, 2027, 3339, 3338, 35, 36, 37, 3337, 2555, 40, 2029, 2030, 43, 2031, 2032, 2033, 47, 2554, 2552, 50, 3330, 2038, 3328, 3326, 55, 2551, 2040, 2550, 59, 60, 61, 62, 63, 3324, 2045, 66, 2046, 68, 69, 70, 71, 2047, 73, 2549, 2050, 2052, 2546, 78, 2057, 80, 81, 3322, 2544, 84, 85, 86, 2541, 2061, 3320, 2062, 91, 92, 2066, 3318, 95, 96, 2068, 98, 2537], [1204, 2004, 2, 3, 4, 3359, 2006, 3357, 2012, 9, 2013, 3350, 2014, 13, 2015, 2558, 2017, 17, 18, 19, 3344, 2018, 22, 23, 24, 25, 26, 27, 28, 2024, 30, 3340, 2027, 3339, 3338, 35, 36, 37, 3337, 2555, 40, 2029, 2030, 43, 2031, 2032, 2033, 47, 2554, 2552, 50, 3330, 2038, 3328, 3326, 55, 2551, 2040, 2550, 59, 60, 61, 62, 63, 3324, 2045, 66, 2046, 68, 69, 70, 71, 2047, 73, 2549, 2050, 2052, 2546, 78, 2057, 80, 81, 3322, 2544, 84, 85, 86, 2541, 2061, 3320, 2062, 91, 92, 2066, 3318, 95, 96, 2068, 98, 2537], [602, 2197, 2, 3, 4, 2198, 6, 2649, 2648, 2201, 2202, 11, 2203, 13, 14, 15, 2645, 17, 18, 19, 2205, 2642, 2207, 23, 24, 25, 26, 2640, 28, 2639, 30, 2638, 2637, 2636, 2635, 35, 36, 2634, 2633, 2216, 40, 41, 2632, 43, 2218, 2630, 46, 47, 2220, 49, 50, 2629, 2628, 2625, 54, 55, 56, 2224, 2620, 2226, 60, 61, 62, 2619, 2618, 2229, 66, 2615, 68, 69, 70, 71, 72, 73, 2231, 2232, 2233, 2612, 2235, 2611, 80, 81, 2610, 2238, 84, 85, 86, 87, 88, 2239, 2608, 2606, 92, 2603, 2243, 95, 96, 2244, 98, 2245], [1204, 2004, 2, 3, 4, 3359, 2006, 3357, 2012, 9, 2013, 3350, 2014, 13, 2015, 2558, 2017, 17, 18, 19, 3344, 2018, 22, 23, 24, 25, 26, 27, 28, 2024, 30, 3340, 2027, 3339, 3338, 35, 36, 37, 3337, 2555, 40, 2029, 2030, 43, 2031, 2032, 2033, 47, 2554, 2552, 50, 3330, 2038, 3328, 3326, 55, 2551, 2040, 2550, 59, 60, 61, 62, 63, 3324, 2045, 66, 2046, 68, 69, 70, 71, 2047, 73, 2549, 2050, 2052, 2546, 78, 2057, 80, 81, 3322, 2544, 84, 85, 86, 2541, 2061, 3320, 2062, 91, 92, 2066, 3318, 95, 96, 2068, 98, 2537], [1204, 2004, 2, 3, 4, 3359, 2006, 3357, 2012, 9, 2013, 3350, 2014, 13, 2015, 2558, 2017, 17, 18, 19, 3344, 2018, 22, 23, 24, 25, 26, 27, 28, 2024, 30, 3340, 2027, 3339, 3338, 35, 36, 37, 3337, 2555, 40, 2029, 2030, 43, 2031, 2032, 2033, 47, 2554, 2552, 50, 3330, 2038, 3328, 3326, 55, 2551, 2040, 2550, 59, 60, 61, 62, 63, 3324, 2045, 66, 2046, 68, 69, 70, 71, 2047, 73, 2549, 2050, 2052, 2546, 78, 2057, 80, 81, 3322, 2544, 84, 85, 86, 2541, 2061, 3320, 2062, 91, 92, 2066, 3318, 95, 96, 2068, 98, 2537], [1204, 2004, 2, 3, 4, 3359, 2006, 3357, 2012, 9, 2013, 3350, 2014, 13, 2015, 2558, 2017, 17, 18, 19, 3344, 2018, 22, 23, 24, 25, 26, 27, 28, 2024, 30, 3340, 2027, 3339, 3338, 35, 36, 37, 3337, 2555, 40, 2029, 2030, 43, 2031, 2032, 2033, 47, 2554, 2552, 50, 3330, 2038, 3328, 3326, 55, 2551, 2040, 2550, 59, 60, 61, 62, 63, 3324, 2045, 66, 2046, 68, 69, 70, 71, 2047, 73, 2549, 2050, 2052, 2546, 78, 2057, 80, 81, 3322, 2544, 84, 85, 86, 2541, 2061, 3320, 2062, 91, 92, 2066, 3318, 95, 96, 2068, 98, 2537], [1204, 2004, 2, 3, 4, 3359, 2006, 3357, 2012, 9, 2013, 3350, 2014, 13, 2015, 2558, 2017, 17, 18, 19, 3344, 2018, 22, 23, 24, 25, 26, 27, 28, 2024, 30, 3340, 2027, 3339, 3338, 35, 36, 37, 3337, 2555, 40, 2029, 2030, 43, 2031, 2032, 2033, 47, 2554, 2552, 50, 3330, 2038, 3328, 3326, 55, 2551, 2040, 2550, 59, 60, 61, 62, 63, 3324, 2045, 66, 2046, 68, 69, 70, 71, 2047, 73, 2549, 2050, 2052, 2546, 78, 2057, 80, 81, 3322, 2544, 84, 85, 86, 2541, 2061, 3320, 2062, 91, 92, 2066, 3318, 95, 96, 2068, 98, 2537]], 'score': [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]}\n",
      "user_indice: [8071, 7935, 13705, 12730, 3735, 14832, 10069, 15786, 6742, 8061]\n",
      "recommendation: [[1204, 2004, 2, 3, 4, 3359, 2006, 3357, 2012, 9, 2013, 3350, 2014, 13, 2015, 2558, 2017, 17, 18, 19, 3344, 2018, 22, 23, 24, 25, 26, 27, 28, 2024, 30, 3340, 2027, 3339, 3338, 35, 36, 37, 3337, 2555, 40, 2029, 2030, 43, 2031, 2032, 2033, 47, 2554, 2552, 50, 3330, 2038, 3328, 3326, 55, 2551, 2040, 2550, 59, 60, 61, 62, 63, 3324, 2045, 66, 2046, 68, 69, 70, 71, 2047, 73, 2549, 2050, 2052, 2546, 78, 2057, 80, 81, 3322, 2544, 84, 85, 86, 2541, 2061, 3320, 2062, 91, 92, 2066, 3318, 95, 96, 2068, 98, 2537], [1204, 2004, 2, 3, 4, 3359, 2006, 3357, 2012, 9, 2013, 3350, 2014, 13, 2015, 2558, 2017, 17, 18, 19, 3344, 2018, 22, 23, 24, 25, 26, 27, 28, 2024, 30, 3340, 2027, 3339, 3338, 35, 36, 37, 3337, 2555, 40, 2029, 2030, 43, 2031, 2032, 2033, 47, 2554, 2552, 50, 3330, 2038, 3328, 3326, 55, 2551, 2040, 2550, 59, 60, 61, 62, 63, 3324, 2045, 66, 2046, 68, 69, 70, 71, 2047, 73, 2549, 2050, 2052, 2546, 78, 2057, 80, 81, 3322, 2544, 84, 85, 86, 2541, 2061, 3320, 2062, 91, 92, 2066, 3318, 95, 96, 2068, 98, 2537], [1204, 2004, 2, 3, 4, 3359, 2006, 3357, 2012, 9, 2013, 3350, 2014, 13, 2015, 2558, 2017, 17, 18, 19, 3344, 2018, 22, 23, 24, 25, 26, 27, 28, 2024, 30, 3340, 2027, 3339, 3338, 35, 36, 37, 3337, 2555, 40, 2029, 2030, 43, 2031, 2032, 2033, 47, 2554, 2552, 50, 3330, 2038, 3328, 3326, 55, 2551, 2040, 2550, 59, 60, 61, 62, 63, 3324, 2045, 66, 2046, 68, 69, 70, 71, 2047, 73, 2549, 2050, 2052, 2546, 78, 2057, 80, 81, 3322, 2544, 84, 85, 86, 2541, 2061, 3320, 2062, 91, 92, 2066, 3318, 95, 96, 2068, 98, 2537], [1204, 2004, 2, 3, 4, 3359, 2006, 3357, 2012, 9, 2013, 3350, 2014, 13, 2015, 2558, 2017, 17, 18, 19, 3344, 2018, 22, 23, 24, 25, 26, 27, 28, 2024, 30, 3340, 2027, 3339, 3338, 35, 36, 37, 3337, 2555, 40, 2029, 2030, 43, 2031, 2032, 2033, 47, 2554, 2552, 50, 3330, 2038, 3328, 3326, 55, 2551, 2040, 2550, 59, 60, 61, 62, 63, 3324, 2045, 66, 2046, 68, 69, 70, 71, 2047, 73, 2549, 2050, 2052, 2546, 78, 2057, 80, 81, 3322, 2544, 84, 85, 86, 2541, 2061, 3320, 2062, 91, 92, 2066, 3318, 95, 96, 2068, 98, 2537], [1204, 2004, 2, 3, 4, 3359, 2006, 3357, 2012, 9, 2013, 3350, 2014, 13, 2015, 2558, 2017, 17, 18, 19, 3344, 2018, 22, 23, 24, 25, 26, 27, 28, 2024, 30, 3340, 2027, 3339, 3338, 35, 36, 37, 3337, 2555, 40, 2029, 2030, 43, 2031, 2032, 2033, 47, 2554, 2552, 50, 3330, 2038, 3328, 3326, 55, 2551, 2040, 2550, 59, 60, 61, 62, 63, 3324, 2045, 66, 2046, 68, 69, 70, 71, 2047, 73, 2549, 2050, 2052, 2546, 78, 2057, 80, 81, 3322, 2544, 84, 85, 86, 2541, 2061, 3320, 2062, 91, 92, 2066, 3318, 95, 96, 2068, 98, 2537], [602, 2197, 2, 3, 4, 2198, 6, 2649, 2648, 2201, 2202, 11, 2203, 13, 14, 15, 2645, 17, 18, 19, 2205, 2642, 2207, 23, 24, 25, 26, 2640, 28, 2639, 30, 2638, 2637, 2636, 2635, 35, 36, 2634, 2633, 2216, 40, 41, 2632, 43, 2218, 2630, 46, 47, 2220, 49, 50, 2629, 2628, 2625, 54, 55, 56, 2224, 2620, 2226, 60, 61, 62, 2619, 2618, 2229, 66, 2615, 68, 69, 70, 71, 72, 73, 2231, 2232, 2233, 2612, 2235, 2611, 80, 81, 2610, 2238, 84, 85, 86, 87, 88, 2239, 2608, 2606, 92, 2603, 2243, 95, 96, 2244, 98, 2245], [1204, 2004, 2, 3, 4, 3359, 2006, 3357, 2012, 9, 2013, 3350, 2014, 13, 2015, 2558, 2017, 17, 18, 19, 3344, 2018, 22, 23, 24, 25, 26, 27, 28, 2024, 30, 3340, 2027, 3339, 3338, 35, 36, 37, 3337, 2555, 40, 2029, 2030, 43, 2031, 2032, 2033, 47, 2554, 2552, 50, 3330, 2038, 3328, 3326, 55, 2551, 2040, 2550, 59, 60, 61, 62, 63, 3324, 2045, 66, 2046, 68, 69, 70, 71, 2047, 73, 2549, 2050, 2052, 2546, 78, 2057, 80, 81, 3322, 2544, 84, 85, 86, 2541, 2061, 3320, 2062, 91, 92, 2066, 3318, 95, 96, 2068, 98, 2537], [1204, 2004, 2, 3, 4, 3359, 2006, 3357, 2012, 9, 2013, 3350, 2014, 13, 2015, 2558, 2017, 17, 18, 19, 3344, 2018, 22, 23, 24, 25, 26, 27, 28, 2024, 30, 3340, 2027, 3339, 3338, 35, 36, 37, 3337, 2555, 40, 2029, 2030, 43, 2031, 2032, 2033, 47, 2554, 2552, 50, 3330, 2038, 3328, 3326, 55, 2551, 2040, 2550, 59, 60, 61, 62, 63, 3324, 2045, 66, 2046, 68, 69, 70, 71, 2047, 73, 2549, 2050, 2052, 2546, 78, 2057, 80, 81, 3322, 2544, 84, 85, 86, 2541, 2061, 3320, 2062, 91, 92, 2066, 3318, 95, 96, 2068, 98, 2537], [1204, 2004, 2, 3, 4, 3359, 2006, 3357, 2012, 9, 2013, 3350, 2014, 13, 2015, 2558, 2017, 17, 18, 19, 3344, 2018, 22, 23, 24, 25, 26, 27, 28, 2024, 30, 3340, 2027, 3339, 3338, 35, 36, 37, 3337, 2555, 40, 2029, 2030, 43, 2031, 2032, 2033, 47, 2554, 2552, 50, 3330, 2038, 3328, 3326, 55, 2551, 2040, 2550, 59, 60, 61, 62, 63, 3324, 2045, 66, 2046, 68, 69, 70, 71, 2047, 73, 2549, 2050, 2052, 2546, 78, 2057, 80, 81, 3322, 2544, 84, 85, 86, 2541, 2061, 3320, 2062, 91, 92, 2066, 3318, 95, 96, 2068, 98, 2537], [1204, 2004, 2, 3, 4, 3359, 2006, 3357, 2012, 9, 2013, 3350, 2014, 13, 2015, 2558, 2017, 17, 18, 19, 3344, 2018, 22, 23, 24, 25, 26, 27, 28, 2024, 30, 3340, 2027, 3339, 3338, 35, 36, 37, 3337, 2555, 40, 2029, 2030, 43, 2031, 2032, 2033, 47, 2554, 2552, 50, 3330, 2038, 3328, 3326, 55, 2551, 2040, 2550, 59, 60, 61, 62, 63, 3324, 2045, 66, 2046, 68, 69, 70, 71, 2047, 73, 2549, 2050, 2052, 2546, 78, 2057, 80, 81, 3322, 2544, 84, 85, 86, 2541, 2061, 3320, 2062, 91, 92, 2066, 3318, 95, 96, 2068, 98, 2537]]\n",
      "score: [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]\n",
      "Recommendations_df:    user_indice recommendation score\n",
      "0         8071           1204   1.0\n",
      "1         8071           2004   1.0\n",
      "2         8071              2   1.0\n",
      "3         8071              3   1.0\n",
      "4         8071              4   1.0\n",
      "Recommendations_df:      user_indice item_indice score  rec_ranking                       user_id  \\\n",
      "0           8071        1204   1.0          1.0  AFZ4EK2LJ655XQKTEUELCARO6RYA   \n",
      "1           8071        2004   1.0          2.0  AFZ4EK2LJ655XQKTEUELCARO6RYA   \n",
      "2           8071           2   1.0          3.0  AFZ4EK2LJ655XQKTEUELCARO6RYA   \n",
      "3           8071           3   1.0          4.0  AFZ4EK2LJ655XQKTEUELCARO6RYA   \n",
      "4           8071           4   1.0          5.0  AFZ4EK2LJ655XQKTEUELCARO6RYA   \n",
      "..           ...         ...   ...          ...                           ...   \n",
      "995         8061          95   1.0         96.0  AFZ2LKCLXIYCNTYC43ZDPHB52KSQ   \n",
      "996         8061          96   1.0         97.0  AFZ2LKCLXIYCNTYC43ZDPHB52KSQ   \n",
      "997         8061        2068   1.0         98.0  AFZ2LKCLXIYCNTYC43ZDPHB52KSQ   \n",
      "998         8061          98   1.0         99.0  AFZ2LKCLXIYCNTYC43ZDPHB52KSQ   \n",
      "999         8061        2537   1.0        100.0  AFZ2LKCLXIYCNTYC43ZDPHB52KSQ   \n",
      "\n",
      "    parent_asin  \n",
      "0    B00CD5JC6S  \n",
      "1    B00U43F99A  \n",
      "2    B000001OM5  \n",
      "3    B00000K2YR  \n",
      "4    B00002EQCW  \n",
      "..          ...  \n",
      "995  B000ENRQ3M  \n",
      "996  B000ER5G6C  \n",
      "997  B00WIF2T7C  \n",
      "998  B000F5K82A  \n",
      "999  B01DN7OJ30  \n",
      "\n",
      "[1000 rows x 6 columns]\n",
      "Label_df:          user_indice  item_indice  rating  rating_rank\n",
      "254783         8251          289       1          1.0\n",
      "242559        13446         4226       1          1.0\n",
      "222524         5086         4194       1          1.0\n",
      "242557         9512         4324       1          1.0\n",
      "86540         14381         1802       1          1.0\n",
      "...             ...          ...     ...          ...\n",
      "30227         16206         1296       0        180.0\n",
      "30179         16206         2743       0        181.0\n",
      "30176         16206         1653       0        182.0\n",
      "30174         16206         3743       0        183.0\n",
      "30172         16206          795       0        184.0\n",
      "\n",
      "[254784 rows x 4 columns]\n",
      "Eval_df:          user_indice item_indice score  rec_ranking user_id parent_asin  \\\n",
      "0                 0         154   NaN          101     NaN         NaN   \n",
      "1                 0         446   NaN          101     NaN         NaN   \n",
      "2                 0         930   NaN          101     NaN         NaN   \n",
      "3                 0        1741   NaN          101     NaN         NaN   \n",
      "4                 0        1885   NaN          101     NaN         NaN   \n",
      "...             ...         ...   ...          ...     ...         ...   \n",
      "255770        16406        3030   NaN          101     NaN         NaN   \n",
      "255771        16406        3184   NaN          101     NaN         NaN   \n",
      "255772        16406        3379   NaN          101     NaN         NaN   \n",
      "255773        16406        3788   NaN          101     NaN         NaN   \n",
      "255774        16406        4541   NaN          101     NaN         NaN   \n",
      "\n",
      "        rating  rating_rank  \n",
      "0            1          2.0  \n",
      "1            0          7.0  \n",
      "2            1          5.0  \n",
      "3            1          4.0  \n",
      "4            0          9.0  \n",
      "...        ...          ...  \n",
      "255770       0         10.0  \n",
      "255771       0         12.0  \n",
      "255772       1          5.0  \n",
      "255773       1          9.0  \n",
      "255774       0         16.0  \n",
      "\n",
      "[255775 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\evidently\\metrics\\recsys\\f_beta_top_k.py:64: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "\u001b[32m2025-05-01 14:45:27.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.gSASRec.trainer\u001b[0m:\u001b[36mon_fit_end\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mEvidently metrics are available at: c:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\data\\first-attempt\\018-sasrec\u001b[0m\n",
      "\u001b[32m2025-05-01 14:45:27.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mLogs available at c:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\data\\first-attempt\\018-sasrec\\logs\\overfit\\lightning_logs\\version_77\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': [{'metric': 'NDCGKMetric', 'result': {'k': 10, 'current': 1     0.000000\n",
      "2     0.000000\n",
      "3     0.000000\n",
      "4     0.000000\n",
      "5     0.000008\n",
      "6     0.000007\n",
      "7     0.000006\n",
      "8     0.000006\n",
      "9     0.000006\n",
      "10    0.000005\n",
      "dtype: float64, 'current_value': 5.5420266117497916e-06, 'reference': None, 'reference_value': None}}, {'metric': 'RecallTopKMetric', 'result': {'k': 100, 'current': 0     0.000000\n",
      "1     0.000000\n",
      "2     0.000000\n",
      "3     0.000000\n",
      "4     0.000003\n",
      "        ...   \n",
      "95    0.000059\n",
      "96    0.000059\n",
      "97    0.000059\n",
      "98    0.000059\n",
      "99    0.000059\n",
      "Length: 100, dtype: float64, 'current_value': 5.9366488329735725e-05, 'reference': None, 'reference_value': None}}, {'metric': 'PrecisionTopKMetric', 'result': {'k': 100, 'current': 0     0.000000\n",
      "1     0.000000\n",
      "2     0.000000\n",
      "3     0.000000\n",
      "4     0.000012\n",
      "        ...   \n",
      "95    0.000005\n",
      "96    0.000005\n",
      "97    0.000005\n",
      "98    0.000005\n",
      "99    0.000005\n",
      "Length: 100, dtype: float64, 'current_value': 4.875967574815627e-06, 'reference': None, 'reference_value': None}}, {'metric': 'FBetaTopKMetric', 'result': {'k': 10, 'current': 0         NaN\n",
      "1         NaN\n",
      "2         NaN\n",
      "3         NaN\n",
      "4    0.000005\n",
      "5    0.000004\n",
      "6    0.000004\n",
      "7    0.000004\n",
      "8    0.000004\n",
      "9    0.000004\n",
      "dtype: float64, 'current_value': 3.8093496678247085e-06, 'reference': None, 'reference_value': None}}, {'metric': 'PersonalizationMetric', 'result': {'k': 10, 'current_value': 0.13999999999999993, 'current_table': {'2694': 1748, '3089': 1684, '2237': 1139, '2253': 1129, '3678': 1077, '3443': 992, '4516': 858, '954': 719, '3839': 694, '3585': 651}, 'reference_value': None, 'reference_table': None}}]}\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=5, mode=\"min\", verbose=False\n",
    ")\n",
    "\n",
    "model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "lit_model = SASRecLitModule(\n",
    "    model,\n",
    "    log_dir=args.notebook_persit_dp,\n",
    "    accelerator=args.device,\n",
    "    lr=args.lr,\n",
    "    l2_emb=args.l2_emb,\n",
    "    idm= idm\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persit_dp}/logs/overfit\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    max_epochs=args.num_epochs,\n",
    "    overfit_batches=1,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=train_loader,\n",
    ")\n",
    "logger.info(f\"Logs available at {trainer.log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ddfce9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Args' object has no attribute 'embedding_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      1\u001b[39m early_stopping = EarlyStopping(\n\u001b[32m      2\u001b[39m     monitor=\u001b[33m\"\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m\"\u001b[39m, patience=args.early_stopping_patience, mode=\u001b[33m\"\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m\"\u001b[39m, verbose=\u001b[38;5;28;01mFalse\u001b[39;00m, min_delta=\u001b[32m0.0025\u001b[39m\n\u001b[32m      3\u001b[39m )\n\u001b[32m      5\u001b[39m checkpoint_callback = ModelCheckpoint(\n\u001b[32m      6\u001b[39m     dirpath=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs.notebook_persit_dp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/checkpoints\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     filename=\u001b[33m\"\u001b[39m\u001b[33mbest-checkpoint\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     mode=\u001b[33m\"\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m model = init_model(n_users, n_items, \u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding_dim\u001b[49m, args.dropout)\n\u001b[32m     14\u001b[39m lit_model = SASRecLitModule(\n\u001b[32m     15\u001b[39m     model,\n\u001b[32m     16\u001b[39m     lr=args.lr,\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m     idm= idm\n\u001b[32m     21\u001b[39m )\n\u001b[32m     23\u001b[39m log_dir = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs.notebook_persit_dp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/logs/run\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\pydantic\\main.py:891\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    888\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    889\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    890\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m891\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Args' object has no attribute 'embedding_dim'"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=args.early_stopping_patience, mode=\"min\", verbose=False, min_delta=0.0025\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{args.notebook_persit_dp}/checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "lit_model = SASRecLitModule(\n",
    "    model,\n",
    "    log_dir=args.notebook_persit_dp,\n",
    "    accelerator=args.device,\n",
    "    lr=args.lr,\n",
    "    l2_emb=args.l2_emb,\n",
    "    idm= idm\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persit_dp}/logs/run\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    max_epochs=args.num_epochs,\n",
    "    callbacks=[early_stopping, checkpoint_callback],\n",
    "    logger=args._mlf_logger if args.log_to_mlflow else None,\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")\n",
    "\n",
    "# Change the library as a workaround for the issue in the latest Lightning release\n",
    "#https://github.com/Lightning-AI/pytorch-lightning/pull/20669/commits/429f732a0528c558e701da7ec01e51c1e2e4f32e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8d60a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = [args]\n",
    "\n",
    "if args.log_to_mlflow:\n",
    "    run_id = trainer.logger.run_id\n",
    "\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        for params in all_params:\n",
    "            params_dict = params.model_dump()\n",
    "            params_ = dict()\n",
    "            for k, v in params_dict.items():\n",
    "                if k == \"top_K\":\n",
    "                    k = \"top_big_K\"\n",
    "                if k == \"top_k\":\n",
    "                    k = \"top_small_k\"\n",
    "                params_[f\"{params.__repr_name__()}.{k}\"] = v\n",
    "            mlflow.log_params(params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hm-scalablerecs-QHnDFvap-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
