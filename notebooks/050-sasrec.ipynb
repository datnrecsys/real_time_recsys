{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6defc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52b77b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydantic import BaseModel\n",
    "import sys\n",
    "import os\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from loguru import logger\n",
    "from load_dotenv import load_dotenv\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import mlflow\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src.utils.embedding_id_mapper import IDMapper\n",
    "from src.algo.gSASRec.model import SASRec\n",
    "from src.algo.gSASRec.dataset import SASRecDataset\n",
    "from src.algo.gSASRec.trainer import SASRecLitModule\n",
    "from src.eval.utils import create_rec_df, create_label_df, merge_recs_with_target\n",
    "from src.eval.log_metrics import log_ranking_metrics, log_classification_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "737a8749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ace436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-06 20:56:22.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mSetting up Mlflow experiment: first-attempt, run_name: 050-sasrec\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"testing\": false,\n",
      "  \"log_to_mlflow\": true,\n",
      "  \"experiment_name\": \"first-attempt\",\n",
      "  \"run_name\": \"050-sasrec\",\n",
      "  \"notebook_persit_dp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\notebooks\\\\data\\\\first-attempt\\\\050-sasrec\",\n",
      "  \"user_col\": \"user_id\",\n",
      "  \"item_col\": \"parent_asin\",\n",
      "  \"rating_col\": \"rating\",\n",
      "  \"timestamp_col\": \"timestamp\",\n",
      "  \"group_name\": \"seq-modelling\",\n",
      "  \"top_K\": 100,\n",
      "  \"top_k\": 10,\n",
      "  \"batch_size\": 512,\n",
      "  \"lr\": 0.0005,\n",
      "  \"l2_emb\": 0.0,\n",
      "  \"early_stopping_patience\": 10,\n",
      "  \"device\": \"cpu\",\n",
      "  \"num_epochs\": 100,\n",
      "  \"max_len\": 10,\n",
      "  \"dropout\": 0.5,\n",
      "  \"hidden_units\": 128,\n",
      "  \"num_blocks\": 1,\n",
      "  \"num_heads\": 4,\n",
      "  \"num_workers\": 3,\n",
      "  \"train_data_fp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\data_for_ai\\\\interim\\\\train_sample_interactions_16407u_neg_seq.parquet\",\n",
      "  \"val_data_fp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\data_for_ai\\\\interim\\\\val_sample_interactions_16407u_neg_seq.parquet\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Args(BaseModel):\n",
    "    testing: bool = False\n",
    "    log_to_mlflow: bool = True\n",
    "    experiment_name: str = \"first-attempt\"\n",
    "    run_name: str = f\"050-sasrec\"\n",
    "    notebook_persit_dp: str = None\n",
    "    \n",
    "    user_col: str = \"user_id\"\n",
    "    item_col: str = \"parent_asin\"\n",
    "    rating_col: str = \"rating\"\n",
    "    timestamp_col: str = \"timestamp\"\n",
    "    group_name: str = \"seq-modelling\"\n",
    "\n",
    "    top_K: int = 100\n",
    "    top_k: int = 10\n",
    "\n",
    "    batch_size: int = 512\n",
    "    lr: float = 0.00005\n",
    "    l2_emb: float = 0.0\n",
    "    early_stopping_patience: int = 15\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    num_epochs: int = 100\n",
    "\n",
    "    # SASrec specific\n",
    "    max_len: int = 10\n",
    "    dropout: float = 0.5\n",
    "    hidden_units: int = 128\n",
    "    num_blocks: int = 1\n",
    "    num_heads: int = 4\n",
    "    num_workers: int = 3\n",
    "    # seq_length: int = 10\n",
    "    \n",
    "    train_data_fp: str = os.path.abspath(\"../data_for_ai/interim/train_sample_interactions_16407u_neg_seq.parquet\")\n",
    "    val_data_fp: str = os.path.abspath(\"../data_for_ai/interim/val_sample_interactions_16407u_neg_seq.parquet\")\n",
    "\n",
    "    def init(self):\n",
    "        self.notebook_persit_dp = os.path.abspath(f\"data/{self.experiment_name}/{self.run_name}\")\n",
    "\n",
    "        if not (mlflow_uri := os.environ.get(\"MLFLOW_TRACKING_URI\")):\n",
    "            self.log_to_mlflow = False\n",
    "            logger.warning(\"MLFlow is not enabled. Turn off tracking to Mlflow.\")\n",
    "\n",
    "        if self.log_to_mlflow:\n",
    "            logger.info(\n",
    "                f\"Setting up Mlflow experiment: {self.experiment_name}, run_name: {self.run_name}\"\n",
    "            )\n",
    "\n",
    "            self._mlf_logger = MLFlowLogger(\n",
    "                experiment_name=self.experiment_name,\n",
    "                run_name=self.run_name,\n",
    "                tracking_uri=mlflow_uri,\n",
    "                log_model=True,\n",
    "            )\n",
    "\n",
    "        if not self.testing:\n",
    "            os.makedirs(self.notebook_persit_dp, exist_ok=True)\n",
    "        return self\n",
    "    \n",
    "args = Args().init()\n",
    "print(args.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "383bb869",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(args.train_data_fp)\n",
    "train_df[args.rating_col] = train_df[args.rating_col].apply(lambda x: 1 if x > 0 else 0)    \n",
    "train_df = train_df[train_df['item_sequence'].apply(lambda seq: not all(item == -1 for item in seq))]        \n",
    "\n",
    "val_df = pd.read_parquet(args.val_data_fp)\n",
    "val_df[args.rating_col] = val_df[args.rating_col].apply(lambda x: 1 if x > 0 else 0)\n",
    "val_df = val_df[val_df['item_sequence'].apply(lambda seq: not all(item == -1 for item in seq))]\n",
    "\n",
    "assert set(val_df[args.user_col].unique()).issubset(set(train_df[args.user_col].unique())), \"Validation users must be present in training users.\"\n",
    "\n",
    "assert set(val_df[args.item_col].unique()).issubset(set(train_df[args.item_col].unique())), \"Validation items must be present in training items.\"\n",
    "assert train_df[args.timestamp_col].max() < val_df[args.timestamp_col].min(), \"Validation data must be after training data. Otherwise, its a data contamination problem.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca341b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B004FV4ROA</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-27 00:30:31.146</td>\n",
       "      <td>11295</td>\n",
       "      <td>528</td>\n",
       "      <td>[1898, 3479, 3908, 1570, 91, 2723, 2962, 106, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B07KFQFDNB</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-27 00:30:31.146</td>\n",
       "      <td>11295</td>\n",
       "      <td>3503</td>\n",
       "      <td>[3479, 3908, 1570, 91, 2723, 2962, 106, 3557, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AEHS7YR7BGGWMZS24H5UR5IP46HQ</td>\n",
       "      <td>B08F1P3BCC</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-27 01:44:52.242</td>\n",
       "      <td>1784</td>\n",
       "      <td>3925</td>\n",
       "      <td>[4319, 3382, 4330, 1173, 1330, 423, 2868, 3167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEHS7YR7BGGWMZS24H5UR5IP46HQ</td>\n",
       "      <td>B00HXT8EKE</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-27 01:44:52.242</td>\n",
       "      <td>1784</td>\n",
       "      <td>1507</td>\n",
       "      <td>[3382, 4330, 1173, 1330, 423, 2868, 3167, 1071...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGAVHCK42EGMVS7DGPRX6HBCUCNQ</td>\n",
       "      <td>B09Q3NR84W</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-27 02:25:48.357</td>\n",
       "      <td>9042</td>\n",
       "      <td>4273</td>\n",
       "      <td>[1311, 1416, 455, 3743, 1823, 2694, 3612, 3462...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6953</th>\n",
       "      <td>AEEQZRQBOFHFBFPYBX2BZ5WOI33A</td>\n",
       "      <td>B01A08E70K</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-19 16:56:53.030</td>\n",
       "      <td>1396</td>\n",
       "      <td>2441</td>\n",
       "      <td>[3451, 3827, 1839, 1347, 2504, 2694, 4546, 427...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6954</th>\n",
       "      <td>AHLN6GKTKZE22AON34YAQXTGK63A</td>\n",
       "      <td>B0C682GZ5X</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-19 17:28:55.519</td>\n",
       "      <td>14550</td>\n",
       "      <td>4772</td>\n",
       "      <td>[2950, 1812, 4735, 4165, 4575, 2440, 607, 4807...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6955</th>\n",
       "      <td>AHLN6GKTKZE22AON34YAQXTGK63A</td>\n",
       "      <td>B09SWWCN6Q</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-19 17:28:55.519</td>\n",
       "      <td>14550</td>\n",
       "      <td>4303</td>\n",
       "      <td>[1812, 4735, 4165, 4575, 2440, 607, 4807, 374,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6956</th>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B091K4WYD1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-19 22:08:53.253</td>\n",
       "      <td>2446</td>\n",
       "      <td>4086</td>\n",
       "      <td>[644, 3602, 4569, 1865, 3030, 3653, 3803, 3998...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6957</th>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B005CTKYB4</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-19 22:08:53.253</td>\n",
       "      <td>2446</td>\n",
       "      <td>654</td>\n",
       "      <td>[3602, 4569, 1865, 3030, 3653, 3803, 3998, 285...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6958 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           user_id parent_asin  rating  \\\n",
       "0     AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B004FV4ROA       1   \n",
       "1     AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B07KFQFDNB       0   \n",
       "2     AEHS7YR7BGGWMZS24H5UR5IP46HQ  B08F1P3BCC       1   \n",
       "3     AEHS7YR7BGGWMZS24H5UR5IP46HQ  B00HXT8EKE       0   \n",
       "4     AGAVHCK42EGMVS7DGPRX6HBCUCNQ  B09Q3NR84W       1   \n",
       "...                            ...         ...     ...   \n",
       "6953  AEEQZRQBOFHFBFPYBX2BZ5WOI33A  B01A08E70K       0   \n",
       "6954  AHLN6GKTKZE22AON34YAQXTGK63A  B0C682GZ5X       1   \n",
       "6955  AHLN6GKTKZE22AON34YAQXTGK63A  B09SWWCN6Q       0   \n",
       "6956  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B091K4WYD1       1   \n",
       "6957  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B005CTKYB4       0   \n",
       "\n",
       "                   timestamp  user_indice  item_indice  \\\n",
       "0    2020-12-27 00:30:31.146        11295          528   \n",
       "1    2020-12-27 00:30:31.146        11295         3503   \n",
       "2    2020-12-27 01:44:52.242         1784         3925   \n",
       "3    2020-12-27 01:44:52.242         1784         1507   \n",
       "4    2020-12-27 02:25:48.357         9042         4273   \n",
       "...                      ...          ...          ...   \n",
       "6953 2022-02-19 16:56:53.030         1396         2441   \n",
       "6954 2022-02-19 17:28:55.519        14550         4772   \n",
       "6955 2022-02-19 17:28:55.519        14550         4303   \n",
       "6956 2022-02-19 22:08:53.253         2446         4086   \n",
       "6957 2022-02-19 22:08:53.253         2446          654   \n",
       "\n",
       "                                          item_sequence  \n",
       "0     [1898, 3479, 3908, 1570, 91, 2723, 2962, 106, ...  \n",
       "1     [3479, 3908, 1570, 91, 2723, 2962, 106, 3557, ...  \n",
       "2     [4319, 3382, 4330, 1173, 1330, 423, 2868, 3167...  \n",
       "3     [3382, 4330, 1173, 1330, 423, 2868, 3167, 1071...  \n",
       "4     [1311, 1416, 455, 3743, 1823, 2694, 3612, 3462...  \n",
       "...                                                 ...  \n",
       "6953  [3451, 3827, 1839, 1347, 2504, 2694, 4546, 427...  \n",
       "6954  [2950, 1812, 4735, 4165, 4575, 2440, 607, 4807...  \n",
       "6955  [1812, 4735, 4165, 4575, 2440, 607, 4807, 374,...  \n",
       "6956  [644, 3602, 4569, 1865, 3030, 3653, 3803, 3998...  \n",
       "6957  [3602, 4569, 1865, 3030, 3653, 3803, 3998, 285...  \n",
       "\n",
       "[6958 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21bc2bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFZ4EK2LJ655XQKTEUELCARO6RYA</td>\n",
       "      <td>B095JX15XF</td>\n",
       "      <td>0</td>\n",
       "      <td>2003-01-23 03:28:15.000</td>\n",
       "      <td>8071</td>\n",
       "      <td>4132</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFY2C4YOUP2SSMM43HD2L3FIEFZA</td>\n",
       "      <td>B00OQVZDJM</td>\n",
       "      <td>0</td>\n",
       "      <td>2003-11-25 18:12:09.000</td>\n",
       "      <td>7935</td>\n",
       "      <td>1859</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AHF3TGIOSTD2UCHF3MO4MIHFJ5NQ</td>\n",
       "      <td>B07KQWX947</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-06-18 02:02:57.000</td>\n",
       "      <td>13705</td>\n",
       "      <td>3514</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AH5Z47PJ5RTSUL2RLCO2QITGIT4Q</td>\n",
       "      <td>B07W4GJGCM</td>\n",
       "      <td>0</td>\n",
       "      <td>2004-09-13 20:18:44.000</td>\n",
       "      <td>12730</td>\n",
       "      <td>3734</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AEX3L4NKDESOCGWOFNF63GRFGXCA</td>\n",
       "      <td>B0067HY7HW</td>\n",
       "      <td>0</td>\n",
       "      <td>2004-10-22 14:26:12.000</td>\n",
       "      <td>3735</td>\n",
       "      <td>746</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254779</th>\n",
       "      <td>AES2U6KIAORYLTBPENQWMDVALTDQ</td>\n",
       "      <td>B07ZZVX1F2</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-26 21:37:58.968</td>\n",
       "      <td>3109</td>\n",
       "      <td>3800</td>\n",
       "      <td>[-1.0, 2237.0, 1691.0, 2694.0, 1633.0, 934.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254780</th>\n",
       "      <td>AGU6SDEIMLBQZII2FVFJ6YIUZRKQ</td>\n",
       "      <td>B0BSF5LM3J</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-26 22:29:54.459</td>\n",
       "      <td>11489</td>\n",
       "      <td>4622</td>\n",
       "      <td>[107.0, 3997.0, 2858.0, 1680.0, 2919.0, 4109.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254781</th>\n",
       "      <td>AGU6SDEIMLBQZII2FVFJ6YIUZRKQ</td>\n",
       "      <td>B0BZJ9BYZ3</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-26 22:29:54.459</td>\n",
       "      <td>11489</td>\n",
       "      <td>4696</td>\n",
       "      <td>[3997.0, 2858.0, 1680.0, 2919.0, 4109.0, 3695....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254782</th>\n",
       "      <td>AG2HB7HEYSIAGYBEFFL666KVYTHA</td>\n",
       "      <td>B0895KGSY1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-26 23:06:03.454</td>\n",
       "      <td>8251</td>\n",
       "      <td>3896</td>\n",
       "      <td>[-1.0, -1.0, 2531.0, 382.0, 2756.0, 3373.0, 34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254783</th>\n",
       "      <td>AG2HB7HEYSIAGYBEFFL666KVYTHA</td>\n",
       "      <td>B0029U2YSA</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-26 23:06:03.454</td>\n",
       "      <td>8251</td>\n",
       "      <td>289</td>\n",
       "      <td>[-1.0, 2531.0, 382.0, 2756.0, 3373.0, 3486.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238377 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id parent_asin  rating  \\\n",
       "1       AFZ4EK2LJ655XQKTEUELCARO6RYA  B095JX15XF       0   \n",
       "3       AFY2C4YOUP2SSMM43HD2L3FIEFZA  B00OQVZDJM       0   \n",
       "5       AHF3TGIOSTD2UCHF3MO4MIHFJ5NQ  B07KQWX947       1   \n",
       "7       AH5Z47PJ5RTSUL2RLCO2QITGIT4Q  B07W4GJGCM       0   \n",
       "9       AEX3L4NKDESOCGWOFNF63GRFGXCA  B0067HY7HW       0   \n",
       "...                              ...         ...     ...   \n",
       "254779  AES2U6KIAORYLTBPENQWMDVALTDQ  B07ZZVX1F2       1   \n",
       "254780  AGU6SDEIMLBQZII2FVFJ6YIUZRKQ  B0BSF5LM3J       1   \n",
       "254781  AGU6SDEIMLBQZII2FVFJ6YIUZRKQ  B0BZJ9BYZ3       0   \n",
       "254782  AG2HB7HEYSIAGYBEFFL666KVYTHA  B0895KGSY1       0   \n",
       "254783  AG2HB7HEYSIAGYBEFFL666KVYTHA  B0029U2YSA       1   \n",
       "\n",
       "                     timestamp  user_indice  item_indice  \\\n",
       "1      2003-01-23 03:28:15.000         8071         4132   \n",
       "3      2003-11-25 18:12:09.000         7935         1859   \n",
       "5      2004-06-18 02:02:57.000        13705         3514   \n",
       "7      2004-09-13 20:18:44.000        12730         3734   \n",
       "9      2004-10-22 14:26:12.000         3735          746   \n",
       "...                        ...          ...          ...   \n",
       "254779 2020-12-26 21:37:58.968         3109         3800   \n",
       "254780 2020-12-26 22:29:54.459        11489         4622   \n",
       "254781 2020-12-26 22:29:54.459        11489         4696   \n",
       "254782 2020-12-26 23:06:03.454         8251         3896   \n",
       "254783 2020-12-26 23:06:03.454         8251          289   \n",
       "\n",
       "                                            item_sequence  \n",
       "1       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "3       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "5       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "7       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "9       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "...                                                   ...  \n",
       "254779  [-1.0, 2237.0, 1691.0, 2694.0, 1633.0, 934.0, ...  \n",
       "254780  [107.0, 3997.0, 2858.0, 1680.0, 2919.0, 4109.0...  \n",
       "254781  [3997.0, 2858.0, 1680.0, 2919.0, 4109.0, 3695....  \n",
       "254782  [-1.0, -1.0, 2531.0, 382.0, 2756.0, 3373.0, 34...  \n",
       "254783  [-1.0, 2531.0, 382.0, 2756.0, 3373.0, 3486.0, ...  \n",
       "\n",
       "[238377 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ad41a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(n_user, n_items, dropout, hidden_units, num_blocks, num_heads):\n",
    "    \"\"\"\n",
    "    Initialize the model with the given parameters.\n",
    "    \"\"\"\n",
    "    model = SASRec(\n",
    "        user_num = n_user,\n",
    "        item_num = n_items,\n",
    "        dropout_rate = dropout,\n",
    "        hidden_units = hidden_units,\n",
    "        num_blocks = num_blocks,\n",
    "        num_heads = num_heads,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17f32acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-06 20:56:27.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mNumber of users: 16407, Number of items: 4817\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các row NaN ngay sau init: []\n"
     ]
    }
   ],
   "source": [
    "item_indices = train_df[args.item_col].unique()\n",
    "user_indices = train_df[args.user_col].unique()\n",
    "n_items = len(item_indices)\n",
    "n_users = len(user_indices)\n",
    "\n",
    "logger.info(f\"Number of users: {n_users}, Number of items: {n_items}\")\n",
    "model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "emb_weights = model.item_emb.weight.data\n",
    "nan_rows = torch.isnan(emb_weights).any(dim=1).nonzero().squeeze().tolist()\n",
    "print(\"Các row NaN ngay sau init:\", nan_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3721313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2342]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = torch.tensor([7411])\n",
    "seq = torch.tensor([[1782, 1975, 3089, 3719, 4721, 3443, 4178, 2953, 684, 3401]])\n",
    "target_item = torch.tensor([[474]])\n",
    "predictions = model(user, seq, target_item)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "beb513ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_num = 4817\n",
      "Padding token index: 4817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0194, -0.0074, -0.0403,  0.0226, -0.0096, -0.0282, -0.0128,  0.0249,\n",
       "         -0.0270,  0.0130,  0.0081, -0.0017, -0.0308, -0.0097, -0.0134,  0.0060,\n",
       "         -0.0003, -0.0315,  0.0237, -0.0179,  0.0005, -0.0153,  0.0368,  0.0201,\n",
       "          0.0212,  0.0370,  0.0039,  0.0195, -0.0347,  0.0309,  0.0179,  0.0231,\n",
       "          0.0080, -0.0228,  0.0085,  0.0098, -0.0597,  0.0156, -0.0082,  0.0015,\n",
       "         -0.0155, -0.0115, -0.0362,  0.0578,  0.0080,  0.0327, -0.0235,  0.0525,\n",
       "         -0.0270, -0.0104,  0.0117, -0.0296,  0.0024,  0.0316,  0.0110, -0.0108,\n",
       "         -0.0013, -0.0216, -0.0030, -0.0054, -0.0023, -0.0253,  0.0177,  0.0141,\n",
       "          0.0124,  0.0424,  0.0058,  0.0063,  0.0052,  0.0073,  0.0049, -0.0182,\n",
       "          0.0153,  0.0205,  0.0216, -0.0075,  0.0211,  0.0285, -0.0253, -0.0058,\n",
       "         -0.0149, -0.0093,  0.0175, -0.0245, -0.0362,  0.0037, -0.0011,  0.0075,\n",
       "         -0.0021,  0.0224,  0.0294,  0.0130, -0.0177,  0.0016, -0.0271,  0.0105,\n",
       "          0.0340,  0.0063,  0.0050,  0.0227, -0.0080, -0.0229,  0.0009, -0.0012,\n",
       "          0.0069, -0.0149, -0.0315, -0.0343,  0.0051,  0.0095, -0.0193, -0.0080,\n",
       "         -0.0286,  0.0028,  0.0195, -0.0018,  0.0284, -0.0069,  0.0447,  0.0106,\n",
       "          0.0091, -0.0022,  0.0046, -0.0314, -0.0090,  0.0029,  0.0194, -0.0005]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"item_num = {model.item_num}\")\n",
    "print(f\"Padding token index: {model.item_emb.padding_idx}\")\n",
    "model.item_emb(torch.tensor([3089]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0e4c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 4\n",
    "# for i in range(0,10000):\n",
    "#     user = torch.tensor([[0]])\n",
    "#     seq = torch.randint(0, model.item_num, (batch_size, args.max_len))\n",
    "#     seq[:, :np.random.randint(1,10)] = model.item_num \n",
    "#     target_item = torch.tensor([[4000]])\n",
    "#     # print(f\"seq: {seq}\")\n",
    "#     predictions = model(user, seq, target_item)\n",
    "#     # if prediction is returned by nan values, then print the seq\n",
    "#     if torch.isnan(predictions).any():\n",
    "#         print(\"nan prediction\")\n",
    "#         print(seq)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85ec519d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SASRec(\n",
       "  (item_emb): Embedding(4818, 128, padding_idx=4817)\n",
       "  (pos_emb): Embedding(10, 128)\n",
       "  (emb_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (attention_layernorms): ModuleList(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (attention_layers): ModuleList(\n",
       "    (0): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (forward_layernorms): ModuleList(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (forward_layers): ModuleList(\n",
       "    (0): PointWiseFeedForward(\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "      (dropout1): Dropout(p=0.5, inplace=False)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "      (dropout2): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce5dddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_train_df = train_df.sample(frac=0.2, random_state=42)\n",
    "\n",
    "rating_dataset = SASRecDataset(\n",
    "    train_df, \"user_indice\", \"item_sequence\", \"item_indice\", \"rating\",args.max_len, n_items, args.timestamp_col, \n",
    ")\n",
    "val_rating_dataset = SASRecDataset(\n",
    "    val_df, \"user_indice\", \"item_sequence\", \"item_indice\", \"rating\", args.max_len, n_items, args.timestamp_col, \n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    rating_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True, num_workers=args.num_workers, persistent_workers=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_rating_dataset, batch_size=args.batch_size, shuffle=False, drop_last=False, num_workers=args.num_workers, persistent_workers=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe049bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in train_loader:\n",
    "#     print(i[\"user\"])\n",
    "#     print(i[\"sequence\"])\n",
    "#     print(i[\"item\"])\n",
    "#     print(i[\"rating\"])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "939d52ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AE227WAM4NWQPJI33OPN7ZARNNZQ'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idm_path = os.path.abspath(\"../data_for_ai/interim/idm_16407u.json\")\n",
    "idm = IDMapper().load(idm_path)\n",
    "idm.get_user_id(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bec2235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "\n",
    "# # 1. Hyper-params & setup\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# num_epochs = 10\n",
    "# lr = 1e-4          # giảm thêm nếu vẫn NaN\n",
    "# weight_decay = 1e-4\n",
    "# grad_clip_norm = 1.0\n",
    "\n",
    "# # 2. Dataset & DataLoader\n",
    "# # exist above \n",
    "\n",
    "# # 3. Model, Loss, Optimizer, Scheduler\n",
    "# model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "# model = model.to(device)\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1)\n",
    "\n",
    "# # 4. Anomaly detection (chỉ bật khi debug)\n",
    "# # torch.autograd.detect_anomaly(check_nan=True)\n",
    "\n",
    "# # for epoch in range(1, num_epochs + 1):\n",
    "#     ##### Training #####\n",
    "# epoch = 0\n",
    "# model.train()\n",
    "# total_train_loss = 0.0\n",
    "# for batch_idx, batch in enumerate(train_loader, 1):\n",
    "#     print(f\"Epoch {epoch} ─ batch {batch_idx}/{len(train_loader)}\")\n",
    "#     # if batch_idx == 10:\n",
    "#     #     break\n",
    "#     users    = batch[\"user\"].to(device)\n",
    "#     items    = batch[\"item\"].to(device)\n",
    "#     seqs     = batch[\"sequence\"].long().to(device)\n",
    "#     labels   = batch[\"rating\"].float().to(device)\n",
    "\n",
    "#     # Zero gradients\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     # Forward\n",
    "#     logits = model(users, seqs, items).view_as(labels)\n",
    "\n",
    "#     # Loss\n",
    "#     loss = criterion(logits, labels)\n",
    "#     total_train_loss += loss.item()\n",
    "#     # print(f\"Epoch {epoch} ─ batch {batch_idx}/{len(train_loader)} ─ loss: {loss.item():.4f}\")\n",
    "#     # Backward + gradient clipping\n",
    "#     try:\n",
    "#         loss.backward()\n",
    "#     except RuntimeError as e:\n",
    "#         print(f\"🚨 Backward failed: {e}\")\n",
    "#         # inspect tất cả gradients\n",
    "#         for name, p in model.named_parameters():\n",
    "#             if p.grad is not None:\n",
    "#                 has_nan = torch.isnan(p.grad).any().item()\n",
    "#                 print(f\"  grad for {name}: contains_nan={has_nan}, max_abs={p.grad.abs().max().item():.4e}\")\n",
    "#         raise  # vẫn ném exception để dừng\n",
    "#     torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip_norm)\n",
    "\n",
    "#     # (optional) log max grad for each layer\n",
    "#     for name, p in model.named_parameters():\n",
    "#         if p.grad is not None:\n",
    "#             if torch.isnan(p.grad).any():\n",
    "#                 print(f\"[NaN grad] {name}\")\n",
    "#             # print(f\"{name} grad_norm={p.grad.norm():.4f}\")\n",
    "\n",
    "#     # Step optimizer\n",
    "#     optimizer.step()\n",
    "\n",
    "# avg_train_loss = total_train_loss / len(train_loader)\n",
    "# print(f\"Epoch {epoch} ─ train_loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "# ##### Validation #####\n",
    "# # model.eval()\n",
    "# # total_val_loss = 0.0\n",
    "# # with torch.no_grad():\n",
    "# #     for batch in val_loader:\n",
    "# #         users  = batch[\"user\"].to(device)\n",
    "# #         items  = batch[\"item\"].to(device)\n",
    "# #         seqs   = batch[\"sequence\"].long().to(device)\n",
    "# #         labels = batch[\"rating\"].float().to(device)\n",
    "\n",
    "# #         logits = model(users, seqs, items).view_as(labels)\n",
    "# #         loss = criterion(logits, labels)\n",
    "# #         total_val_loss += loss.item()\n",
    "\n",
    "# # avg_val_loss = total_val_loss / len(val_loader)\n",
    "# # print(f\"Epoch {epoch} ─ val_loss:   {avg_val_loss:.4f}\")\n",
    "\n",
    "# # Scheduler step\n",
    "# # scheduler.step(avg_val_loss)\n",
    "\n",
    "# print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff6faaa",
   "metadata": {},
   "source": [
    "## check nan cases in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c9491de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "# # Extract the attention layer from the model\n",
    "# attention_layer = model.attention_layers[0]\n",
    "\n",
    "# for batch_idx, batch in enumerate(train_loader):\n",
    "#     user_ids, seq, target_item, labels = batch\n",
    "\n",
    "#     # Get the embeddings for the sequence\n",
    "#     sequence_embeddings = model.item_emb(batch[\"sequence\"])\n",
    "    \n",
    "\n",
    "#     # Pass the embeddings through the attention layer\n",
    "#     attention_output, _ = attention_layer(sequence_embeddings, sequence_embeddings, sequence_embeddings)\n",
    "#     # if any NaN values are found in the attention output, print the batch and the attention output\n",
    "#     if torch.isnan(attention_output).any():\n",
    "#         print(f\"Batch {batch_idx} - Attention output contains NaN values.\")\n",
    "#         print(batch[\"sequence\"])\n",
    "#         print(\"Sample seq:\", batch[\"sequence\"][0])\n",
    "#         print(\"Item emb weight stats:\", model.item_emb.weight.min(), model.item_emb.weight.max())\n",
    "#         print(attention_output)\n",
    "#         break\n",
    "#     # Example: Perform some operation with the attention output\n",
    "#     predictions = model.final_layer(attention_output[:, -1, :])  # Use the last position for predictions\n",
    "\n",
    "#     # Check for NaN values in predictions\n",
    "#     if torch.isnan(predictions).any():\n",
    "#         print(f\"Batch {batch_idx} - Predictions contain NaN values.\")\n",
    "#         print(batch[\"sequence\"])\n",
    "#         print(\"Sample seq:\", batch[\"sequence\"][0])\n",
    "#         print(\"Item emb weight stats:\", model.item_emb.weight.min(), model.item_emb.weight.max())\n",
    "#         print(predictions)\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6be76f",
   "metadata": {},
   "source": [
    "## overfit 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0675501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type   | Params | Mode \n",
      "-----------------------------------------\n",
      "0 | model | SASRec | 717 K  | train\n",
      "-----------------------------------------\n",
      "717 K     Trainable params\n",
      "0         Non-trainable params\n",
      "717 K     Total params\n",
      "2.871     Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d34c9d16a8c4aa8a95f68020ab5557f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:252: UserWarning:\n",
      "\n",
      "You requested to overfit but enabled val dataloader shuffling. We are turning off the val dataloader shuffling for you.\n",
      "\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:252: UserWarning:\n",
      "\n",
      "You requested to overfit but enabled train dataloader shuffling. We are turning off the train dataloader shuffling for you.\n",
      "\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:310: PossibleUserWarning:\n",
      "\n",
      "The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36be88f21934360aa8715ac12a22cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e46a9e65dd243f2919ea7f916cfde1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dba268c1363411aaa6d71fa421d0bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fad6daaf517487db7fa09554b05c203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2320d0a45cf642fd9bc3b8acff89f1d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e7ec8884054d7e9edb9a4edf3358c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b5c0759eed49fd8fc3a1a368837f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e4e2c5eb3247b8bcaf7d0ad5bb5773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83bba5a84c994c56b7a50ea2b362023b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1489b59860449d97184b9e6bf96da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f88de1f34324e2b804ff49219fd975a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "\u001b[32m2025-05-06 20:58:39.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.gSASRec.trainer\u001b[0m:\u001b[36mon_fit_end\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mLogging classification metrics...\u001b[0m\n",
      "\u001b[32m2025-05-06 21:00:29.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.gSASRec.trainer\u001b[0m:\u001b[36mon_fit_end\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mLogging ranking metrics...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations_df:    user_indice recommendation     score\n",
      "0         8071            334  0.999899\n",
      "1         8071            120  0.999874\n",
      "2         8071           1411  0.999848\n",
      "3         8071            477  0.999821\n",
      "4         8071           3775  0.999818\n",
      "Recommendations_df:      user_indice item_indice     score  rec_ranking  \\\n",
      "0           8071         334  0.999899          1.0   \n",
      "1           8071         120  0.999874          2.0   \n",
      "2           8071        1411  0.999848          3.0   \n",
      "3           8071         477  0.999821          4.0   \n",
      "4           8071        3775  0.999818          5.0   \n",
      "..           ...         ...       ...          ...   \n",
      "995         8061         350  0.998992         96.0   \n",
      "996         8061        2001  0.998985         97.0   \n",
      "997         8061         272  0.998956         98.0   \n",
      "998         8061          68  0.998954         99.0   \n",
      "999         8061         284  0.998949        100.0   \n",
      "\n",
      "                          user_id parent_asin  \n",
      "0    AFZ4EK2LJ655XQKTEUELCARO6RYA  B002PAR1FK  \n",
      "1    AFZ4EK2LJ655XQKTEUELCARO6RYA  B000LIFB7S  \n",
      "2    AFZ4EK2LJ655XQKTEUELCARO6RYA  B00FHASA3W  \n",
      "3    AFZ4EK2LJ655XQKTEUELCARO6RYA  B00426C57O  \n",
      "4    AFZ4EK2LJ655XQKTEUELCARO6RYA  B07YD48WNN  \n",
      "..                            ...         ...  \n",
      "995  AFZ2LKCLXIYCNTYC43ZDPHB52KSQ  B002VJL0OS  \n",
      "996  AFZ2LKCLXIYCNTYC43ZDPHB52KSQ  B00U2EJH3K  \n",
      "997  AFZ2LKCLXIYCNTYC43ZDPHB52KSQ  B001V5J82E  \n",
      "998  AFZ2LKCLXIYCNTYC43ZDPHB52KSQ  B0007M6GI6  \n",
      "999  AFZ2LKCLXIYCNTYC43ZDPHB52KSQ  B0027VSSJU  \n",
      "\n",
      "[1000 rows x 6 columns]\n",
      "Label_df:          user_indice  item_indice  rating  rating_rank\n",
      "254783         8251          289       1          1.0\n",
      "213846         3200         1906       1          1.0\n",
      "213853         2916         3953       1          1.0\n",
      "213854        12493         4313       1          1.0\n",
      "213884        11264         3447       1          1.0\n",
      "Eval_df:     user_indice item_indice score  rec_ranking user_id parent_asin  rating  \\\n",
      "0            0         154   NaN          101     NaN         NaN       1   \n",
      "1            0         446   NaN          101     NaN         NaN       0   \n",
      "2            0        1741   NaN          101     NaN         NaN       1   \n",
      "3            0        1885   NaN          101     NaN         NaN       0   \n",
      "4            0        2811   NaN          101     NaN         NaN       0   \n",
      "\n",
      "   rating_rank  \n",
      "0          2.0  \n",
      "1          6.0  \n",
      "2          4.0  \n",
      "3          8.0  \n",
      "4          9.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\evidently\\metrics\\recsys\\f_beta_top_k.py:64: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "\u001b[32m2025-05-06 21:01:17.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.gSASRec.trainer\u001b[0m:\u001b[36mon_fit_end\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mEvidently metrics are available at: c:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\data\\first-attempt\\050-sasrec\u001b[0m\n",
      "\u001b[32m2025-05-06 21:01:17.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mLogs available at c:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\data\\first-attempt\\050-sasrec\\logs\\overfit\\lightning_logs\\version_9\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': [{'metric': 'NDCGKMetric', 'result': {'k': 10, 'current': 1     0.000000\n",
      "2     0.000000\n",
      "3     0.000000\n",
      "4     0.000000\n",
      "5     0.000000\n",
      "6     0.000000\n",
      "7     0.000000\n",
      "8     0.000007\n",
      "9     0.000014\n",
      "10    0.000014\n",
      "dtype: float64, 'current_value': 1.3683747005771374e-05, 'reference': None, 'reference_value': None}}, {'metric': 'RecallTopKMetric', 'result': {'k': 100, 'current': 0     0.000000\n",
      "1     0.000000\n",
      "2     0.000000\n",
      "3     0.000000\n",
      "4     0.000000\n",
      "        ...   \n",
      "95    0.000061\n",
      "96    0.000061\n",
      "97    0.000061\n",
      "98    0.000061\n",
      "99    0.000061\n",
      "Length: 100, dtype: float64, 'current_value': 6.1029641057202176e-05, 'reference': None, 'reference_value': None}}, {'metric': 'PrecisionTopKMetric', 'result': {'k': 100, 'current': 0     0.000000\n",
      "1     0.000000\n",
      "2     0.000000\n",
      "3     0.000000\n",
      "4     0.000000\n",
      "        ...   \n",
      "95    0.000004\n",
      "96    0.000004\n",
      "97    0.000004\n",
      "98    0.000004\n",
      "99    0.000004\n",
      "Length: 100, dtype: float64, 'current_value': 3.6569756811117203e-06, 'reference': None, 'reference_value': None}}, {'metric': 'FBetaTopKMetric', 'result': {'k': 10, 'current': 0         NaN\n",
      "1         NaN\n",
      "2         NaN\n",
      "3         NaN\n",
      "4         NaN\n",
      "5         NaN\n",
      "6         NaN\n",
      "7    0.000009\n",
      "8    0.000018\n",
      "9    0.000017\n",
      "dtype: float64, 'current_value': 1.687834929743871e-05, 'reference': None, 'reference_value': None}}, {'metric': 'PersonalizationMetric', 'result': {'k': 10, 'current_value': 0.03555555555555559, 'current_table': {'2694': 1672, '3089': 1594, '2253': 1074, '2237': 1045, '3678': 1003, '3443': 946, '4516': 818, '954': 661, '3839': 640, '3585': 614}, 'reference_value': None, 'reference_table': None}}]}\n"
     ]
    }
   ],
   "source": [
    "# early_stopping = EarlyStopping(\n",
    "#     monitor=\"val_loss\", patience=5, mode=\"min\", verbose=False\n",
    "# )\n",
    "# # create log_dir if it does not exist\n",
    "# if not os.path.exists(args.notebook_persit_dp):\n",
    "#     os.makedirs(args.notebook_persit_dp, exist_ok=True)\n",
    "\n",
    "# model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "# lit_model = SASRecLitModule(\n",
    "#     model,\n",
    "#     log_dir=args.notebook_persit_dp,\n",
    "#     accelerator=args.device,\n",
    "#     lr=args.lr,\n",
    "#     l2_emb=args.l2_emb,\n",
    "#     idm= idm\n",
    "# )\n",
    "\n",
    "# log_dir = f\"{args.notebook_persit_dp}/logs/overfit\"\n",
    "# # create log_dir if it does not exist\n",
    "# if not os.path.exists(log_dir):\n",
    "#     os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# # train model\n",
    "# trainer = L.Trainer(\n",
    "#     default_root_dir=log_dir,\n",
    "#     accelerator=args.device if args.device else \"auto\",\n",
    "#     max_epochs=10,\n",
    "#     # max_epochs=args.num_epochs,\n",
    "#     overfit_batches=10,\n",
    "#     callbacks=[early_stopping],\n",
    "# )\n",
    "# trainer.fit(\n",
    "#     model=lit_model,\n",
    "#     train_dataloaders=train_loader,\n",
    "#     val_dataloaders=train_loader,\n",
    "# )\n",
    "# logger.info(f\"Logs available at {trainer.log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ddfce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=args.early_stopping_patience, mode=\"min\", verbose=False, min_delta=0.0025\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{args.notebook_persit_dp}/checkpoints\",\n",
    "    filename=\"best_checkpoint\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "# model = model.double()\n",
    "lit_model = SASRecLitModule(\n",
    "    model,\n",
    "    log_dir=args.notebook_persit_dp,\n",
    "    accelerator=args.device,\n",
    "    lr=args.lr,\n",
    "    l2_emb=args.l2_emb,\n",
    "    idm= idm\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persit_dp}/logs/run\"\n",
    "# create log_dir if it does not exist\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    # max_epochs=5,\n",
    "    # detect_anomaly=True,\n",
    "    max_epochs=args.num_epochs,\n",
    "    # gradient_clip_val=1.0,     \n",
    "    # gradient_clip_algorithm=\"norm\",\n",
    "    callbacks=[early_stopping, checkpoint_callback],\n",
    "    logger=args._mlf_logger if args.log_to_mlflow else None,\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")\n",
    "\n",
    "\n",
    "# Change the library as a workaround for the issue in the latest Lightning release\n",
    "#https://github.com/Lightning-AI/pytorch-lightning/pull/20669/commits/429f732a0528c558e701da7ec01e51c1e2e4f32e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef8d60a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TensorBoardLogger' object has no attribute 'run_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m all_params = [args]\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args.log_to_mlflow:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     run_id = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_id\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m mlflow.start_run(run_id=run_id):\n\u001b[32m      7\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m all_params:\n",
      "\u001b[31mAttributeError\u001b[39m: 'TensorBoardLogger' object has no attribute 'run_id'"
     ]
    }
   ],
   "source": [
    "all_params = [args]\n",
    "\n",
    "if args.log_to_mlflow:\n",
    "    run_id = trainer.logger.run_id\n",
    "\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        for params in all_params:\n",
    "            params_dict = params.model_dump()\n",
    "            params_ = dict()\n",
    "            for k, v in params_dict.items():\n",
    "                if k == \"top_K\":\n",
    "                    k = \"top_big_K\"\n",
    "                if k == \"top_k\":\n",
    "                    k = \"top_small_k\"\n",
    "                params_[f\"{params.__repr_name__()}.{k}\"] = v\n",
    "            mlflow.log_params(params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1efc4e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-06 22:10:21.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mSetting up Mlflow experiment: first-attempt, run_name: 050-sasrec\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])\n",
      "odict_keys(['model.item_emb.weight', 'model.pos_emb.weight', 'model.attention_layernorms.0.weight', 'model.attention_layernorms.0.bias', 'model.attention_layers.0.in_proj_weight', 'model.attention_layers.0.in_proj_bias', 'model.attention_layers.0.out_proj.weight', 'model.attention_layers.0.out_proj.bias', 'model.forward_layernorms.0.weight', 'model.forward_layernorms.0.bias', 'model.forward_layers.0.conv1.weight', 'model.forward_layers.0.conv1.bias', 'model.forward_layers.0.conv2.weight', 'model.forward_layers.0.conv2.bias', 'model.final_layer.weight', 'model.final_layer.bias'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SASRec(\n",
       "  (item_emb): Embedding(4818, 128, padding_idx=4817)\n",
       "  (pos_emb): Embedding(10, 128)\n",
       "  (emb_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (attention_layernorms): ModuleList(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (attention_layers): ModuleList(\n",
       "    (0): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (forward_layernorms): ModuleList(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (forward_layers): ModuleList(\n",
       "    (0): PointWiseFeedForward(\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "      (dropout1): Dropout(p=0.5, inplace=False)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "      (dropout2): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = Args().init()  # Load lại các tham số từ class Args\n",
    "model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "\n",
    "# Đường dẫn đến file checkpoint\n",
    "checkpoint_path = f\"{args.notebook_persit_dp}/checkpoints/best_checkpoint.ckpt\"\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device(args.device))\n",
    "print(checkpoint.keys())\n",
    "print(checkpoint['state_dict'].keys())\n",
    "\n",
    "# Tạo một state_dict mới, loại bỏ tiền tố \"model.\"\n",
    "model_state_dict = {k.replace(\"model.\", \"\"): v for k, v in checkpoint['state_dict'].items() if k.startswith(\"model.\")}\n",
    "\n",
    "# Load state_dict đã điều chỉnh vào mô hình SASRec\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.eval()  # Chuyển sang chế độ đánh giá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5ee4d824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ví dụ: chọn một batch từ val_loader\n",
    "# create a random index to get a sample from a batch\n",
    "sample_index = np.random.randint(0, 512)\n",
    "sample_batch = next(iter(train_loader))\n",
    "user = sample_batch[\"user\"].to(args.device)\n",
    "seq = sample_batch[\"sequence\"].to(args.device)\n",
    "target_item = sample_batch[\"item\"].to(args.device)\n",
    "rating = sample_batch[\"rating\"].to(args.device)\n",
    "# print shape\n",
    "# print(f\"User: {user.shape}, Seq: {seq.shape}, Target item: {target_item.shape} \")\n",
    "# print(f\"User: {user}, Seq: {seq}, Target item: {target_item}, Rating: {rating}\")\n",
    "# user_indice = torch.tensor([11295])  # ID người dùng đã được ánh xạ\n",
    "# sequence = torch.tensor([[4817, 1898, 3479, 3908, 1570, 91, 2723, 2962, 106, 3557]])  # Lịch sử tương tác\n",
    "# target = torch.tensor([528])  # Item mục tiêu cần dự đoán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3052badf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6949495077133179\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Chuyển dữ liệu sang device phù hợp (CPU/GPU)\n",
    "    user = user.to(args.device)\n",
    "    seq = seq.to(args.device)\n",
    "    target = target_item.to(args.device)\n",
    "    \n",
    "    # Dự đoán\n",
    "    logits = model(user, seq, target)\n",
    "    prediction = torch.sigmoid(logits)  # Áp dụng sigmoid để có xác suất\n",
    "# print(f\"Logits: {logits}\")\n",
    "# print(f\"Prediction score: {prediction}\")\n",
    "# print(f\"rating: {rating}\")\n",
    "# cal the loss\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "loss = criterion(logits.unsqueeze(0), rating.unsqueeze(0).float())\n",
    "print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d137e6e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hm-scalablerecs-QHnDFvap-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
