{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6defc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52b77b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydantic import BaseModel\n",
    "import sys\n",
    "import os\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from loguru import logger\n",
    "from load_dotenv import load_dotenv\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import mlflow\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src.utils.embedding_id_mapper import IDMapper\n",
    "from src.algo.gSASRec.model import SASRec\n",
    "from src.algo.gSASRec.dataset import SASRecDataset\n",
    "from src.algo.gSASRec.trainer import SASRecLitModule\n",
    "from src.eval.utils import create_rec_df, create_label_df, merge_recs_with_target\n",
    "from src.eval.log_metrics import log_ranking_metrics, log_classification_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737a8749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ace436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 22:26:35.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mSetting up Mlflow experiment: first-attempt, run_name: 050-sasrec lr=0.00006 dropout=0.2 num_heads=4\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"testing\": false,\n",
      "  \"log_to_mlflow\": true,\n",
      "  \"experiment_name\": \"first-attempt\",\n",
      "  \"run_name\": \"050-sasrec lr=0.00006 dropout=0.2 num_heads=4\",\n",
      "  \"notebook_persit_dp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\notebooks\\\\data\\\\first-attempt\\\\050-sasrec lr=0.00006 dropout=0.2 num_heads=4\",\n",
      "  \"user_col\": \"user_id\",\n",
      "  \"item_col\": \"parent_asin\",\n",
      "  \"rating_col\": \"rating\",\n",
      "  \"timestamp_col\": \"timestamp\",\n",
      "  \"group_name\": \"seq-modelling\",\n",
      "  \"top_K\": 100,\n",
      "  \"top_k\": 10,\n",
      "  \"batch_size\": 256,\n",
      "  \"lr\": 0.00006,\n",
      "  \"l2_emb\": 0.0,\n",
      "  \"early_stopping_patience\": 10,\n",
      "  \"device\": \"cpu\",\n",
      "  \"num_epochs\": 100,\n",
      "  \"max_len\": 10,\n",
      "  \"dropout\": 0.2,\n",
      "  \"hidden_units\": 128,\n",
      "  \"num_blocks\": 1,\n",
      "  \"num_heads\": 4,\n",
      "  \"num_workers\": 3,\n",
      "  \"seq_length\": 50,\n",
      "  \"train_data_fp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\data_for_ai\\\\interim\\\\train_sample_interactions_16407u_neg_seq.parquet\",\n",
      "  \"val_data_fp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\data_for_ai\\\\interim\\\\val_sample_interactions_16407u_neg_seq.parquet\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Args(BaseModel):\n",
    "    testing: bool = False\n",
    "    log_to_mlflow: bool = True\n",
    "    experiment_name: str = \"first-attempt\"\n",
    "    # run name contains the hyperparameters \"lr bs dropout num_heads\" used for the run\n",
    "    run_name: str = f\"050-sasrec lr=0.0005 dropout=0.5 num_heads=4\" \n",
    "    notebook_persit_dp: str = None\n",
    "    \n",
    "    user_col: str = \"user_id\"\n",
    "    item_col: str = \"parent_asin\"\n",
    "    rating_col: str = \"rating\"\n",
    "    timestamp_col: str = \"timestamp\"\n",
    "    group_name: str = \"seq-modelling\"\n",
    "\n",
    "    top_K: int = 100\n",
    "    top_k: int = 10\n",
    "\n",
    "    batch_size: int = 256\n",
    "    lr: float = 0.0005\n",
    "    l2_emb: float = 0.0001\n",
    "    early_stopping_patience: int = 5\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    num_epochs: int = 100\n",
    "\n",
    "    # SASrec specific\n",
    "    max_len: int = 50\n",
    "    dropout: float = 0.5\n",
    "    hidden_units: int = 128\n",
    "    num_blocks: int = 1\n",
    "    num_heads: int = 4\n",
    "    num_workers: int = 3\n",
    "    seq_length: int = 50\n",
    "    \n",
    "    train_data_fp: str = os.path.abspath(\"../data_for_ai/interim/train_sample_interactions_16407u_neg_seq.parquet\")\n",
    "    val_data_fp: str = os.path.abspath(\"../data_for_ai/interim/val_sample_interactions_16407u_neg_seq.parquet\")\n",
    "\n",
    "    def init(self):\n",
    "        self.notebook_persit_dp = os.path.abspath(f\"data/{self.experiment_name}/{self.run_name}\")\n",
    "\n",
    "        if not (mlflow_uri := os.environ.get(\"MLFLOW_TRACKING_URI\")):\n",
    "            self.log_to_mlflow = False\n",
    "            logger.warning(\"MLFlow is not enabled. Turn off tracking to Mlflow.\")\n",
    "\n",
    "        if self.log_to_mlflow:\n",
    "            logger.info(\n",
    "                f\"Setting up Mlflow experiment: {self.experiment_name}, run_name: {self.run_name}\"\n",
    "            )\n",
    "\n",
    "            self._mlf_logger = MLFlowLogger(\n",
    "                experiment_name=self.experiment_name,\n",
    "                run_name=self.run_name,\n",
    "                tracking_uri=mlflow_uri,\n",
    "                log_model=True,\n",
    "            )\n",
    "\n",
    "        if not self.testing:\n",
    "            os.makedirs(self.notebook_persit_dp, exist_ok=True)\n",
    "        return self\n",
    "    \n",
    "args = Args().init()\n",
    "print(args.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "383bb869",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(args.train_data_fp)\n",
    "train_df[args.rating_col] = train_df[args.rating_col].apply(lambda x: 1 if x > 0 else 0)    \n",
    "# train_df = train_df[train_df['item_sequence'].apply(lambda seq: not all(item == -1 for item in seq))]        \n",
    "\n",
    "val_df = pd.read_parquet(args.val_data_fp)\n",
    "val_df[args.rating_col] = val_df[args.rating_col].apply(lambda x: 1 if x > 0 else 0)\n",
    "# val_df = val_df[val_df['item_sequence'].apply(lambda seq: not all(item == -1 for item in seq))]\n",
    "\n",
    "assert set(val_df[args.user_col].unique()).issubset(set(train_df[args.user_col].unique())), \"Validation users must be present in training users.\"\n",
    "\n",
    "assert set(val_df[args.item_col].unique()).issubset(set(train_df[args.item_col].unique())), \"Validation items must be present in training items.\"\n",
    "assert train_df[args.timestamp_col].max() < val_df[args.timestamp_col].min(), \"Validation data must be after training data. Otherwise, its a data contamination problem.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca341b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B004FV4ROA</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-27 00:30:31.146</td>\n",
       "      <td>11295</td>\n",
       "      <td>528</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B07KFQFDNB</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-27 00:30:31.146</td>\n",
       "      <td>11295</td>\n",
       "      <td>3503</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AEHS7YR7BGGWMZS24H5UR5IP46HQ</td>\n",
       "      <td>B08F1P3BCC</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-27 01:44:52.242</td>\n",
       "      <td>1784</td>\n",
       "      <td>3925</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEHS7YR7BGGWMZS24H5UR5IP46HQ</td>\n",
       "      <td>B00HXT8EKE</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-27 01:44:52.242</td>\n",
       "      <td>1784</td>\n",
       "      <td>1507</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGAVHCK42EGMVS7DGPRX6HBCUCNQ</td>\n",
       "      <td>B09Q3NR84W</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-27 02:25:48.357</td>\n",
       "      <td>9042</td>\n",
       "      <td>4273</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6953</th>\n",
       "      <td>AEEQZRQBOFHFBFPYBX2BZ5WOI33A</td>\n",
       "      <td>B00007KDX6</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-19 16:56:53.030</td>\n",
       "      <td>1396</td>\n",
       "      <td>32</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6954</th>\n",
       "      <td>AHLN6GKTKZE22AON34YAQXTGK63A</td>\n",
       "      <td>B09SWWCN6Q</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-19 17:28:55.519</td>\n",
       "      <td>14550</td>\n",
       "      <td>4303</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6955</th>\n",
       "      <td>AHLN6GKTKZE22AON34YAQXTGK63A</td>\n",
       "      <td>B0C682GZ5X</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-19 17:28:55.519</td>\n",
       "      <td>14550</td>\n",
       "      <td>4772</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6956</th>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B091K4WYD1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-19 22:08:53.253</td>\n",
       "      <td>2446</td>\n",
       "      <td>4086</td>\n",
       "      <td>[528, 395, 3226, 2286, 4734, 856, 631, 890, 45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6957</th>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B005CTKYB4</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-19 22:08:53.253</td>\n",
       "      <td>2446</td>\n",
       "      <td>654</td>\n",
       "      <td>[395, 3226, 2286, 4734, 856, 631, 890, 4516, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6958 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           user_id parent_asin  rating  \\\n",
       "0     AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B004FV4ROA       1   \n",
       "1     AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B07KFQFDNB       0   \n",
       "2     AEHS7YR7BGGWMZS24H5UR5IP46HQ  B08F1P3BCC       1   \n",
       "3     AEHS7YR7BGGWMZS24H5UR5IP46HQ  B00HXT8EKE       0   \n",
       "4     AGAVHCK42EGMVS7DGPRX6HBCUCNQ  B09Q3NR84W       1   \n",
       "...                            ...         ...     ...   \n",
       "6953  AEEQZRQBOFHFBFPYBX2BZ5WOI33A  B00007KDX6       1   \n",
       "6954  AHLN6GKTKZE22AON34YAQXTGK63A  B09SWWCN6Q       0   \n",
       "6955  AHLN6GKTKZE22AON34YAQXTGK63A  B0C682GZ5X       1   \n",
       "6956  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B091K4WYD1       1   \n",
       "6957  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B005CTKYB4       0   \n",
       "\n",
       "                   timestamp  user_indice  item_indice  \\\n",
       "0    2020-12-27 00:30:31.146        11295          528   \n",
       "1    2020-12-27 00:30:31.146        11295         3503   \n",
       "2    2020-12-27 01:44:52.242         1784         3925   \n",
       "3    2020-12-27 01:44:52.242         1784         1507   \n",
       "4    2020-12-27 02:25:48.357         9042         4273   \n",
       "...                      ...          ...          ...   \n",
       "6953 2022-02-19 16:56:53.030         1396           32   \n",
       "6954 2022-02-19 17:28:55.519        14550         4303   \n",
       "6955 2022-02-19 17:28:55.519        14550         4772   \n",
       "6956 2022-02-19 22:08:53.253         2446         4086   \n",
       "6957 2022-02-19 22:08:53.253         2446          654   \n",
       "\n",
       "                                          item_sequence  \n",
       "0     [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "1     [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "2     [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "3     [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "4     [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "...                                                 ...  \n",
       "6953  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "6954  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "6955  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "6956  [528, 395, 3226, 2286, 4734, 856, 631, 890, 45...  \n",
       "6957  [395, 3226, 2286, 4734, 856, 631, 890, 4516, 4...  \n",
       "\n",
       "[6958 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21bc2bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFZ4EK2LJ655XQKTEUELCARO6RYA</td>\n",
       "      <td>B00002EQCW</td>\n",
       "      <td>1</td>\n",
       "      <td>2003-01-23 03:28:15.000</td>\n",
       "      <td>8071</td>\n",
       "      <td>4</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFZ4EK2LJ655XQKTEUELCARO6RYA</td>\n",
       "      <td>B095JX15XF</td>\n",
       "      <td>0</td>\n",
       "      <td>2003-01-23 03:28:15.000</td>\n",
       "      <td>8071</td>\n",
       "      <td>4132</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFY2C4YOUP2SSMM43HD2L3FIEFZA</td>\n",
       "      <td>B00008SCFL</td>\n",
       "      <td>1</td>\n",
       "      <td>2003-11-25 18:12:09.000</td>\n",
       "      <td>7935</td>\n",
       "      <td>36</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFY2C4YOUP2SSMM43HD2L3FIEFZA</td>\n",
       "      <td>B00OQVZDJM</td>\n",
       "      <td>0</td>\n",
       "      <td>2003-11-25 18:12:09.000</td>\n",
       "      <td>7935</td>\n",
       "      <td>1859</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHF3TGIOSTD2UCHF3MO4MIHFJ5NQ</td>\n",
       "      <td>B07KQWX947</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-06-18 02:02:57.000</td>\n",
       "      <td>13705</td>\n",
       "      <td>3514</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254779</th>\n",
       "      <td>AES2U6KIAORYLTBPENQWMDVALTDQ</td>\n",
       "      <td>B07ZZVX1F2</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-26 21:37:58.968</td>\n",
       "      <td>3109</td>\n",
       "      <td>3800</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254780</th>\n",
       "      <td>AGU6SDEIMLBQZII2FVFJ6YIUZRKQ</td>\n",
       "      <td>B0BZJ9BYZ3</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-26 22:29:54.459</td>\n",
       "      <td>11489</td>\n",
       "      <td>4696</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254781</th>\n",
       "      <td>AGU6SDEIMLBQZII2FVFJ6YIUZRKQ</td>\n",
       "      <td>B0BSF5LM3J</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-26 22:29:54.459</td>\n",
       "      <td>11489</td>\n",
       "      <td>4622</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254782</th>\n",
       "      <td>AG2HB7HEYSIAGYBEFFL666KVYTHA</td>\n",
       "      <td>B0895KGSY1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-26 23:06:03.454</td>\n",
       "      <td>8251</td>\n",
       "      <td>3896</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254783</th>\n",
       "      <td>AG2HB7HEYSIAGYBEFFL666KVYTHA</td>\n",
       "      <td>B0029U2YSA</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-26 23:06:03.454</td>\n",
       "      <td>8251</td>\n",
       "      <td>289</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254784 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id parent_asin  rating  \\\n",
       "0       AFZ4EK2LJ655XQKTEUELCARO6RYA  B00002EQCW       1   \n",
       "1       AFZ4EK2LJ655XQKTEUELCARO6RYA  B095JX15XF       0   \n",
       "2       AFY2C4YOUP2SSMM43HD2L3FIEFZA  B00008SCFL       1   \n",
       "3       AFY2C4YOUP2SSMM43HD2L3FIEFZA  B00OQVZDJM       0   \n",
       "4       AHF3TGIOSTD2UCHF3MO4MIHFJ5NQ  B07KQWX947       1   \n",
       "...                              ...         ...     ...   \n",
       "254779  AES2U6KIAORYLTBPENQWMDVALTDQ  B07ZZVX1F2       1   \n",
       "254780  AGU6SDEIMLBQZII2FVFJ6YIUZRKQ  B0BZJ9BYZ3       0   \n",
       "254781  AGU6SDEIMLBQZII2FVFJ6YIUZRKQ  B0BSF5LM3J       1   \n",
       "254782  AG2HB7HEYSIAGYBEFFL666KVYTHA  B0895KGSY1       0   \n",
       "254783  AG2HB7HEYSIAGYBEFFL666KVYTHA  B0029U2YSA       1   \n",
       "\n",
       "                     timestamp  user_indice  item_indice  \\\n",
       "0      2003-01-23 03:28:15.000         8071            4   \n",
       "1      2003-01-23 03:28:15.000         8071         4132   \n",
       "2      2003-11-25 18:12:09.000         7935           36   \n",
       "3      2003-11-25 18:12:09.000         7935         1859   \n",
       "4      2004-06-18 02:02:57.000        13705         3514   \n",
       "...                        ...          ...          ...   \n",
       "254779 2020-12-26 21:37:58.968         3109         3800   \n",
       "254780 2020-12-26 22:29:54.459        11489         4696   \n",
       "254781 2020-12-26 22:29:54.459        11489         4622   \n",
       "254782 2020-12-26 23:06:03.454         8251         3896   \n",
       "254783 2020-12-26 23:06:03.454         8251          289   \n",
       "\n",
       "                                            item_sequence  \n",
       "0       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "1       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "2       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "3       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "4       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "...                                                   ...  \n",
       "254779  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "254780  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "254781  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "254782  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "254783  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "\n",
       "[254784 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b5861e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_user_train_df = train_df[train_df[\"user_id\"] == \"AGSP5XAQPQBUUXZHEZSC65FD7NOQ\"][[\"timestamp\",\"parent_asin\",\"rating\",\"item_sequence\"]]\n",
    "# change type of item_sequence column into int and save as csv\n",
    "one_user_train_df[\"item_sequence\"] = one_user_train_df[\"item_sequence\"].apply(lambda x: [int(i) for i in x])\n",
    "# sort the dataframe by timestamp\n",
    "one_user_train_df = one_user_train_df.sort_values(by=\"timestamp\")\n",
    "# save as csv\n",
    "one_user_train_df.to_csv(\"one_user_train_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e21cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_user_val_df = val_df[val_df[\"user_id\"] == \"AGSP5XAQPQBUUXZHEZSC65FD7NOQ\"][[\"timestamp\",\"parent_asin\",\"rating\",\"item_sequence\"]]\n",
    "# change type of item_sequence column into int and save as csv\n",
    "one_user_val_df[\"item_sequence\"] = one_user_val_df[\"item_sequence\"].apply(lambda x: [int(i) for i in x])\n",
    "# sort the dataframe by timestamp\n",
    "one_user_val_df = one_user_val_df.sort_values(by=\"timestamp\")\n",
    "# save as csv\n",
    "one_user_val_df.to_csv(\"one_user_val_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d66a933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data statistics: {'avg_seq_length': 9.692512088671188, 'median_seq_length': 7.0, 'short_seqs_pct': 19.31871703089676, 'max_seq_length': 50, 'rating_distribution': {1: 0.5, 0: 0.5}, 'unique_items_in_sequences': 4817, 'top_10pct_items_coverage': 38.00919782449624}\n",
      "Validation data statistics: {'avg_seq_length': 20.355849382006323, 'median_seq_length': 16.0, 'short_seqs_pct': 0.0, 'max_seq_length': 50, 'rating_distribution': {1: 0.5, 0: 0.5}, 'unique_items_in_sequences': 4779, 'top_10pct_items_coverage': 39.69965263068712}\n"
     ]
    }
   ],
   "source": [
    "# Add this code to analyze your sequence data\n",
    "def analyze_sequence_data(df, seq_col='item_sequence', rating_col='rating'):\n",
    "    # 1. Sequence length distribution\n",
    "    seq_lengths = df[seq_col].apply(lambda x: sum(1 for i in x if i != -1))\n",
    "    \n",
    "    # 2. Rating distribution\n",
    "    rating_dist = df[rating_col].value_counts(normalize=True)\n",
    "    \n",
    "    # 3. Item frequency in sequences\n",
    "    all_items = [item for seq in df[seq_col].tolist() for item in seq if item != -1]\n",
    "    item_counts = pd.Series(all_items).value_counts()\n",
    "    \n",
    "    # 4. Calculate item popularity skew\n",
    "    top_10_pct = item_counts.head(int(len(item_counts)*0.1)).sum() / item_counts.sum()\n",
    "    \n",
    "    return {\n",
    "        \"avg_seq_length\": seq_lengths.mean(),\n",
    "        \"median_seq_length\": seq_lengths.median(),\n",
    "        \"short_seqs_pct\": (seq_lengths <= 2).mean() * 100,  # % sequences with â‰¤2 items\n",
    "        \"max_seq_length\": seq_lengths.max(),\n",
    "        \"rating_distribution\": rating_dist.to_dict(),\n",
    "        \"unique_items_in_sequences\": len(set(all_items)),\n",
    "        \"top_10pct_items_coverage\": top_10_pct * 100,  # % of interactions covered by top 10% popular items\n",
    "    }\n",
    "\n",
    "# Run the analysis on train and validation sets\n",
    "train_stats = analyze_sequence_data(train_df)\n",
    "val_stats = analyze_sequence_data(val_df)\n",
    "# Print the statistics\n",
    "print(\"Training data statistics:\", train_stats)\n",
    "print(\"Validation data statistics:\", val_stats)\n",
    "\n",
    "# print(\"Training data statistics:\")\n",
    "# print(json.dumps(train_stats, indent=2))\n",
    "# print(\"\\nValidation data statistics:\")\n",
    "# print(json.dumps(val_stats, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ad41a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(n_user, n_items, dropout, hidden_units, num_blocks, num_heads, seq_length):\n",
    "    \"\"\"\n",
    "    Initialize the model with the given parameters.\n",
    "    \"\"\"\n",
    "    model = SASRec(\n",
    "        user_num = n_user,\n",
    "        item_num = n_items,\n",
    "        dropout_rate = dropout,\n",
    "        hidden_units = hidden_units,\n",
    "        num_blocks = num_blocks,\n",
    "        num_heads = num_heads,\n",
    "        sequence_length = seq_length,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17f32acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 22:26:44.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mNumber of users: 16407, Number of items: 4817\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CÃ¡c row NaN ngay sau init: []\n"
     ]
    }
   ],
   "source": [
    "item_indices = train_df[args.item_col].unique()\n",
    "user_indices = train_df[args.user_col].unique()\n",
    "n_items = len(item_indices)\n",
    "n_users = len(user_indices)\n",
    "\n",
    "logger.info(f\"Number of users: {n_users}, Number of items: {n_items}\")\n",
    "model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads, args.seq_length)\n",
    "emb_weights = model.item_emb.weight.data\n",
    "nan_rows = torch.isnan(emb_weights).any(dim=1).nonzero().squeeze().tolist()\n",
    "print(\"CÃ¡c row NaN ngay sau init:\", nan_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3721313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user = torch.tensor([7411])\n",
    "# seq = torch.tensor([[1782, 1975, 3089, 3719, 4721, 3443, 4178, 2953, 684, 3401]])\n",
    "# target_item = torch.tensor([[474]])\n",
    "# predictions = model(user, seq, target_item)\n",
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beb513ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_num = 4817\n",
      "Padding token index: 4817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0103,  0.0065,  0.0075,  0.0237,  0.0049,  0.0029,  0.0139,  0.0252,\n",
       "          0.0081, -0.0062,  0.0020, -0.0315, -0.0343,  0.0042, -0.0158,  0.0296,\n",
       "         -0.0159, -0.0278, -0.0075, -0.0069, -0.0115,  0.0147, -0.0008,  0.0308,\n",
       "         -0.0011,  0.0205,  0.0137, -0.0200, -0.0156, -0.0093, -0.0026, -0.0121,\n",
       "          0.0036,  0.0191, -0.0027,  0.0071, -0.0120,  0.0513, -0.0123, -0.0188,\n",
       "          0.0141,  0.0460, -0.0023, -0.0069,  0.0172,  0.0159,  0.0003, -0.0241,\n",
       "         -0.0308,  0.0469,  0.0203,  0.0354,  0.0001,  0.0184,  0.0469,  0.0094,\n",
       "          0.0031,  0.0338,  0.0093, -0.0141,  0.0088,  0.0001,  0.0164,  0.0127,\n",
       "          0.0229,  0.0028, -0.0058,  0.0062, -0.0145,  0.0137, -0.0051, -0.0308,\n",
       "         -0.0158, -0.0099, -0.0373, -0.0178, -0.0207, -0.0090, -0.0080, -0.0176,\n",
       "         -0.0122, -0.0028,  0.0011, -0.0195,  0.0016, -0.0017, -0.0239,  0.0210,\n",
       "         -0.0323, -0.0191, -0.0384, -0.0082, -0.0156,  0.0078,  0.0141, -0.0006,\n",
       "         -0.0170, -0.0156,  0.0111,  0.0710, -0.0213, -0.0143, -0.0069, -0.0227,\n",
       "          0.0150, -0.0157, -0.0064,  0.0275,  0.0084,  0.0029,  0.0176,  0.0395,\n",
       "         -0.0201,  0.0285,  0.0039, -0.0029, -0.0212, -0.0124,  0.0155, -0.0401,\n",
       "         -0.0342, -0.0278, -0.0003,  0.0210, -0.0161, -0.0325,  0.0200,  0.0204]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"item_num = {model.item_num}\")\n",
    "print(f\"Padding token index: {model.item_emb.padding_idx}\")\n",
    "model.item_emb(torch.tensor([3089]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0e4c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 4\n",
    "# for i in range(0,10000):\n",
    "#     user = torch.tensor([[0]])\n",
    "#     seq = torch.randint(0, model.item_num, (batch_size, args.max_len))\n",
    "#     seq[:, :np.random.randint(1,10)] = model.item_num \n",
    "#     target_item = torch.tensor([[4000]])\n",
    "#     # print(f\"seq: {seq}\")\n",
    "#     predictions = model(user, seq, target_item)\n",
    "#     # if prediction is returned by nan values, then print the seq\n",
    "#     if torch.isnan(predictions).any():\n",
    "#         print(\"nan prediction\")\n",
    "#         print(seq)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85ec519d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SASRec(\n",
       "  (item_emb): Embedding(4818, 128, padding_idx=4817)\n",
       "  (pos_emb): Embedding(50, 128)\n",
       "  (emb_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (attention_layernorms): ModuleList(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (attention_layers): ModuleList(\n",
       "    (0): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (forward_layernorms): ModuleList(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (forward_layers): ModuleList(\n",
       "    (0): PointWiseFeedForward(\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "      (dropout1): Dropout(p=0.2, inplace=False)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "      (dropout2): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce5dddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_train_df = train_df.sample(frac=0.2, random_state=42)\n",
    "\n",
    "rating_dataset = SASRecDataset(\n",
    "    train_df, \"user_indice\", \"item_sequence\", \"item_indice\", \"rating\",args.max_len, n_items, args.timestamp_col, \n",
    ")\n",
    "val_rating_dataset = SASRecDataset(\n",
    "    val_df, \"user_indice\", \"item_sequence\", \"item_indice\", \"rating\", args.max_len, n_items, args.timestamp_col, \n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    rating_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True, num_workers=args.num_workers, persistent_workers=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_rating_dataset, batch_size=args.batch_size, shuffle=False, drop_last=False, num_workers=args.num_workers, persistent_workers=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe049bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256])\n",
      "torch.Size([256, 50])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i[\"user\"].shape)\n",
    "    print(i[\"sequence\"].shape)\n",
    "    print(i[\"item\"].shape)\n",
    "    print(i[\"rating\"].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "939d52ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AE227WAM4NWQPJI33OPN7ZARNNZQ'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idm_path = os.path.abspath(\"../data_for_ai/interim/idm_16407u.json\")\n",
    "idm = IDMapper().load(idm_path)\n",
    "idm.get_user_id(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bec2235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "\n",
    "# # 1. Hyper-params & setup\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# num_epochs = 10\n",
    "# lr = 1e-4          # giáº£m thÃªm náº¿u váº«n NaN\n",
    "# weight_decay = 1e-4\n",
    "# grad_clip_norm = 1.0\n",
    "\n",
    "# # 2. Dataset & DataLoader\n",
    "# # exist above \n",
    "\n",
    "# # 3. Model, Loss, Optimizer, Scheduler\n",
    "# model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "# model = model.to(device)\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1)\n",
    "\n",
    "# # 4. Anomaly detection (chá»‰ báº­t khi debug)\n",
    "# # torch.autograd.detect_anomaly(check_nan=True)\n",
    "\n",
    "# # for epoch in range(1, num_epochs + 1):\n",
    "#     ##### Training #####\n",
    "# epoch = 0\n",
    "# model.train()\n",
    "# total_train_loss = 0.0\n",
    "# for batch_idx, batch in enumerate(train_loader, 1):\n",
    "#     print(f\"Epoch {epoch} â”€ batch {batch_idx}/{len(train_loader)}\")\n",
    "#     # if batch_idx == 10:\n",
    "#     #     break\n",
    "#     users    = batch[\"user\"].to(device)\n",
    "#     items    = batch[\"item\"].to(device)\n",
    "#     seqs     = batch[\"sequence\"].long().to(device)\n",
    "#     labels   = batch[\"rating\"].float().to(device)\n",
    "\n",
    "#     # Zero gradients\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     # Forward\n",
    "#     logits = model(users, seqs, items).view_as(labels)\n",
    "\n",
    "#     # Loss\n",
    "#     loss = criterion(logits, labels)\n",
    "#     total_train_loss += loss.item()\n",
    "#     # print(f\"Epoch {epoch} â”€ batch {batch_idx}/{len(train_loader)} â”€ loss: {loss.item():.4f}\")\n",
    "#     # Backward + gradient clipping\n",
    "#     try:\n",
    "#         loss.backward()\n",
    "#     except RuntimeError as e:\n",
    "#         print(f\"ðŸš¨ Backward failed: {e}\")\n",
    "#         # inspect táº¥t cáº£ gradients\n",
    "#         for name, p in model.named_parameters():\n",
    "#             if p.grad is not None:\n",
    "#                 has_nan = torch.isnan(p.grad).any().item()\n",
    "#                 print(f\"  grad for {name}: contains_nan={has_nan}, max_abs={p.grad.abs().max().item():.4e}\")\n",
    "#         raise  # váº«n nÃ©m exception Ä‘á»ƒ dá»«ng\n",
    "#     torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip_norm)\n",
    "\n",
    "#     # (optional) log max grad for each layer\n",
    "#     for name, p in model.named_parameters():\n",
    "#         if p.grad is not None:\n",
    "#             if torch.isnan(p.grad).any():\n",
    "#                 print(f\"[NaN grad] {name}\")\n",
    "#             # print(f\"{name} grad_norm={p.grad.norm():.4f}\")\n",
    "\n",
    "#     # Step optimizer\n",
    "#     optimizer.step()\n",
    "\n",
    "# avg_train_loss = total_train_loss / len(train_loader)\n",
    "# print(f\"Epoch {epoch} â”€ train_loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "# ##### Validation #####\n",
    "# # model.eval()\n",
    "# # total_val_loss = 0.0\n",
    "# # with torch.no_grad():\n",
    "# #     for batch in val_loader:\n",
    "# #         users  = batch[\"user\"].to(device)\n",
    "# #         items  = batch[\"item\"].to(device)\n",
    "# #         seqs   = batch[\"sequence\"].long().to(device)\n",
    "# #         labels = batch[\"rating\"].float().to(device)\n",
    "\n",
    "# #         logits = model(users, seqs, items).view_as(labels)\n",
    "# #         loss = criterion(logits, labels)\n",
    "# #         total_val_loss += loss.item()\n",
    "\n",
    "# # avg_val_loss = total_val_loss / len(val_loader)\n",
    "# # print(f\"Epoch {epoch} â”€ val_loss:   {avg_val_loss:.4f}\")\n",
    "\n",
    "# # Scheduler step\n",
    "# # scheduler.step(avg_val_loss)\n",
    "\n",
    "# print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff6faaa",
   "metadata": {},
   "source": [
    "## check nan cases in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c9491de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "# # Extract the attention layer from the model\n",
    "# attention_layer = model.attention_layers[0]\n",
    "\n",
    "# for batch_idx, batch in enumerate(train_loader):\n",
    "#     user_ids, seq, target_item, labels = batch\n",
    "\n",
    "#     # Get the embeddings for the sequence\n",
    "#     sequence_embeddings = model.item_emb(batch[\"sequence\"])\n",
    "    \n",
    "\n",
    "#     # Pass the embeddings through the attention layer\n",
    "#     attention_output, _ = attention_layer(sequence_embeddings, sequence_embeddings, sequence_embeddings)\n",
    "#     # if any NaN values are found in the attention output, print the batch and the attention output\n",
    "#     if torch.isnan(attention_output).any():\n",
    "#         print(f\"Batch {batch_idx} - Attention output contains NaN values.\")\n",
    "#         print(batch[\"sequence\"])\n",
    "#         print(\"Sample seq:\", batch[\"sequence\"][0])\n",
    "#         print(\"Item emb weight stats:\", model.item_emb.weight.min(), model.item_emb.weight.max())\n",
    "#         print(attention_output)\n",
    "#         break\n",
    "#     # Example: Perform some operation with the attention output\n",
    "#     predictions = model.final_layer(attention_output[:, -1, :])  # Use the last position for predictions\n",
    "\n",
    "#     # Check for NaN values in predictions\n",
    "#     if torch.isnan(predictions).any():\n",
    "#         print(f\"Batch {batch_idx} - Predictions contain NaN values.\")\n",
    "#         print(batch[\"sequence\"])\n",
    "#         print(\"Sample seq:\", batch[\"sequence\"][0])\n",
    "#         print(\"Item emb weight stats:\", model.item_emb.weight.min(), model.item_emb.weight.max())\n",
    "#         print(predictions)\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6be76f",
   "metadata": {},
   "source": [
    "## overfit 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0675501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping = EarlyStopping(\n",
    "#     monitor=\"val_loss\", patience=5, mode=\"min\", verbose=False\n",
    "# )\n",
    "# # create log_dir if it does not exist\n",
    "# if not os.path.exists(args.notebook_persit_dp):\n",
    "#     os.makedirs(args.notebook_persit_dp, exist_ok=True)\n",
    "\n",
    "# model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads, args.seq_length)\n",
    "# lit_model = SASRecLitModule(\n",
    "#     model,\n",
    "#     log_dir=args.notebook_persit_dp,\n",
    "#     accelerator=args.device,\n",
    "#     lr=args.lr,\n",
    "#     l2_emb=args.l2_emb,\n",
    "#     idm= idm\n",
    "# )\n",
    "\n",
    "# log_dir = f\"{args.notebook_persit_dp}/logs/overfit\"\n",
    "# # create log_dir if it does not exist\n",
    "# if not os.path.exists(log_dir):\n",
    "#     os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# # train model\n",
    "# trainer = L.Trainer(\n",
    "#     default_root_dir=log_dir,\n",
    "#     accelerator=args.device if args.device else \"auto\",\n",
    "#     max_epochs=10,\n",
    "#     # max_epochs=args.num_epochs,\n",
    "#     overfit_batches=1,\n",
    "#     callbacks=[early_stopping],\n",
    "# )\n",
    "# trainer.fit(\n",
    "#     model=lit_model,\n",
    "#     train_dataloaders=train_loader,\n",
    "#     val_dataloaders=train_loader,\n",
    "# )\n",
    "# logger.info(f\"Logs available at {trainer.log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ddfce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type   | Params | Mode \n",
      "-----------------------------------------\n",
      "0 | model | SASRec | 722 K  | train\n",
      "-----------------------------------------\n",
      "722 K     Trainable params\n",
      "0         Non-trainable params\n",
      "722 K     Total params\n",
      "2.891     Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d4233c41ae41bfb6dc53654750c2a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6974566578865051\n",
      "Val Loss: 0.6997570991516113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660da90d8a2e4d45b8c4cd7213e1924c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eddf2882e1a4b1eaf5cc966d38da2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6962968111038208\n",
      "Val Loss: 0.6970601677894592\n",
      "Val Loss: 0.6930683255195618\n",
      "Val Loss: 0.7009881138801575\n",
      "Val Loss: 0.6959498524665833\n",
      "Val Loss: 0.6952573657035828\n",
      "Val Loss: 0.6927010416984558\n",
      "Val Loss: 0.7005616426467896\n",
      "Val Loss: 0.6954341530799866\n",
      "Val Loss: 0.6972519159317017\n",
      "Val Loss: 0.6979076862335205\n",
      "Val Loss: 0.691720724105835\n",
      "Val Loss: 0.6986429691314697\n",
      "Val Loss: 0.6956564784049988\n",
      "Val Loss: 0.7043942213058472\n",
      "Val Loss: 0.6992948651313782\n",
      "Val Loss: 0.6967430114746094\n",
      "Val Loss: 0.7009515762329102\n",
      "Val Loss: 0.6960301399230957\n",
      "Val Loss: 0.7002236247062683\n",
      "Val Loss: 0.704680323600769\n",
      "Val Loss: 0.6964830756187439\n",
      "Val Loss: 0.6953856348991394\n",
      "Val Loss: 0.699321448802948\n",
      "Val Loss: 0.6958011388778687\n",
      "Val Loss: 0.6973512172698975\n",
      "Val Loss: 0.6872048377990723\n",
      "Val Loss: 0.7017459869384766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations_df:    user_indice recommendation     score\n",
      "0        11295           4172   0.63765\n",
      "1        11295            422  0.620351\n",
      "2        11295             13  0.614194\n",
      "3        11295           4218  0.597724\n",
      "4        11295            744  0.597677\n",
      "Recommendations_df:      user_indice item_indice     score  rec_ranking  \\\n",
      "0          11295        4172   0.63765          1.0   \n",
      "1          11295         422  0.620351          2.0   \n",
      "2          11295          13  0.614194          3.0   \n",
      "3          11295        4218  0.597724          4.0   \n",
      "4          11295         744  0.597677          5.0   \n",
      "..           ...         ...       ...          ...   \n",
      "995         1134        2464  0.551014         96.0   \n",
      "996         1134         881  0.550933         97.0   \n",
      "997         1134        1078  0.550834         98.0   \n",
      "998         1134        3893  0.550776         99.0   \n",
      "999         1134        1197  0.550762        100.0   \n",
      "\n",
      "                          user_id parent_asin  \n",
      "0    AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B099V8GPR4  \n",
      "1    AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B003M8NVFS  \n",
      "2    AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B00005N9D3  \n",
      "3    AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B09HV56NJ5  \n",
      "4    AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B0065DUJ0C  \n",
      "..                            ...         ...  \n",
      "995  AECHOCFTVBBW6ID4GSMHTPK2775Q  B01B6KE5MG  \n",
      "996  AECHOCFTVBBW6ID4GSMHTPK2775Q  B00829E7XC  \n",
      "997  AECHOCFTVBBW6ID4GSMHTPK2775Q  B00A7VYO90  \n",
      "998  AECHOCFTVBBW6ID4GSMHTPK2775Q  B088NJQQFH  \n",
      "999  AECHOCFTVBBW6ID4GSMHTPK2775Q  B00C9UFTGO  \n",
      "\n",
      "[1000 rows x 6 columns]\n",
      "Label_df:        user_indice  item_indice  rating  rating_rank\n",
      "3479        11466          518       1          1.0\n",
      "4784        15544         4689       1          1.0\n",
      "4782        11406         3699       1          1.0\n",
      "1961         8976         4593       1          1.0\n",
      "4780         6108         3959       1          1.0\n",
      "Eval_df:     user_indice item_indice score  rec_ranking user_id parent_asin  rating  \\\n",
      "0            8        2125   NaN          101     NaN         NaN       0   \n",
      "1            8        4032   NaN          101     NaN         NaN       0   \n",
      "2            8        4597   NaN          101     NaN         NaN       1   \n",
      "3            8        4621   NaN          101     NaN         NaN       1   \n",
      "4           13        3189   NaN          101     NaN         NaN       0   \n",
      "\n",
      "   rating_rank  \n",
      "0          4.0  \n",
      "1          3.0  \n",
      "2          2.0  \n",
      "3          1.0  \n",
      "4          2.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\evidently\\metrics\\recsys\\f_beta_top_k.py:64: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': [{'metric': 'NDCGKMetric', 'result': {'k': 10, 'current': 1     0.0\n",
      "2     0.0\n",
      "3     0.0\n",
      "4     0.0\n",
      "5     0.0\n",
      "6     0.0\n",
      "7     0.0\n",
      "8     0.0\n",
      "9     0.0\n",
      "10    0.0\n",
      "dtype: float64, 'current_value': 0.0, 'reference': None, 'reference_value': None}}, {'metric': 'RecallTopKMetric', 'result': {'k': 100, 'current': 0     0.000000\n",
      "1     0.000000\n",
      "2     0.000000\n",
      "3     0.000000\n",
      "4     0.000000\n",
      "        ...   \n",
      "95    0.000206\n",
      "96    0.000206\n",
      "97    0.000206\n",
      "98    0.000206\n",
      "99    0.000206\n",
      "Length: 100, dtype: float64, 'current_value': 0.00020627062706270627, 'reference': None, 'reference_value': None}}, {'metric': 'PrecisionTopKMetric', 'result': {'k': 100, 'current': 0     0.000000\n",
      "1     0.000000\n",
      "2     0.000000\n",
      "3     0.000000\n",
      "4     0.000000\n",
      "        ...   \n",
      "95    0.000004\n",
      "96    0.000004\n",
      "97    0.000004\n",
      "98    0.000004\n",
      "99    0.000004\n",
      "Length: 100, dtype: float64, 'current_value': 4.125412541254125e-06, 'reference': None, 'reference_value': None}}, {'metric': 'FBetaTopKMetric', 'result': {'k': 10, 'current': 0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "5   NaN\n",
      "6   NaN\n",
      "7   NaN\n",
      "8   NaN\n",
      "9   NaN\n",
      "dtype: float64, 'current_value': nan, 'reference': None, 'reference_value': None}}, {'metric': 'PersonalizationMetric', 'result': {'k': 10, 'current_value': 0.9933333333333334, 'current_table': {'3443': 86, '3925': 64, '3454': 54, '3726': 42, '4054': 40, '3472': 35, '3590': 33, '3923': 33, '4055': 31, '2694': 29}, 'reference_value': None, 'reference_table': None}}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 22:35:08.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.gSASRec.trainer\u001b[0m:\u001b[36mon_fit_end\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mEvidently metrics are available at: c:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\data\\first-attempt\\050-sasrec lr=0.00006 dropout=0.2 num_heads=4\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run 050-sasrec lr=0.00006 dropout=0.2 num_heads=4 at: http://138.2.61.6:5002/#/experiments/2/runs/f00e9203599d48bfaf1072c0b79aad64\n",
      "ðŸ§ª View experiment at: http://138.2.61.6:5002/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=args.early_stopping_patience, mode=\"min\", verbose=False, min_delta=0.0025\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{args.notebook_persit_dp}/checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads, args.seq_length)\n",
    "# model = model.double()\n",
    "lit_model = SASRecLitModule(\n",
    "    model,\n",
    "    log_dir=args.notebook_persit_dp,\n",
    "    accelerator=args.device,\n",
    "    lr=args.lr,\n",
    "    l2_emb=args.l2_emb,\n",
    "    idm= idm\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persit_dp}/logs/run\"\n",
    "# create log_dir if it does not exist\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    # max_epochs=1,\n",
    "    # detect_anomaly=True,\n",
    "    max_epochs=args.num_epochs,\n",
    "    # gradient_clip_val=1.0,     \n",
    "    # gradient_clip_algorithm=\"norm\",\n",
    "    callbacks=[early_stopping, checkpoint_callback],\n",
    "    logger=args._mlf_logger if args.log_to_mlflow else None,\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")\n",
    "\n",
    "\n",
    "# Change the library as a workaround for the issue in the latest Lightning release\n",
    "#https://github.com/Lightning-AI/pytorch-lightning/pull/20669/commits/429f732a0528c558e701da7ec01e51c1e2e4f32e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef8d60a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TensorBoardLogger' object has no attribute 'run_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m all_params = [args]\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args.log_to_mlflow:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     run_id = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_id\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m mlflow.start_run(run_id=run_id):\n\u001b[32m      7\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m all_params:\n",
      "\u001b[31mAttributeError\u001b[39m: 'TensorBoardLogger' object has no attribute 'run_id'"
     ]
    }
   ],
   "source": [
    "all_params = [args]\n",
    "\n",
    "if args.log_to_mlflow:\n",
    "    run_id = trainer.logger.run_id\n",
    "\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        for params in all_params:\n",
    "            params_dict = params.model_dump()\n",
    "            params_ = dict()\n",
    "            for k, v in params_dict.items():\n",
    "                if k == \"top_K\":\n",
    "                    k = \"top_big_K\"\n",
    "                if k == \"top_k\":\n",
    "                    k = \"top_small_k\"\n",
    "                params_[f\"{params.__repr_name__()}.{k}\"] = v\n",
    "            mlflow.log_params(params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1efc4e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-10 20:48:05.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mSetting up Mlflow experiment: first-attempt, run_name: 050-sasrec lr=0.00006 dropout=0.2 num_heads=4\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])\n",
      "odict_keys(['model.item_emb.weight', 'model.pos_emb.weight', 'model.attention_layernorms.0.weight', 'model.attention_layernorms.0.bias', 'model.attention_layers.0.in_proj_weight', 'model.attention_layers.0.in_proj_bias', 'model.attention_layers.0.out_proj.weight', 'model.attention_layers.0.out_proj.bias', 'model.forward_layernorms.0.weight', 'model.forward_layernorms.0.bias', 'model.forward_layers.0.conv1.weight', 'model.forward_layers.0.conv1.bias', 'model.forward_layers.0.conv2.weight', 'model.forward_layers.0.conv2.bias', 'model.final_layer.weight', 'model.final_layer.bias'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SASRec(\n",
       "  (item_emb): Embedding(4818, 128, padding_idx=4817)\n",
       "  (pos_emb): Embedding(10, 128)\n",
       "  (emb_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (attention_layernorms): ModuleList(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (attention_layers): ModuleList(\n",
       "    (0): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (forward_layernorms): ModuleList(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (forward_layers): ModuleList(\n",
       "    (0): PointWiseFeedForward(\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "      (dropout1): Dropout(p=0.2, inplace=False)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "      (dropout2): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = Args().init()  # Load láº¡i cÃ¡c tham sá»‘ tá»« class Args\n",
    "model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "\n",
    "# ÄÆ°á»ng dáº«n Ä‘áº¿n file checkpoint\n",
    "checkpoint_path = f\"C:/Users/Trieu/OneDrive/Desktop/recsys/real_time_recsys/notebooks/data/first-attempt/050-sasrec/checkpoints/best_checkpoint.ckpt\"\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device(args.device))\n",
    "print(checkpoint.keys())\n",
    "print(checkpoint['state_dict'].keys())\n",
    "\n",
    "# Táº¡o má»™t state_dict má»›i, loáº¡i bá» tiá»n tá»‘ \"model.\"\n",
    "model_state_dict = {k.replace(\"model.\", \"\"): v for k, v in checkpoint['state_dict'].items() if k.startswith(\"model.\")}\n",
    "\n",
    "# Load state_dict Ä‘Ã£ Ä‘iá»u chá»‰nh vÃ o mÃ´ hÃ¬nh SASRec\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.eval()  # Chuyá»ƒn sang cháº¿ Ä‘á»™ Ä‘Ã¡nh giÃ¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ee4d824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VÃ­ dá»¥: chá»n má»™t batch tá»« val_loader\n",
    "# create a random index to get a sample from a batch\n",
    "sample_index = np.random.randint(0, 512)\n",
    "sample_batch = next(iter(train_loader))\n",
    "user = sample_batch[\"user\"].to(args.device)\n",
    "seq = sample_batch[\"sequence\"].to(args.device)\n",
    "target_item = sample_batch[\"item\"].to(args.device)\n",
    "rating = sample_batch[\"rating\"].to(args.device)\n",
    "# print shape\n",
    "# print(f\"User: {user.shape}, Seq: {seq.shape}, Target item: {target_item.shape} \")\n",
    "# print(f\"User: {user}, Seq: {seq}, Target item: {target_item}, Rating: {rating}\")\n",
    "# user_indice = torch.tensor([11295])  # ID ngÆ°á»i dÃ¹ng Ä‘Ã£ Ä‘Æ°á»£c Ã¡nh xáº¡\n",
    "# sequence = torch.tensor([[4817, 1898, 3479, 3908, 1570, 91, 2723, 2962, 106, 3557]])  # Lá»‹ch sá»­ tÆ°Æ¡ng tÃ¡c\n",
    "# target = torch.tensor([528])  # Item má»¥c tiÃªu cáº§n dá»± Ä‘oÃ¡n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3052badf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6237632632255554\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Chuyá»ƒn dá»¯ liá»‡u sang device phÃ¹ há»£p (CPU/GPU)\n",
    "    user = user.to(args.device)\n",
    "    seq = seq.to(args.device)\n",
    "    target = target_item.to(args.device)\n",
    "    \n",
    "    # Dá»± Ä‘oÃ¡n\n",
    "    logits = model(user, seq, target)\n",
    "    prediction = torch.sigmoid(logits)  # Ãp dá»¥ng sigmoid Ä‘á»ƒ cÃ³ xÃ¡c suáº¥t\n",
    "# print(f\"Logits: {logits}\")\n",
    "# print(f\"Prediction score: {prediction}\")\n",
    "# print(f\"rating: {rating}\")\n",
    "# cal the loss\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "loss = criterion(logits.unsqueeze(0), rating.unsqueeze(0).float())\n",
    "print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d137e6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample seq: tensor([4817, 4817, 2615, 4678, 1936, 1192, 4734, 4264, 3723, 2168])\n",
      "Sample user: 4468\n",
      "Sample target item: 4516\n",
      "Sample rating: 1.0\n",
      "Sample prediction: 0.463296115398407\n"
     ]
    }
   ],
   "source": [
    "# print a random sample of the sequence\n",
    "sample_id = np.random.randint(0, 256)\n",
    "print(f\"Sample seq: {seq[sample_id]}\")\n",
    "print(f\"Sample user: {user[sample_id]}\")\n",
    "print(f\"Sample target item: {target_item[sample_id]}\")\n",
    "print(f\"Sample rating: {rating[sample_id]}\")\n",
    "print(f\"Sample prediction: {prediction[sample_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faecbaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hm-scalablerecs-QHnDFvap-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
