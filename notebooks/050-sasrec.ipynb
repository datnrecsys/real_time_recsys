{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6defc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52b77b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydantic import BaseModel\n",
    "import sys\n",
    "import os\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from loguru import logger\n",
    "from load_dotenv import load_dotenv\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import mlflow\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src.utils.embedding_id_mapper import IDMapper\n",
    "from src.algo.gSASRec.model import SASRec\n",
    "from src.algo.gSASRec.dataset import SASRecDataset\n",
    "from src.algo.gSASRec.trainer import SASRecLitModule\n",
    "from src.eval.utils import create_rec_df, create_label_df, merge_recs_with_target\n",
    "from src.eval.log_metrics import log_ranking_metrics, log_classification_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737a8749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ace436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-03 00:02:28.770\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m41\u001b[0m - \u001b[33m\u001b[1mMLFlow is not enabled. Turn off tracking to Mlflow.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"testing\": false,\n",
      "  \"log_to_mlflow\": false,\n",
      "  \"experiment_name\": \"first-attempt\",\n",
      "  \"run_name\": \"018-sasrec\",\n",
      "  \"notebook_persit_dp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\notebooks\\\\data\\\\first-attempt\\\\018-sasrec\",\n",
      "  \"user_col\": \"user_id\",\n",
      "  \"item_col\": \"parent_asin\",\n",
      "  \"rating_col\": \"rating\",\n",
      "  \"timestamp_col\": \"timestamp\",\n",
      "  \"group_name\": \"seq-modelling\",\n",
      "  \"top_K\": 100,\n",
      "  \"top_k\": 10,\n",
      "  \"batch_size\": 512,\n",
      "  \"lr\": 0.001,\n",
      "  \"l2_emb\": 0.001,\n",
      "  \"early_stopping_patience\": 10,\n",
      "  \"device\": \"cpu\",\n",
      "  \"num_epochs\": 100,\n",
      "  \"max_len\": 10,\n",
      "  \"dropout\": 0.3,\n",
      "  \"hidden_units\": 128,\n",
      "  \"num_blocks\": 1,\n",
      "  \"num_heads\": 2,\n",
      "  \"num_workers\": 3,\n",
      "  \"train_data_fp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\data_for_ai\\\\interim\\\\train_sample_interactions_16407u_neg_seq.parquet\",\n",
      "  \"val_data_fp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\data_for_ai\\\\interim\\\\val_sample_interactions_16407u_neg_seq.parquet\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Args(BaseModel):\n",
    "    testing: bool = False\n",
    "    log_to_mlflow: bool = True\n",
    "    experiment_name: str = \"first-attempt\"\n",
    "    run_name: str = f\"018-sasrec\"\n",
    "    notebook_persit_dp: str = None\n",
    "    \n",
    "    user_col: str = \"user_id\"\n",
    "    item_col: str = \"parent_asin\"\n",
    "    rating_col: str = \"rating\"\n",
    "    timestamp_col: str = \"timestamp\"\n",
    "    group_name: str = \"seq-modelling\"\n",
    "\n",
    "    top_K: int = 100\n",
    "    top_k: int = 10\n",
    "\n",
    "    batch_size: int = 512\n",
    "    lr: float = 0.0001\n",
    "    l2_emb: float = 0.001\n",
    "    early_stopping_patience: int = 10\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    num_epochs: int = 200\n",
    "\n",
    "    # SASrec specific\n",
    "    max_len: int = 10\n",
    "    dropout: float = 0.3\n",
    "    hidden_units: int = 128\n",
    "    num_blocks: int = 1\n",
    "    num_heads: int = 2\n",
    "    num_workers: int = 3\n",
    "    # seq_length: int = 10\n",
    "    \n",
    "    train_data_fp: str = os.path.abspath(\"../data_for_ai/interim/train_sample_interactions_16407u_neg_seq.parquet\")\n",
    "    val_data_fp: str = os.path.abspath(\"../data_for_ai/interim/val_sample_interactions_16407u_neg_seq.parquet\")\n",
    "\n",
    "    def init(self):\n",
    "        self.notebook_persit_dp = os.path.abspath(f\"data/{self.experiment_name}/{self.run_name}\")\n",
    "\n",
    "        if not (mlflow_uri := os.environ.get(\"MLFLOW_TRACKING_URI\")):\n",
    "            self.log_to_mlflow = False\n",
    "            logger.warning(\"MLFlow is not enabled. Turn off tracking to Mlflow.\")\n",
    "\n",
    "        if self.log_to_mlflow:\n",
    "            logger.info(\n",
    "                f\"Setting up Mlflow experiment: {self.experiment_name}, run_name: {self.run_name}\"\n",
    "            )\n",
    "\n",
    "            self._mlf_logger = MLFlowLogger(\n",
    "                experiment_name=self.experiment_name,\n",
    "                run_name=self.run_name,\n",
    "                tracking_uri=mlflow_uri,\n",
    "                log_model=True,\n",
    "            )\n",
    "\n",
    "        if not self.testing:\n",
    "            os.makedirs(self.notebook_persit_dp, exist_ok=True)\n",
    "        return self\n",
    "    \n",
    "args = Args().init()\n",
    "print(args.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "383bb869",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(args.train_data_fp)\n",
    "train_df[args.rating_col] = train_df[args.rating_col].apply(lambda x: 1 if x > 0 else 0)    \n",
    "train_df = train_df[train_df['item_sequence'].apply(lambda seq: not all(item == -1 for item in seq))]        \n",
    "\n",
    "val_df = pd.read_parquet(args.val_data_fp)\n",
    "val_df[args.rating_col] = val_df[args.rating_col].apply(lambda x: 1 if x > 0 else 0)\n",
    "val_df = val_df[val_df['item_sequence'].apply(lambda seq: not all(item == -1 for item in seq))]\n",
    "\n",
    "assert set(val_df[args.user_col].unique()).issubset(set(train_df[args.user_col].unique())), \"Validation users must be present in training users.\"\n",
    "\n",
    "assert set(val_df[args.item_col].unique()).issubset(set(train_df[args.item_col].unique())), \"Validation items must be present in training items.\"\n",
    "assert train_df[args.timestamp_col].max() < val_df[args.timestamp_col].min(), \"Validation data must be after training data. Otherwise, its a data contamination problem.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca341b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B004FV4ROA</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-27 00:30:31.146</td>\n",
       "      <td>11295</td>\n",
       "      <td>528</td>\n",
       "      <td>[1898, 3479, 3908, 1570, 91, 2723, 2962, 106, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B07KFQFDNB</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-27 00:30:31.146</td>\n",
       "      <td>11295</td>\n",
       "      <td>3503</td>\n",
       "      <td>[3479, 3908, 1570, 91, 2723, 2962, 106, 3557, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AEHS7YR7BGGWMZS24H5UR5IP46HQ</td>\n",
       "      <td>B08F1P3BCC</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-27 01:44:52.242</td>\n",
       "      <td>1784</td>\n",
       "      <td>3925</td>\n",
       "      <td>[4319, 3382, 4330, 1173, 1330, 423, 2868, 3167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEHS7YR7BGGWMZS24H5UR5IP46HQ</td>\n",
       "      <td>B00HXT8EKE</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-27 01:44:52.242</td>\n",
       "      <td>1784</td>\n",
       "      <td>1507</td>\n",
       "      <td>[3382, 4330, 1173, 1330, 423, 2868, 3167, 1071...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGAVHCK42EGMVS7DGPRX6HBCUCNQ</td>\n",
       "      <td>B09Q3NR84W</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-27 02:25:48.357</td>\n",
       "      <td>9042</td>\n",
       "      <td>4273</td>\n",
       "      <td>[1311, 1416, 455, 3743, 1823, 2694, 3612, 3462...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6953</th>\n",
       "      <td>AEEQZRQBOFHFBFPYBX2BZ5WOI33A</td>\n",
       "      <td>B01A08E70K</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-19 16:56:53.030</td>\n",
       "      <td>1396</td>\n",
       "      <td>2441</td>\n",
       "      <td>[3451, 3827, 1839, 1347, 2504, 2694, 4546, 427...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6954</th>\n",
       "      <td>AHLN6GKTKZE22AON34YAQXTGK63A</td>\n",
       "      <td>B0C682GZ5X</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-19 17:28:55.519</td>\n",
       "      <td>14550</td>\n",
       "      <td>4772</td>\n",
       "      <td>[2950, 1812, 4735, 4165, 4575, 2440, 607, 4807...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6955</th>\n",
       "      <td>AHLN6GKTKZE22AON34YAQXTGK63A</td>\n",
       "      <td>B09SWWCN6Q</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-19 17:28:55.519</td>\n",
       "      <td>14550</td>\n",
       "      <td>4303</td>\n",
       "      <td>[1812, 4735, 4165, 4575, 2440, 607, 4807, 374,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6956</th>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B091K4WYD1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-19 22:08:53.253</td>\n",
       "      <td>2446</td>\n",
       "      <td>4086</td>\n",
       "      <td>[644, 3602, 4569, 1865, 3030, 3653, 3803, 3998...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6957</th>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B005CTKYB4</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-19 22:08:53.253</td>\n",
       "      <td>2446</td>\n",
       "      <td>654</td>\n",
       "      <td>[3602, 4569, 1865, 3030, 3653, 3803, 3998, 285...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6958 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           user_id parent_asin  rating  \\\n",
       "0     AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B004FV4ROA       1   \n",
       "1     AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B07KFQFDNB       0   \n",
       "2     AEHS7YR7BGGWMZS24H5UR5IP46HQ  B08F1P3BCC       1   \n",
       "3     AEHS7YR7BGGWMZS24H5UR5IP46HQ  B00HXT8EKE       0   \n",
       "4     AGAVHCK42EGMVS7DGPRX6HBCUCNQ  B09Q3NR84W       1   \n",
       "...                            ...         ...     ...   \n",
       "6953  AEEQZRQBOFHFBFPYBX2BZ5WOI33A  B01A08E70K       0   \n",
       "6954  AHLN6GKTKZE22AON34YAQXTGK63A  B0C682GZ5X       1   \n",
       "6955  AHLN6GKTKZE22AON34YAQXTGK63A  B09SWWCN6Q       0   \n",
       "6956  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B091K4WYD1       1   \n",
       "6957  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B005CTKYB4       0   \n",
       "\n",
       "                   timestamp  user_indice  item_indice  \\\n",
       "0    2020-12-27 00:30:31.146        11295          528   \n",
       "1    2020-12-27 00:30:31.146        11295         3503   \n",
       "2    2020-12-27 01:44:52.242         1784         3925   \n",
       "3    2020-12-27 01:44:52.242         1784         1507   \n",
       "4    2020-12-27 02:25:48.357         9042         4273   \n",
       "...                      ...          ...          ...   \n",
       "6953 2022-02-19 16:56:53.030         1396         2441   \n",
       "6954 2022-02-19 17:28:55.519        14550         4772   \n",
       "6955 2022-02-19 17:28:55.519        14550         4303   \n",
       "6956 2022-02-19 22:08:53.253         2446         4086   \n",
       "6957 2022-02-19 22:08:53.253         2446          654   \n",
       "\n",
       "                                          item_sequence  \n",
       "0     [1898, 3479, 3908, 1570, 91, 2723, 2962, 106, ...  \n",
       "1     [3479, 3908, 1570, 91, 2723, 2962, 106, 3557, ...  \n",
       "2     [4319, 3382, 4330, 1173, 1330, 423, 2868, 3167...  \n",
       "3     [3382, 4330, 1173, 1330, 423, 2868, 3167, 1071...  \n",
       "4     [1311, 1416, 455, 3743, 1823, 2694, 3612, 3462...  \n",
       "...                                                 ...  \n",
       "6953  [3451, 3827, 1839, 1347, 2504, 2694, 4546, 427...  \n",
       "6954  [2950, 1812, 4735, 4165, 4575, 2440, 607, 4807...  \n",
       "6955  [1812, 4735, 4165, 4575, 2440, 607, 4807, 374,...  \n",
       "6956  [644, 3602, 4569, 1865, 3030, 3653, 3803, 3998...  \n",
       "6957  [3602, 4569, 1865, 3030, 3653, 3803, 3998, 285...  \n",
       "\n",
       "[6958 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21bc2bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFZ4EK2LJ655XQKTEUELCARO6RYA</td>\n",
       "      <td>B095JX15XF</td>\n",
       "      <td>0</td>\n",
       "      <td>2003-01-23 03:28:15.000</td>\n",
       "      <td>8071</td>\n",
       "      <td>4132</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFY2C4YOUP2SSMM43HD2L3FIEFZA</td>\n",
       "      <td>B00OQVZDJM</td>\n",
       "      <td>0</td>\n",
       "      <td>2003-11-25 18:12:09.000</td>\n",
       "      <td>7935</td>\n",
       "      <td>1859</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AHF3TGIOSTD2UCHF3MO4MIHFJ5NQ</td>\n",
       "      <td>B07KQWX947</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-06-18 02:02:57.000</td>\n",
       "      <td>13705</td>\n",
       "      <td>3514</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AH5Z47PJ5RTSUL2RLCO2QITGIT4Q</td>\n",
       "      <td>B07W4GJGCM</td>\n",
       "      <td>0</td>\n",
       "      <td>2004-09-13 20:18:44.000</td>\n",
       "      <td>12730</td>\n",
       "      <td>3734</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AEX3L4NKDESOCGWOFNF63GRFGXCA</td>\n",
       "      <td>B0067HY7HW</td>\n",
       "      <td>0</td>\n",
       "      <td>2004-10-22 14:26:12.000</td>\n",
       "      <td>3735</td>\n",
       "      <td>746</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254779</th>\n",
       "      <td>AES2U6KIAORYLTBPENQWMDVALTDQ</td>\n",
       "      <td>B07ZZVX1F2</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-26 21:37:58.968</td>\n",
       "      <td>3109</td>\n",
       "      <td>3800</td>\n",
       "      <td>[-1.0, 2237.0, 1691.0, 2694.0, 1633.0, 934.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254780</th>\n",
       "      <td>AGU6SDEIMLBQZII2FVFJ6YIUZRKQ</td>\n",
       "      <td>B0BSF5LM3J</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-26 22:29:54.459</td>\n",
       "      <td>11489</td>\n",
       "      <td>4622</td>\n",
       "      <td>[107.0, 3997.0, 2858.0, 1680.0, 2919.0, 4109.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254781</th>\n",
       "      <td>AGU6SDEIMLBQZII2FVFJ6YIUZRKQ</td>\n",
       "      <td>B0BZJ9BYZ3</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-26 22:29:54.459</td>\n",
       "      <td>11489</td>\n",
       "      <td>4696</td>\n",
       "      <td>[3997.0, 2858.0, 1680.0, 2919.0, 4109.0, 3695....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254782</th>\n",
       "      <td>AG2HB7HEYSIAGYBEFFL666KVYTHA</td>\n",
       "      <td>B0895KGSY1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-26 23:06:03.454</td>\n",
       "      <td>8251</td>\n",
       "      <td>3896</td>\n",
       "      <td>[-1.0, -1.0, 2531.0, 382.0, 2756.0, 3373.0, 34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254783</th>\n",
       "      <td>AG2HB7HEYSIAGYBEFFL666KVYTHA</td>\n",
       "      <td>B0029U2YSA</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-26 23:06:03.454</td>\n",
       "      <td>8251</td>\n",
       "      <td>289</td>\n",
       "      <td>[-1.0, 2531.0, 382.0, 2756.0, 3373.0, 3486.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238377 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id parent_asin  rating  \\\n",
       "1       AFZ4EK2LJ655XQKTEUELCARO6RYA  B095JX15XF       0   \n",
       "3       AFY2C4YOUP2SSMM43HD2L3FIEFZA  B00OQVZDJM       0   \n",
       "5       AHF3TGIOSTD2UCHF3MO4MIHFJ5NQ  B07KQWX947       1   \n",
       "7       AH5Z47PJ5RTSUL2RLCO2QITGIT4Q  B07W4GJGCM       0   \n",
       "9       AEX3L4NKDESOCGWOFNF63GRFGXCA  B0067HY7HW       0   \n",
       "...                              ...         ...     ...   \n",
       "254779  AES2U6KIAORYLTBPENQWMDVALTDQ  B07ZZVX1F2       1   \n",
       "254780  AGU6SDEIMLBQZII2FVFJ6YIUZRKQ  B0BSF5LM3J       1   \n",
       "254781  AGU6SDEIMLBQZII2FVFJ6YIUZRKQ  B0BZJ9BYZ3       0   \n",
       "254782  AG2HB7HEYSIAGYBEFFL666KVYTHA  B0895KGSY1       0   \n",
       "254783  AG2HB7HEYSIAGYBEFFL666KVYTHA  B0029U2YSA       1   \n",
       "\n",
       "                     timestamp  user_indice  item_indice  \\\n",
       "1      2003-01-23 03:28:15.000         8071         4132   \n",
       "3      2003-11-25 18:12:09.000         7935         1859   \n",
       "5      2004-06-18 02:02:57.000        13705         3514   \n",
       "7      2004-09-13 20:18:44.000        12730         3734   \n",
       "9      2004-10-22 14:26:12.000         3735          746   \n",
       "...                        ...          ...          ...   \n",
       "254779 2020-12-26 21:37:58.968         3109         3800   \n",
       "254780 2020-12-26 22:29:54.459        11489         4622   \n",
       "254781 2020-12-26 22:29:54.459        11489         4696   \n",
       "254782 2020-12-26 23:06:03.454         8251         3896   \n",
       "254783 2020-12-26 23:06:03.454         8251          289   \n",
       "\n",
       "                                            item_sequence  \n",
       "1       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "3       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "5       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "7       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "9       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "...                                                   ...  \n",
       "254779  [-1.0, 2237.0, 1691.0, 2694.0, 1633.0, 934.0, ...  \n",
       "254780  [107.0, 3997.0, 2858.0, 1680.0, 2919.0, 4109.0...  \n",
       "254781  [3997.0, 2858.0, 1680.0, 2919.0, 4109.0, 3695....  \n",
       "254782  [-1.0, -1.0, 2531.0, 382.0, 2756.0, 3373.0, 34...  \n",
       "254783  [-1.0, 2531.0, 382.0, 2756.0, 3373.0, 3486.0, ...  \n",
       "\n",
       "[238377 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ad41a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(n_user, n_items, dropout, hidden_units, num_blocks, num_heads):\n",
    "    \"\"\"\n",
    "    Initialize the model with the given parameters.\n",
    "    \"\"\"\n",
    "    model = SASRec(\n",
    "        user_num = n_user,\n",
    "        item_num = n_items,\n",
    "        dropout_rate = dropout,\n",
    "        hidden_units = hidden_units,\n",
    "        num_blocks = num_blocks,\n",
    "        num_heads = num_heads,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17f32acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-03 00:02:32.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mNumber of users: 16407, Number of items: 4817\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CÃ¡c row NaN ngay sau init: []\n"
     ]
    }
   ],
   "source": [
    "item_indices = train_df[args.item_col].unique()\n",
    "user_indices = train_df[args.user_col].unique()\n",
    "n_items = len(item_indices)\n",
    "n_users = len(user_indices)\n",
    "\n",
    "logger.info(f\"Number of users: {n_users}, Number of items: {n_items}\")\n",
    "model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "emb_weights = model.item_emb.weight.data\n",
    "nan_rows = torch.isnan(emb_weights).any(dim=1).nonzero().squeeze().tolist()\n",
    "print(\"CÃ¡c row NaN ngay sau init:\", nan_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3721313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1111]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = torch.tensor([7411])\n",
    "seq = torch.tensor([[1782, 1975, 3089, 3719, 4721, 3443, 4178, 2953, 684, 3401]])\n",
    "target_item = torch.tensor([[474]])\n",
    "predictions = model(user, seq, target_item)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beb513ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_num = 4817\n",
      "Padding token index: 4817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.3936e-03, -7.6499e-03,  1.1814e-02, -2.4329e-02,  1.4673e-02,\n",
       "          2.5769e-02, -1.1656e-03, -3.3041e-02,  6.1734e-03,  7.9613e-03,\n",
       "         -1.7432e-02,  8.7700e-03, -1.6371e-02,  2.4884e-02, -1.8612e-02,\n",
       "         -1.2904e-02, -8.6961e-03,  7.3918e-03, -3.0689e-02, -2.4997e-02,\n",
       "          3.1686e-02,  1.3092e-02,  5.7486e-03,  2.5254e-02,  2.7055e-02,\n",
       "         -2.6505e-02,  1.0796e-02, -2.6389e-02, -5.0969e-03,  2.1111e-02,\n",
       "         -5.5239e-03,  8.4614e-03, -3.1410e-02, -5.0082e-03, -8.6538e-03,\n",
       "          1.9261e-02,  3.0144e-02,  3.4273e-02,  2.8078e-02,  1.1149e-02,\n",
       "          2.0210e-03, -9.4555e-03, -1.4229e-02,  1.1223e-04, -3.1423e-02,\n",
       "          5.0647e-03, -1.9311e-02, -4.5509e-04, -3.1216e-02,  2.7416e-02,\n",
       "          1.9963e-02,  1.6873e-02,  2.3036e-02, -4.5613e-03,  8.3995e-03,\n",
       "         -7.6507e-03,  3.2092e-02,  1.3936e-02,  1.2433e-02, -2.3799e-02,\n",
       "         -1.0306e-02,  2.6887e-02,  1.0682e-02, -1.9861e-02,  2.8178e-02,\n",
       "          4.6828e-03,  3.4133e-02, -3.4819e-02,  2.3623e-02,  6.5063e-03,\n",
       "          3.3963e-02, -2.1583e-03, -1.4908e-02, -2.3415e-02,  2.8422e-02,\n",
       "          2.8380e-03,  1.4457e-02,  9.4979e-03, -1.3146e-02,  1.9690e-02,\n",
       "         -2.5153e-02,  3.0367e-02, -6.4415e-03,  3.0912e-05, -2.0091e-02,\n",
       "          2.5735e-02, -1.2950e-02, -9.0945e-04,  2.7144e-02, -3.0782e-02,\n",
       "         -2.2139e-02, -2.9491e-02,  2.9257e-02,  2.0998e-02, -1.4918e-02,\n",
       "          6.5599e-03, -3.0708e-02, -1.6548e-02,  7.8510e-03,  5.3728e-03,\n",
       "         -1.4600e-02, -1.5250e-02, -2.2854e-02, -1.2144e-02, -2.3604e-02,\n",
       "          3.4542e-02, -9.6624e-03, -1.2846e-02, -3.6919e-03, -1.6657e-02,\n",
       "          5.9404e-03,  1.0762e-02,  2.4726e-02,  1.8889e-02, -1.9398e-02,\n",
       "         -3.4768e-02,  7.0080e-03, -1.0816e-02,  1.2310e-02,  3.4693e-02,\n",
       "          3.3405e-02, -2.5251e-02,  1.8645e-02,  2.0099e-02, -2.8481e-02,\n",
       "         -2.5367e-02,  2.8374e-02,  3.2732e-02]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"item_num = {model.item_num}\")\n",
    "print(f\"Padding token index: {model.item_emb.padding_idx}\")\n",
    "model.item_emb(torch.tensor([3089]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0e4c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 4\n",
    "# for i in range(0,10000):\n",
    "#     user = torch.tensor([[0]])\n",
    "#     seq = torch.randint(0, model.item_num, (batch_size, args.max_len))\n",
    "#     seq[:, :np.random.randint(1,10)] = model.item_num \n",
    "#     target_item = torch.tensor([[4000]])\n",
    "#     # print(f\"seq: {seq}\")\n",
    "#     predictions = model(user, seq, target_item)\n",
    "#     # if prediction is returned by nan values, then print the seq\n",
    "#     if torch.isnan(predictions).any():\n",
    "#         print(\"nan prediction\")\n",
    "#         print(seq)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85ec519d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SASRec(\n",
       "  (item_emb): Embedding(4818, 128, padding_idx=4817)\n",
       "  (pos_emb): Embedding(10, 128)\n",
       "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
       "  (attention_layernorms): ModuleList(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (attention_layers): ModuleList(\n",
       "    (0): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (forward_layernorms): ModuleList(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (forward_layers): ModuleList(\n",
       "    (0): PointWiseFeedForward(\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce5dddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset = SASRecDataset(\n",
    "    train_df, \"user_indice\", \"item_sequence\", \"item_indice\", \"rating\",args.max_len, n_items, args.timestamp_col, \n",
    ")\n",
    "val_rating_dataset = SASRecDataset(\n",
    "    val_df, \"user_indice\", \"item_sequence\", \"item_indice\", \"rating\", args.max_len, n_items, args.timestamp_col, \n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    rating_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True, num_workers=args.num_workers, persistent_workers=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_rating_dataset, batch_size=args.batch_size, shuffle=False, drop_last=False, num_workers=args.num_workers, persistent_workers=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe049bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in train_loader:\n",
    "#     print(i[\"user\"])\n",
    "#     print(i[\"sequence\"])\n",
    "#     print(i[\"item\"])\n",
    "#     print(i[\"rating\"])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "939d52ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AE227WAM4NWQPJI33OPN7ZARNNZQ'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idm_path = os.path.abspath(\"../data_for_ai/interim/idm_16407u.json\")\n",
    "idm = IDMapper().load(idm_path)\n",
    "idm.get_user_id(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bec2235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "\n",
    "# # 1. Hyper-params & setup\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# num_epochs = 10\n",
    "# lr = 1e-4          # giáº£m thÃªm náº¿u váº«n NaN\n",
    "# weight_decay = 1e-4\n",
    "# grad_clip_norm = 1.0\n",
    "\n",
    "# # 2. Dataset & DataLoader\n",
    "# # exist above \n",
    "\n",
    "# # 3. Model, Loss, Optimizer, Scheduler\n",
    "# model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "# model = model.to(device)\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1)\n",
    "\n",
    "# # 4. Anomaly detection (chá»‰ báº­t khi debug)\n",
    "# # torch.autograd.detect_anomaly(check_nan=True)\n",
    "\n",
    "# # for epoch in range(1, num_epochs + 1):\n",
    "#     ##### Training #####\n",
    "# epoch = 0\n",
    "# model.train()\n",
    "# total_train_loss = 0.0\n",
    "# for batch_idx, batch in enumerate(train_loader, 1):\n",
    "#     print(f\"Epoch {epoch} â”€ batch {batch_idx}/{len(train_loader)}\")\n",
    "#     # if batch_idx == 10:\n",
    "#     #     break\n",
    "#     users    = batch[\"user\"].to(device)\n",
    "#     items    = batch[\"item\"].to(device)\n",
    "#     seqs     = batch[\"sequence\"].long().to(device)\n",
    "#     labels   = batch[\"rating\"].float().to(device)\n",
    "\n",
    "#     # Zero gradients\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     # Forward\n",
    "#     logits = model(users, seqs, items).view_as(labels)\n",
    "\n",
    "#     # Loss\n",
    "#     loss = criterion(logits, labels)\n",
    "#     total_train_loss += loss.item()\n",
    "#     # print(f\"Epoch {epoch} â”€ batch {batch_idx}/{len(train_loader)} â”€ loss: {loss.item():.4f}\")\n",
    "#     # Backward + gradient clipping\n",
    "#     try:\n",
    "#         loss.backward()\n",
    "#     except RuntimeError as e:\n",
    "#         print(f\"ðŸš¨ Backward failed: {e}\")\n",
    "#         # inspect táº¥t cáº£ gradients\n",
    "#         for name, p in model.named_parameters():\n",
    "#             if p.grad is not None:\n",
    "#                 has_nan = torch.isnan(p.grad).any().item()\n",
    "#                 print(f\"  grad for {name}: contains_nan={has_nan}, max_abs={p.grad.abs().max().item():.4e}\")\n",
    "#         raise  # váº«n nÃ©m exception Ä‘á»ƒ dá»«ng\n",
    "#     torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip_norm)\n",
    "\n",
    "#     # (optional) log max grad for each layer\n",
    "#     for name, p in model.named_parameters():\n",
    "#         if p.grad is not None:\n",
    "#             if torch.isnan(p.grad).any():\n",
    "#                 print(f\"[NaN grad] {name}\")\n",
    "#             # print(f\"{name} grad_norm={p.grad.norm():.4f}\")\n",
    "\n",
    "#     # Step optimizer\n",
    "#     optimizer.step()\n",
    "\n",
    "# avg_train_loss = total_train_loss / len(train_loader)\n",
    "# print(f\"Epoch {epoch} â”€ train_loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "# ##### Validation #####\n",
    "# # model.eval()\n",
    "# # total_val_loss = 0.0\n",
    "# # with torch.no_grad():\n",
    "# #     for batch in val_loader:\n",
    "# #         users  = batch[\"user\"].to(device)\n",
    "# #         items  = batch[\"item\"].to(device)\n",
    "# #         seqs   = batch[\"sequence\"].long().to(device)\n",
    "# #         labels = batch[\"rating\"].float().to(device)\n",
    "\n",
    "# #         logits = model(users, seqs, items).view_as(labels)\n",
    "# #         loss = criterion(logits, labels)\n",
    "# #         total_val_loss += loss.item()\n",
    "\n",
    "# # avg_val_loss = total_val_loss / len(val_loader)\n",
    "# # print(f\"Epoch {epoch} â”€ val_loss:   {avg_val_loss:.4f}\")\n",
    "\n",
    "# # Scheduler step\n",
    "# # scheduler.step(avg_val_loss)\n",
    "\n",
    "# print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff6faaa",
   "metadata": {},
   "source": [
    "## check nan cases in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c9491de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "# # Extract the attention layer from the model\n",
    "# attention_layer = model.attention_layers[0]\n",
    "\n",
    "# for batch_idx, batch in enumerate(train_loader):\n",
    "#     user_ids, seq, target_item, labels = batch\n",
    "\n",
    "#     # Get the embeddings for the sequence\n",
    "#     sequence_embeddings = model.item_emb(batch[\"sequence\"])\n",
    "    \n",
    "\n",
    "#     # Pass the embeddings through the attention layer\n",
    "#     attention_output, _ = attention_layer(sequence_embeddings, sequence_embeddings, sequence_embeddings)\n",
    "#     # if any NaN values are found in the attention output, print the batch and the attention output\n",
    "#     if torch.isnan(attention_output).any():\n",
    "#         print(f\"Batch {batch_idx} - Attention output contains NaN values.\")\n",
    "#         print(batch[\"sequence\"])\n",
    "#         print(\"Sample seq:\", batch[\"sequence\"][0])\n",
    "#         print(\"Item emb weight stats:\", model.item_emb.weight.min(), model.item_emb.weight.max())\n",
    "#         print(attention_output)\n",
    "#         break\n",
    "#     # Example: Perform some operation with the attention output\n",
    "#     predictions = model.final_layer(attention_output[:, -1, :])  # Use the last position for predictions\n",
    "\n",
    "#     # Check for NaN values in predictions\n",
    "#     if torch.isnan(predictions).any():\n",
    "#         print(f\"Batch {batch_idx} - Predictions contain NaN values.\")\n",
    "#         print(batch[\"sequence\"])\n",
    "#         print(\"Sample seq:\", batch[\"sequence\"][0])\n",
    "#         print(\"Item emb weight stats:\", model.item_emb.weight.min(), model.item_emb.weight.max())\n",
    "#         print(predictions)\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6be76f",
   "metadata": {},
   "source": [
    "## overfit 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0675501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n",
      "\n",
      "  | Name  | Type   | Params | Mode \n",
      "-----------------------------------------\n",
      "0 | model | SASRec | 717 K  | train\n",
      "-----------------------------------------\n",
      "717 K     Trainable params\n",
      "0         Non-trainable params\n",
      "717 K     Total params\n",
      "2.871     Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ecd20f3b79436e808fee3c9c6e342d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:252: UserWarning:\n",
      "\n",
      "You requested to overfit but enabled val dataloader shuffling. We are turning off the val dataloader shuffling for you.\n",
      "\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:252: UserWarning:\n",
      "\n",
      "You requested to overfit but enabled train dataloader shuffling. We are turning off the train dataloader shuffling for you.\n",
      "\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:310: PossibleUserWarning:\n",
      "\n",
      "The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c229631dad03450f9d7bfb99e062c744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abde66a5795049ae8824b2ae7d94d84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eca94948f8f4428a538ac65b907ba74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff09ccfd9f94eeb8e948f7929d36142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58ac11f65a54bc9b4503149b17521c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56bb82c0cbdc4b05a3b0201c4f5e0277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87254ca1bc74acfa16db31a292448e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce20ea28a6904b18983500bcf2236ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65c2efd069c4c879b290f86f65e2f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7036469bd3504afc8fb7ee03cc0aabc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163a364db96240a98d341d2e73e2d97a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de6ee7d57564acba322ff501bf76ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594c8e1050144d5a97f439a1715e7b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1060e88b3c4de6bbae7a7564e7393f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c274777994441bb10d3aab2385d50f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df08c95ccb164ec4bbb0f144facfc43d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701a441af4ce4c97a8ba4a39fd4783dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0daae13445af425396052b44e373dbd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf76150ca6094f5a8239c3d2809d90ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c55bb345cd44c7a9a92d33333d2d0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6771e0cab1d7404b95a0ecc0800739ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1bf6dfcd0b47eb9e8416a75b2a92bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba68bc262a8b45f78dd0475719edd543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7088fa80f782412e8157ead08f590e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4474e2c5835448f4898b6ca04f0ea642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a496cbb427144e728c6edd4a04ab1a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14dd7d71dcbc41fc9d45f6ec58e541cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee25253de8bd4d348bf6ac8fcd84ee2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f685a1aa0f47af9f109743c0256530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a49138b717248dbb3e8f4f7f371d0f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c987a08fcb4c9a95ae0b47d6136ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f03ad25310b484e87d29ca77e130399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63d5545c1534ebe907bb524d06fe93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9ec282d35b49f2819171288b858ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07aa9a88aab8456a85cb2ee4d9b5a5ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bcdc66b965b44fb8139132bc2ea8ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73decab60978413bbb9da8cea2027baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a34d69d6f6f4d34a87d7ca49f58fce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-03 00:05:26.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.gSASRec.trainer\u001b[0m:\u001b[36mon_fit_end\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1mLogging classification metrics...\u001b[0m\n",
      "\u001b[32m2025-05-03 00:06:29.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.gSASRec.trainer\u001b[0m:\u001b[36mon_fit_end\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1mLogging ranking metrics...\u001b[0m\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\evidently\\metrics\\recsys\\f_beta_top_k.py:64: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "\u001b[32m2025-05-03 00:07:05.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.gSASRec.trainer\u001b[0m:\u001b[36mon_fit_end\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mEvidently metrics are available at: c:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\data\\first-attempt\\018-sasrec\u001b[0m\n",
      "\u001b[32m2025-05-03 00:07:05.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mLogs available at c:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\data\\first-attempt\\018-sasrec\\logs\\overfit\\lightning_logs\\version_86\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': [{'metric': 'NDCGKMetric', 'result': {'k': 10, 'current': 1     0.0\n",
      "2     0.0\n",
      "3     0.0\n",
      "4     0.0\n",
      "5     0.0\n",
      "6     0.0\n",
      "7     0.0\n",
      "8     0.0\n",
      "9     0.0\n",
      "10    0.0\n",
      "dtype: float64, 'current_value': 0.0, 'reference': None, 'reference_value': None}}, {'metric': 'RecallTopKMetric', 'result': {'k': 100, 'current': 0     0.000000\n",
      "1     0.000000\n",
      "2     0.000000\n",
      "3     0.000000\n",
      "4     0.000000\n",
      "        ...   \n",
      "95    0.000103\n",
      "96    0.000118\n",
      "97    0.000118\n",
      "98    0.000118\n",
      "99    0.000118\n",
      "Length: 100, dtype: float64, 'current_value': 0.00011809644216692368, 'reference': None, 'reference_value': None}}, {'metric': 'PrecisionTopKMetric', 'result': {'k': 100, 'current': 0     0.000000\n",
      "1     0.000000\n",
      "2     0.000000\n",
      "3     0.000000\n",
      "4     0.000000\n",
      "        ...   \n",
      "95    0.000008\n",
      "96    0.000008\n",
      "97    0.000008\n",
      "98    0.000008\n",
      "99    0.000008\n",
      "Length: 100, dtype: float64, 'current_value': 7.923447309075395e-06, 'reference': None, 'reference_value': None}}, {'metric': 'FBetaTopKMetric', 'result': {'k': 10, 'current': 0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "5   NaN\n",
      "6   NaN\n",
      "7   NaN\n",
      "8   NaN\n",
      "9   NaN\n",
      "dtype: float64, 'current_value': nan, 'reference': None, 'reference_value': None}}, {'metric': 'PersonalizationMetric', 'result': {'k': 10, 'current_value': 0.7022222222222223, 'current_table': {'2694': 1672, '3089': 1594, '2253': 1074, '2237': 1045, '3678': 1003, '3443': 946, '4516': 818, '954': 661, '3839': 640, '3585': 614}, 'reference_value': None, 'reference_table': None}}]}\n"
     ]
    }
   ],
   "source": [
    "# early_stopping = EarlyStopping(\n",
    "#     monitor=\"val_loss\", patience=5, mode=\"min\", verbose=False\n",
    "# )\n",
    "# # create log_dir if it does not exist\n",
    "# if not os.path.exists(args.notebook_persit_dp):\n",
    "#     os.makedirs(args.notebook_persit_dp, exist_ok=True)\n",
    "\n",
    "# model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "# lit_model = SASRecLitModule(\n",
    "#     model,\n",
    "#     log_dir=args.notebook_persit_dp,\n",
    "#     accelerator=args.device,\n",
    "#     lr=args.lr,\n",
    "#     l2_emb=args.l2_emb,\n",
    "#     idm= idm\n",
    "# )\n",
    "\n",
    "# log_dir = f\"{args.notebook_persit_dp}/logs/overfit\"\n",
    "# # create log_dir if it does not exist\n",
    "# if not os.path.exists(log_dir):\n",
    "#     os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# # train model\n",
    "# trainer = L.Trainer(\n",
    "#     default_root_dir=log_dir,\n",
    "#     accelerator=args.device if args.device else \"auto\",\n",
    "#     max_epochs=args.num_epochs,\n",
    "#     overfit_batches=1,\n",
    "#     callbacks=[early_stopping],\n",
    "# )\n",
    "# trainer.fit(\n",
    "#     model=lit_model,\n",
    "#     train_dataloaders=train_loader,\n",
    "#     val_dataloaders=train_loader,\n",
    "# )\n",
    "# logger.info(f\"Logs available at {trainer.log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ddfce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:654: UserWarning:\n",
      "\n",
      "Checkpoint directory C:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\data\\first-attempt\\018-sasrec\\checkpoints exists and is not empty.\n",
      "\n",
      "\n",
      "  | Name  | Type   | Params | Mode \n",
      "-----------------------------------------\n",
      "0 | model | SASRec | 717 K  | train\n",
      "-----------------------------------------\n",
      "717 K     Trainable params\n",
      "0         Non-trainable params\n",
      "717 K     Total params\n",
      "2.871     Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1d6638999f4dc98768bca19c1281fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b91c8ed1d104b3bad684bc3b6234f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:150\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:320\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer.lightning_module.automatic_optimization:\n\u001b[32m    319\u001b[39m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m     batch_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mautomatic_optimization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:192\u001b[39m, in \u001b[36m_AutomaticOptimization.run\u001b[39m\u001b[34m(self, optimizer, batch_idx, kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m result = closure.consume_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:270\u001b[39m, in \u001b[36m_AutomaticOptimization._optimizer_step\u001b[39m\u001b[34m(self, batch_idx, train_step_and_backward_closure)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moptimizer_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:176\u001b[39m, in \u001b[36m_call_lightning_module_hook\u001b[39m\u001b[34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\core\\module.py:1302\u001b[39m, in \u001b[36mLightningModule.optimizer_step\u001b[39m\u001b[34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[39m\n\u001b[32m   1278\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[32m   1279\u001b[39m \u001b[33;03mthe optimizer.\u001b[39;00m\n\u001b[32m   1280\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1300\u001b[39m \n\u001b[32m   1301\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1302\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\core\\optimizer.py:154\u001b[39m, in \u001b[36mLightningOptimizer.step\u001b[39m\u001b[34m(self, closure, **kwargs)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m._on_after_step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:239\u001b[39m, in \u001b[36mStrategy.optimizer_step\u001b[39m\u001b[34m(self, optimizer, closure, model, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl.LightningModule)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecision_plugin\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision.py:123\u001b[39m, in \u001b[36mPrecision.optimizer_step\u001b[39m\u001b[34m(self, optimizer, model, closure, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m closure = partial(\u001b[38;5;28mself\u001b[39m._wrap_closure, model, optimizer, closure)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\optim\\optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\optim\\adamw.py:220\u001b[39m, in \u001b[36mAdamW.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    219\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.enable_grad():\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         loss = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.param_groups:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision.py:109\u001b[39m, in \u001b[36mPrecision._wrap_closure\u001b[39m\u001b[34m(self, model, optimizer, closure)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03mhook is called.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \n\u001b[32m    108\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m closure_result = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[38;5;28mself\u001b[39m._after_closure(model, optimizer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:146\u001b[39m, in \u001b[36mClosure.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> Optional[Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28mself\u001b[39m._result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result.loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:131\u001b[39m, in \u001b[36mClosure.closure\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;129m@torch\u001b[39m.enable_grad()\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> ClosureResult:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m step_output.closure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:319\u001b[39m, in \u001b[36m_AutomaticOptimization._training_step\u001b[39m\u001b[34m(self, kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m trainer = \u001b[38;5;28mself\u001b[39m.trainer\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m training_step_output = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.strategy.post_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:328\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:391\u001b[39m, in \u001b[36mStrategy.training_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_redirection(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.lightning_module, \u001b[33m\"\u001b[39m\u001b[33mtraining_step\u001b[39m\u001b[33m\"\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\..\\src\\algo\\gSASRec\\trainer.py:68\u001b[39m, in \u001b[36mSASRecLitModule.training_step\u001b[39m\u001b[34m(self, batch, batch_idx)\u001b[39m\n\u001b[32m     66\u001b[39m labels = batch[\u001b[33m\"\u001b[39m\u001b[33mrating\u001b[39m\u001b[33m\"\u001b[39m].float()\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m predictions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_user_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_item_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_item_ids\u001b[49m\u001b[43m)\u001b[49m.view(labels.shape)\n\u001b[32m     70\u001b[39m loss_fn = \u001b[38;5;28mself\u001b[39m._get_loss_fn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\..\\src\\algo\\gSASRec\\model.py:191\u001b[39m, in \u001b[36mSASRec.forward\u001b[39m\u001b[34m(self, user_ids, seq, target_item)\u001b[39m\n\u001b[32m    190\u001b[39m seq_norm = \u001b[38;5;28mself\u001b[39m.attention_layernorms[i](seq_emb)\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m attn_out, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseq_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseq_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseq_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# lay thong tin batch co loi\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1373\u001b[39m, in \u001b[36mMultiheadAttention.forward\u001b[39m\u001b[34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1373\u001b[39m     attn_output, attn_output_weights = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\torch\\nn\\functional.py:6323\u001b[39m, in \u001b[36mmulti_head_attention_forward\u001b[39m\u001b[34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   6322\u001b[39m zero_attn_shape = (bsz * num_heads, \u001b[32m1\u001b[39m, head_dim)\n\u001b[32m-> \u001b[39m\u001b[32m6323\u001b[39m k = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   6324\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzero_attn_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   6325\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6326\u001b[39m v = torch.cat(\n\u001b[32m   6327\u001b[39m     [v, torch.zeros(zero_attn_shape, dtype=v.dtype, device=v.device)], dim=\u001b[32m1\u001b[39m\n\u001b[32m   6328\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[32m     32\u001b[39m trainer = L.Trainer(\n\u001b[32m     33\u001b[39m     default_root_dir=log_dir,\n\u001b[32m     34\u001b[39m     accelerator=args.device \u001b[38;5;28;01mif\u001b[39;00m args.device \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m     logger=args._mlf_logger \u001b[38;5;28;01mif\u001b[39;00m args.log_to_mlflow \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     42\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Change the library as a workaround for the issue in the latest Lightning release\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m#https://github.com/Lightning-AI/pytorch-lightning/pull/20669/commits/429f732a0528c558e701da7ec01e51c1e2e4f32e\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:65\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     64\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     68\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=args.early_stopping_patience, mode=\"min\", verbose=False, min_delta=0.0025\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{args.notebook_persit_dp}/checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "model = model.double()\n",
    "lit_model = SASRecLitModule(\n",
    "    model,\n",
    "    log_dir=args.notebook_persit_dp,\n",
    "    accelerator=args.device,\n",
    "    lr=args.lr,\n",
    "    l2_emb=args.l2_emb,\n",
    "    idm= idm\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persit_dp}/logs/run\"\n",
    "# create log_dir if it does not exist\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    # max_epochs=1,\n",
    "    # detect_anomaly=True,\n",
    "    max_epochs=args.num_epochs,\n",
    "    # gradient_clip_val=1.0,     \n",
    "    # gradient_clip_algorithm=\"norm\",\n",
    "    callbacks=[early_stopping, checkpoint_callback],\n",
    "    logger=args._mlf_logger if args.log_to_mlflow else None,\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")\n",
    "\n",
    "\n",
    "# Change the library as a workaround for the issue in the latest Lightning release\n",
    "#https://github.com/Lightning-AI/pytorch-lightning/pull/20669/commits/429f732a0528c558e701da7ec01e51c1e2e4f32e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8d60a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = [args]\n",
    "\n",
    "if args.log_to_mlflow:\n",
    "    run_id = trainer.logger.run_id\n",
    "\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        for params in all_params:\n",
    "            params_dict = params.model_dump()\n",
    "            params_ = dict()\n",
    "            for k, v in params_dict.items():\n",
    "                if k == \"top_K\":\n",
    "                    k = \"top_big_K\"\n",
    "                if k == \"top_k\":\n",
    "                    k = \"top_small_k\"\n",
    "                params_[f\"{params.__repr_name__()}.{k}\"] = v\n",
    "            mlflow.log_params(params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hm-scalablerecs-QHnDFvap-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
