{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6defc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52b77b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydantic import BaseModel\n",
    "import sys\n",
    "import os\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from loguru import logger\n",
    "from load_dotenv import load_dotenv\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import mlflow\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src.utils.embedding_id_mapper import IDMapper\n",
    "from src.algo.gSASRec.model import SASRec\n",
    "from src.algo.gSASRec.dataset import SASRecDataset\n",
    "from src.algo.gSASRec.trainer import SASRecLitModule\n",
    "from src.eval.utils import create_rec_df, create_label_df, merge_recs_with_target\n",
    "from src.eval.log_metrics import log_ranking_metrics, log_classification_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737a8749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ace436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-05 21:32:15.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mSetting up Mlflow experiment: first-attempt, run_name: 050-sasrec\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"testing\": false,\n",
      "  \"log_to_mlflow\": true,\n",
      "  \"experiment_name\": \"first-attempt\",\n",
      "  \"run_name\": \"050-sasrec\",\n",
      "  \"notebook_persit_dp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\notebooks\\\\data\\\\first-attempt\\\\050-sasrec\",\n",
      "  \"user_col\": \"user_id\",\n",
      "  \"item_col\": \"parent_asin\",\n",
      "  \"rating_col\": \"rating\",\n",
      "  \"timestamp_col\": \"timestamp\",\n",
      "  \"group_name\": \"seq-modelling\",\n",
      "  \"top_K\": 100,\n",
      "  \"top_k\": 10,\n",
      "  \"batch_size\": 512,\n",
      "  \"lr\": 0.0005,\n",
      "  \"l2_emb\": 0.0004,\n",
      "  \"early_stopping_patience\": 10,\n",
      "  \"device\": \"cpu\",\n",
      "  \"num_epochs\": 100,\n",
      "  \"max_len\": 10,\n",
      "  \"dropout\": 0.5,\n",
      "  \"hidden_units\": 128,\n",
      "  \"num_blocks\": 1,\n",
      "  \"num_heads\": 4,\n",
      "  \"num_workers\": 3,\n",
      "  \"train_data_fp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\data_for_ai\\\\interim\\\\train_sample_interactions_16407u_neg_seq.parquet\",\n",
      "  \"val_data_fp\": \"c:\\\\Users\\\\Trieu\\\\OneDrive\\\\Desktop\\\\recsys\\\\real_time_recsys\\\\data_for_ai\\\\interim\\\\val_sample_interactions_16407u_neg_seq.parquet\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Args(BaseModel):\n",
    "    testing: bool = False\n",
    "    log_to_mlflow: bool = True\n",
    "    experiment_name: str = \"first-attempt\"\n",
    "    run_name: str = f\"050-sasrec\"\n",
    "    notebook_persit_dp: str = None\n",
    "    \n",
    "    user_col: str = \"user_id\"\n",
    "    item_col: str = \"parent_asin\"\n",
    "    rating_col: str = \"rating\"\n",
    "    timestamp_col: str = \"timestamp\"\n",
    "    group_name: str = \"seq-modelling\"\n",
    "\n",
    "    top_K: int = 100\n",
    "    top_k: int = 10\n",
    "\n",
    "    batch_size: int = 512\n",
    "    lr: float = 0.0005\n",
    "    l2_emb: float = 0.0004\n",
    "    early_stopping_patience: int = 10\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    num_epochs: int = 100\n",
    "\n",
    "    # SASrec specific\n",
    "    max_len: int = 10\n",
    "    dropout: float = 0.5\n",
    "    hidden_units: int = 128\n",
    "    num_blocks: int = 1\n",
    "    num_heads: int = 8\n",
    "    num_workers: int = 3\n",
    "    # seq_length: int = 10\n",
    "    \n",
    "    train_data_fp: str = os.path.abspath(\"../data_for_ai/interim/train_sample_interactions_16407u_neg_seq.parquet\")\n",
    "    val_data_fp: str = os.path.abspath(\"../data_for_ai/interim/val_sample_interactions_16407u_neg_seq.parquet\")\n",
    "\n",
    "    def init(self):\n",
    "        self.notebook_persit_dp = os.path.abspath(f\"data/{self.experiment_name}/{self.run_name}\")\n",
    "\n",
    "        if not (mlflow_uri := os.environ.get(\"MLFLOW_TRACKING_URI\")):\n",
    "            self.log_to_mlflow = False\n",
    "            logger.warning(\"MLFlow is not enabled. Turn off tracking to Mlflow.\")\n",
    "\n",
    "        if self.log_to_mlflow:\n",
    "            logger.info(\n",
    "                f\"Setting up Mlflow experiment: {self.experiment_name}, run_name: {self.run_name}\"\n",
    "            )\n",
    "\n",
    "            self._mlf_logger = MLFlowLogger(\n",
    "                experiment_name=self.experiment_name,\n",
    "                run_name=self.run_name,\n",
    "                tracking_uri=mlflow_uri,\n",
    "                log_model=True,\n",
    "            )\n",
    "\n",
    "        if not self.testing:\n",
    "            os.makedirs(self.notebook_persit_dp, exist_ok=True)\n",
    "        return self\n",
    "    \n",
    "args = Args().init()\n",
    "print(args.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "383bb869",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(args.train_data_fp)\n",
    "train_df[args.rating_col] = train_df[args.rating_col].apply(lambda x: 1 if x > 0 else 0)    \n",
    "train_df = train_df[train_df['item_sequence'].apply(lambda seq: not all(item == -1 for item in seq))]        \n",
    "\n",
    "val_df = pd.read_parquet(args.val_data_fp)\n",
    "val_df[args.rating_col] = val_df[args.rating_col].apply(lambda x: 1 if x > 0 else 0)\n",
    "val_df = val_df[val_df['item_sequence'].apply(lambda seq: not all(item == -1 for item in seq))]\n",
    "\n",
    "assert set(val_df[args.user_col].unique()).issubset(set(train_df[args.user_col].unique())), \"Validation users must be present in training users.\"\n",
    "\n",
    "assert set(val_df[args.item_col].unique()).issubset(set(train_df[args.item_col].unique())), \"Validation items must be present in training items.\"\n",
    "assert train_df[args.timestamp_col].max() < val_df[args.timestamp_col].min(), \"Validation data must be after training data. Otherwise, its a data contamination problem.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca341b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B004FV4ROA</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-27 00:30:31.146</td>\n",
       "      <td>11295</td>\n",
       "      <td>528</td>\n",
       "      <td>[1898, 3479, 3908, 1570, 91, 2723, 2962, 106, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGSP5XAQPQBUUXZHEZSC65FD7NOQ</td>\n",
       "      <td>B07KFQFDNB</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-27 00:30:31.146</td>\n",
       "      <td>11295</td>\n",
       "      <td>3503</td>\n",
       "      <td>[3479, 3908, 1570, 91, 2723, 2962, 106, 3557, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AEHS7YR7BGGWMZS24H5UR5IP46HQ</td>\n",
       "      <td>B08F1P3BCC</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-27 01:44:52.242</td>\n",
       "      <td>1784</td>\n",
       "      <td>3925</td>\n",
       "      <td>[4319, 3382, 4330, 1173, 1330, 423, 2868, 3167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEHS7YR7BGGWMZS24H5UR5IP46HQ</td>\n",
       "      <td>B00HXT8EKE</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-27 01:44:52.242</td>\n",
       "      <td>1784</td>\n",
       "      <td>1507</td>\n",
       "      <td>[3382, 4330, 1173, 1330, 423, 2868, 3167, 1071...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGAVHCK42EGMVS7DGPRX6HBCUCNQ</td>\n",
       "      <td>B09Q3NR84W</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-27 02:25:48.357</td>\n",
       "      <td>9042</td>\n",
       "      <td>4273</td>\n",
       "      <td>[1311, 1416, 455, 3743, 1823, 2694, 3612, 3462...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6953</th>\n",
       "      <td>AEEQZRQBOFHFBFPYBX2BZ5WOI33A</td>\n",
       "      <td>B01A08E70K</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-19 16:56:53.030</td>\n",
       "      <td>1396</td>\n",
       "      <td>2441</td>\n",
       "      <td>[3451, 3827, 1839, 1347, 2504, 2694, 4546, 427...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6954</th>\n",
       "      <td>AHLN6GKTKZE22AON34YAQXTGK63A</td>\n",
       "      <td>B0C682GZ5X</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-19 17:28:55.519</td>\n",
       "      <td>14550</td>\n",
       "      <td>4772</td>\n",
       "      <td>[2950, 1812, 4735, 4165, 4575, 2440, 607, 4807...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6955</th>\n",
       "      <td>AHLN6GKTKZE22AON34YAQXTGK63A</td>\n",
       "      <td>B09SWWCN6Q</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-19 17:28:55.519</td>\n",
       "      <td>14550</td>\n",
       "      <td>4303</td>\n",
       "      <td>[1812, 4735, 4165, 4575, 2440, 607, 4807, 374,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6956</th>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B091K4WYD1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-19 22:08:53.253</td>\n",
       "      <td>2446</td>\n",
       "      <td>4086</td>\n",
       "      <td>[644, 3602, 4569, 1865, 3030, 3653, 3803, 3998...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6957</th>\n",
       "      <td>AEMYBWDN67IB5IBTMHLHN76V4QHQ</td>\n",
       "      <td>B005CTKYB4</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-19 22:08:53.253</td>\n",
       "      <td>2446</td>\n",
       "      <td>654</td>\n",
       "      <td>[3602, 4569, 1865, 3030, 3653, 3803, 3998, 285...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6958 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           user_id parent_asin  rating  \\\n",
       "0     AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B004FV4ROA       1   \n",
       "1     AGSP5XAQPQBUUXZHEZSC65FD7NOQ  B07KFQFDNB       0   \n",
       "2     AEHS7YR7BGGWMZS24H5UR5IP46HQ  B08F1P3BCC       1   \n",
       "3     AEHS7YR7BGGWMZS24H5UR5IP46HQ  B00HXT8EKE       0   \n",
       "4     AGAVHCK42EGMVS7DGPRX6HBCUCNQ  B09Q3NR84W       1   \n",
       "...                            ...         ...     ...   \n",
       "6953  AEEQZRQBOFHFBFPYBX2BZ5WOI33A  B01A08E70K       0   \n",
       "6954  AHLN6GKTKZE22AON34YAQXTGK63A  B0C682GZ5X       1   \n",
       "6955  AHLN6GKTKZE22AON34YAQXTGK63A  B09SWWCN6Q       0   \n",
       "6956  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B091K4WYD1       1   \n",
       "6957  AEMYBWDN67IB5IBTMHLHN76V4QHQ  B005CTKYB4       0   \n",
       "\n",
       "                   timestamp  user_indice  item_indice  \\\n",
       "0    2020-12-27 00:30:31.146        11295          528   \n",
       "1    2020-12-27 00:30:31.146        11295         3503   \n",
       "2    2020-12-27 01:44:52.242         1784         3925   \n",
       "3    2020-12-27 01:44:52.242         1784         1507   \n",
       "4    2020-12-27 02:25:48.357         9042         4273   \n",
       "...                      ...          ...          ...   \n",
       "6953 2022-02-19 16:56:53.030         1396         2441   \n",
       "6954 2022-02-19 17:28:55.519        14550         4772   \n",
       "6955 2022-02-19 17:28:55.519        14550         4303   \n",
       "6956 2022-02-19 22:08:53.253         2446         4086   \n",
       "6957 2022-02-19 22:08:53.253         2446          654   \n",
       "\n",
       "                                          item_sequence  \n",
       "0     [1898, 3479, 3908, 1570, 91, 2723, 2962, 106, ...  \n",
       "1     [3479, 3908, 1570, 91, 2723, 2962, 106, 3557, ...  \n",
       "2     [4319, 3382, 4330, 1173, 1330, 423, 2868, 3167...  \n",
       "3     [3382, 4330, 1173, 1330, 423, 2868, 3167, 1071...  \n",
       "4     [1311, 1416, 455, 3743, 1823, 2694, 3612, 3462...  \n",
       "...                                                 ...  \n",
       "6953  [3451, 3827, 1839, 1347, 2504, 2694, 4546, 427...  \n",
       "6954  [2950, 1812, 4735, 4165, 4575, 2440, 607, 4807...  \n",
       "6955  [1812, 4735, 4165, 4575, 2440, 607, 4807, 374,...  \n",
       "6956  [644, 3602, 4569, 1865, 3030, 3653, 3803, 3998...  \n",
       "6957  [3602, 4569, 1865, 3030, 3653, 3803, 3998, 285...  \n",
       "\n",
       "[6958 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21bc2bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFZ4EK2LJ655XQKTEUELCARO6RYA</td>\n",
       "      <td>B095JX15XF</td>\n",
       "      <td>0</td>\n",
       "      <td>2003-01-23 03:28:15.000</td>\n",
       "      <td>8071</td>\n",
       "      <td>4132</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFY2C4YOUP2SSMM43HD2L3FIEFZA</td>\n",
       "      <td>B00OQVZDJM</td>\n",
       "      <td>0</td>\n",
       "      <td>2003-11-25 18:12:09.000</td>\n",
       "      <td>7935</td>\n",
       "      <td>1859</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AHF3TGIOSTD2UCHF3MO4MIHFJ5NQ</td>\n",
       "      <td>B07KQWX947</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-06-18 02:02:57.000</td>\n",
       "      <td>13705</td>\n",
       "      <td>3514</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AH5Z47PJ5RTSUL2RLCO2QITGIT4Q</td>\n",
       "      <td>B07W4GJGCM</td>\n",
       "      <td>0</td>\n",
       "      <td>2004-09-13 20:18:44.000</td>\n",
       "      <td>12730</td>\n",
       "      <td>3734</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AEX3L4NKDESOCGWOFNF63GRFGXCA</td>\n",
       "      <td>B0067HY7HW</td>\n",
       "      <td>0</td>\n",
       "      <td>2004-10-22 14:26:12.000</td>\n",
       "      <td>3735</td>\n",
       "      <td>746</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254779</th>\n",
       "      <td>AES2U6KIAORYLTBPENQWMDVALTDQ</td>\n",
       "      <td>B07ZZVX1F2</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-26 21:37:58.968</td>\n",
       "      <td>3109</td>\n",
       "      <td>3800</td>\n",
       "      <td>[-1.0, 2237.0, 1691.0, 2694.0, 1633.0, 934.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254780</th>\n",
       "      <td>AGU6SDEIMLBQZII2FVFJ6YIUZRKQ</td>\n",
       "      <td>B0BSF5LM3J</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-26 22:29:54.459</td>\n",
       "      <td>11489</td>\n",
       "      <td>4622</td>\n",
       "      <td>[107.0, 3997.0, 2858.0, 1680.0, 2919.0, 4109.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254781</th>\n",
       "      <td>AGU6SDEIMLBQZII2FVFJ6YIUZRKQ</td>\n",
       "      <td>B0BZJ9BYZ3</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-26 22:29:54.459</td>\n",
       "      <td>11489</td>\n",
       "      <td>4696</td>\n",
       "      <td>[3997.0, 2858.0, 1680.0, 2919.0, 4109.0, 3695....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254782</th>\n",
       "      <td>AG2HB7HEYSIAGYBEFFL666KVYTHA</td>\n",
       "      <td>B0895KGSY1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-26 23:06:03.454</td>\n",
       "      <td>8251</td>\n",
       "      <td>3896</td>\n",
       "      <td>[-1.0, -1.0, 2531.0, 382.0, 2756.0, 3373.0, 34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254783</th>\n",
       "      <td>AG2HB7HEYSIAGYBEFFL666KVYTHA</td>\n",
       "      <td>B0029U2YSA</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-26 23:06:03.454</td>\n",
       "      <td>8251</td>\n",
       "      <td>289</td>\n",
       "      <td>[-1.0, 2531.0, 382.0, 2756.0, 3373.0, 3486.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238377 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id parent_asin  rating  \\\n",
       "1       AFZ4EK2LJ655XQKTEUELCARO6RYA  B095JX15XF       0   \n",
       "3       AFY2C4YOUP2SSMM43HD2L3FIEFZA  B00OQVZDJM       0   \n",
       "5       AHF3TGIOSTD2UCHF3MO4MIHFJ5NQ  B07KQWX947       1   \n",
       "7       AH5Z47PJ5RTSUL2RLCO2QITGIT4Q  B07W4GJGCM       0   \n",
       "9       AEX3L4NKDESOCGWOFNF63GRFGXCA  B0067HY7HW       0   \n",
       "...                              ...         ...     ...   \n",
       "254779  AES2U6KIAORYLTBPENQWMDVALTDQ  B07ZZVX1F2       1   \n",
       "254780  AGU6SDEIMLBQZII2FVFJ6YIUZRKQ  B0BSF5LM3J       1   \n",
       "254781  AGU6SDEIMLBQZII2FVFJ6YIUZRKQ  B0BZJ9BYZ3       0   \n",
       "254782  AG2HB7HEYSIAGYBEFFL666KVYTHA  B0895KGSY1       0   \n",
       "254783  AG2HB7HEYSIAGYBEFFL666KVYTHA  B0029U2YSA       1   \n",
       "\n",
       "                     timestamp  user_indice  item_indice  \\\n",
       "1      2003-01-23 03:28:15.000         8071         4132   \n",
       "3      2003-11-25 18:12:09.000         7935         1859   \n",
       "5      2004-06-18 02:02:57.000        13705         3514   \n",
       "7      2004-09-13 20:18:44.000        12730         3734   \n",
       "9      2004-10-22 14:26:12.000         3735          746   \n",
       "...                        ...          ...          ...   \n",
       "254779 2020-12-26 21:37:58.968         3109         3800   \n",
       "254780 2020-12-26 22:29:54.459        11489         4622   \n",
       "254781 2020-12-26 22:29:54.459        11489         4696   \n",
       "254782 2020-12-26 23:06:03.454         8251         3896   \n",
       "254783 2020-12-26 23:06:03.454         8251          289   \n",
       "\n",
       "                                            item_sequence  \n",
       "1       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "3       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "5       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "7       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "9       [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "...                                                   ...  \n",
       "254779  [-1.0, 2237.0, 1691.0, 2694.0, 1633.0, 934.0, ...  \n",
       "254780  [107.0, 3997.0, 2858.0, 1680.0, 2919.0, 4109.0...  \n",
       "254781  [3997.0, 2858.0, 1680.0, 2919.0, 4109.0, 3695....  \n",
       "254782  [-1.0, -1.0, 2531.0, 382.0, 2756.0, 3373.0, 34...  \n",
       "254783  [-1.0, 2531.0, 382.0, 2756.0, 3373.0, 3486.0, ...  \n",
       "\n",
       "[238377 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ad41a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(n_user, n_items, dropout, hidden_units, num_blocks, num_heads):\n",
    "    \"\"\"\n",
    "    Initialize the model with the given parameters.\n",
    "    \"\"\"\n",
    "    model = SASRec(\n",
    "        user_num = n_user,\n",
    "        item_num = n_items,\n",
    "        dropout_rate = dropout,\n",
    "        hidden_units = hidden_units,\n",
    "        num_blocks = num_blocks,\n",
    "        num_heads = num_heads,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17f32acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-05 21:32:22.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mNumber of users: 16407, Number of items: 4817\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các row NaN ngay sau init: []\n"
     ]
    }
   ],
   "source": [
    "item_indices = train_df[args.item_col].unique()\n",
    "user_indices = train_df[args.user_col].unique()\n",
    "n_items = len(item_indices)\n",
    "n_users = len(user_indices)\n",
    "\n",
    "logger.info(f\"Number of users: {n_users}, Number of items: {n_items}\")\n",
    "model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "emb_weights = model.item_emb.weight.data\n",
    "nan_rows = torch.isnan(emb_weights).any(dim=1).nonzero().squeeze().tolist()\n",
    "print(\"Các row NaN ngay sau init:\", nan_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3721313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3967]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = torch.tensor([7411])\n",
    "seq = torch.tensor([[1782, 1975, 3089, 3719, 4721, 3443, 4178, 2953, 684, 3401]])\n",
    "target_item = torch.tensor([[474]])\n",
    "predictions = model(user, seq, target_item)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beb513ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_num = 4817\n",
      "Padding token index: 4817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.4862e-03, -2.1793e-02,  1.3495e-02,  2.0228e-02,  1.2922e-02,\n",
       "          5.1636e-03,  1.2720e-02, -2.3668e-02, -1.2471e-03, -1.5433e-02,\n",
       "         -1.2523e-02,  2.1091e-02, -1.2338e-02,  1.9056e-02, -2.8543e-04,\n",
       "         -8.0733e-03, -4.1696e-02,  1.3169e-02, -4.6033e-02,  1.5589e-02,\n",
       "         -1.6338e-02,  1.9738e-02,  5.4753e-03,  1.2264e-02, -8.7587e-03,\n",
       "         -9.9318e-03,  2.4434e-02, -1.3355e-03,  2.3578e-02,  2.8056e-02,\n",
       "          1.3728e-02, -2.9685e-02, -3.5156e-02, -2.0388e-02,  3.7354e-02,\n",
       "          1.2534e-02,  3.2672e-02, -1.9796e-02,  2.5103e-02, -1.2852e-02,\n",
       "          2.3225e-02,  2.3252e-03, -2.1664e-02, -1.6950e-02,  9.0158e-04,\n",
       "          1.8577e-02, -8.7271e-03,  2.4325e-02, -1.1368e-02,  3.5014e-02,\n",
       "          1.8989e-02, -2.5415e-02,  7.5023e-03, -1.3683e-02,  2.2361e-02,\n",
       "          1.1535e-02, -9.7951e-03,  4.6113e-03, -6.4869e-03,  1.1308e-02,\n",
       "          5.3972e-02,  1.5254e-02, -4.0887e-05, -1.0531e-02,  1.3775e-02,\n",
       "          3.9870e-03,  4.9325e-03, -4.1758e-02,  3.6802e-03,  7.8679e-03,\n",
       "          1.9131e-02,  1.1882e-02,  1.2018e-02, -3.4192e-03,  8.7505e-03,\n",
       "          4.4311e-02, -1.7420e-02,  9.5933e-03,  8.5090e-03, -3.1513e-02,\n",
       "          2.8212e-02,  2.5951e-02, -2.3199e-02, -2.4014e-03, -7.3946e-03,\n",
       "          1.8460e-02, -2.7010e-02, -6.9427e-03,  2.6826e-02,  9.8935e-03,\n",
       "         -1.8091e-02, -8.2101e-03,  2.4687e-02, -7.8443e-03, -1.7309e-02,\n",
       "         -2.8100e-02, -2.3176e-02, -6.1840e-04,  2.6804e-02, -2.1511e-02,\n",
       "         -6.6959e-03, -1.4701e-02,  8.8175e-03,  7.5454e-03, -2.1803e-02,\n",
       "          2.7409e-02,  3.9474e-03,  2.8331e-02, -1.1925e-02,  1.4127e-02,\n",
       "         -6.3029e-03,  4.3393e-03, -1.4729e-03,  2.7559e-02, -7.2313e-03,\n",
       "          1.4939e-02,  3.8269e-02,  1.6245e-02, -4.6818e-03,  1.2817e-02,\n",
       "          2.0769e-02, -2.2892e-02, -2.2395e-02,  1.2886e-02, -1.7918e-02,\n",
       "          1.5940e-02,  1.2452e-02,  1.2833e-03]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"item_num = {model.item_num}\")\n",
    "print(f\"Padding token index: {model.item_emb.padding_idx}\")\n",
    "model.item_emb(torch.tensor([3089]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0e4c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 4\n",
    "# for i in range(0,10000):\n",
    "#     user = torch.tensor([[0]])\n",
    "#     seq = torch.randint(0, model.item_num, (batch_size, args.max_len))\n",
    "#     seq[:, :np.random.randint(1,10)] = model.item_num \n",
    "#     target_item = torch.tensor([[4000]])\n",
    "#     # print(f\"seq: {seq}\")\n",
    "#     predictions = model(user, seq, target_item)\n",
    "#     # if prediction is returned by nan values, then print the seq\n",
    "#     if torch.isnan(predictions).any():\n",
    "#         print(\"nan prediction\")\n",
    "#         print(seq)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85ec519d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SASRec(\n",
       "  (item_emb): Embedding(4818, 128, padding_idx=4817)\n",
       "  (pos_emb): Embedding(10, 128)\n",
       "  (emb_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (attention_layernorms): ModuleList(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (attention_layers): ModuleList(\n",
       "    (0): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (forward_layernorms): ModuleList(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (forward_layers): ModuleList(\n",
       "    (0): PointWiseFeedForward(\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "      (dropout1): Dropout(p=0.5, inplace=False)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "      (dropout2): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce5dddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_train_df = train_df.sample(frac=0.2, random_state=42)\n",
    "\n",
    "rating_dataset = SASRecDataset(\n",
    "    train_df, \"user_indice\", \"item_sequence\", \"item_indice\", \"rating\",args.max_len, n_items, args.timestamp_col, \n",
    ")\n",
    "val_rating_dataset = SASRecDataset(\n",
    "    val_df, \"user_indice\", \"item_sequence\", \"item_indice\", \"rating\", args.max_len, n_items, args.timestamp_col, \n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    rating_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True, num_workers=args.num_workers, persistent_workers=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_rating_dataset, batch_size=args.batch_size, shuffle=False, drop_last=False, num_workers=args.num_workers, persistent_workers=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe049bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in train_loader:\n",
    "#     print(i[\"user\"])\n",
    "#     print(i[\"sequence\"])\n",
    "#     print(i[\"item\"])\n",
    "#     print(i[\"rating\"])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "939d52ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AE227WAM4NWQPJI33OPN7ZARNNZQ'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idm_path = os.path.abspath(\"../data_for_ai/interim/idm_16407u.json\")\n",
    "idm = IDMapper().load(idm_path)\n",
    "idm.get_user_id(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bec2235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "\n",
    "# # 1. Hyper-params & setup\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# num_epochs = 10\n",
    "# lr = 1e-4          # giảm thêm nếu vẫn NaN\n",
    "# weight_decay = 1e-4\n",
    "# grad_clip_norm = 1.0\n",
    "\n",
    "# # 2. Dataset & DataLoader\n",
    "# # exist above \n",
    "\n",
    "# # 3. Model, Loss, Optimizer, Scheduler\n",
    "# model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "# model = model.to(device)\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1)\n",
    "\n",
    "# # 4. Anomaly detection (chỉ bật khi debug)\n",
    "# # torch.autograd.detect_anomaly(check_nan=True)\n",
    "\n",
    "# # for epoch in range(1, num_epochs + 1):\n",
    "#     ##### Training #####\n",
    "# epoch = 0\n",
    "# model.train()\n",
    "# total_train_loss = 0.0\n",
    "# for batch_idx, batch in enumerate(train_loader, 1):\n",
    "#     print(f\"Epoch {epoch} ─ batch {batch_idx}/{len(train_loader)}\")\n",
    "#     # if batch_idx == 10:\n",
    "#     #     break\n",
    "#     users    = batch[\"user\"].to(device)\n",
    "#     items    = batch[\"item\"].to(device)\n",
    "#     seqs     = batch[\"sequence\"].long().to(device)\n",
    "#     labels   = batch[\"rating\"].float().to(device)\n",
    "\n",
    "#     # Zero gradients\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     # Forward\n",
    "#     logits = model(users, seqs, items).view_as(labels)\n",
    "\n",
    "#     # Loss\n",
    "#     loss = criterion(logits, labels)\n",
    "#     total_train_loss += loss.item()\n",
    "#     # print(f\"Epoch {epoch} ─ batch {batch_idx}/{len(train_loader)} ─ loss: {loss.item():.4f}\")\n",
    "#     # Backward + gradient clipping\n",
    "#     try:\n",
    "#         loss.backward()\n",
    "#     except RuntimeError as e:\n",
    "#         print(f\"🚨 Backward failed: {e}\")\n",
    "#         # inspect tất cả gradients\n",
    "#         for name, p in model.named_parameters():\n",
    "#             if p.grad is not None:\n",
    "#                 has_nan = torch.isnan(p.grad).any().item()\n",
    "#                 print(f\"  grad for {name}: contains_nan={has_nan}, max_abs={p.grad.abs().max().item():.4e}\")\n",
    "#         raise  # vẫn ném exception để dừng\n",
    "#     torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip_norm)\n",
    "\n",
    "#     # (optional) log max grad for each layer\n",
    "#     for name, p in model.named_parameters():\n",
    "#         if p.grad is not None:\n",
    "#             if torch.isnan(p.grad).any():\n",
    "#                 print(f\"[NaN grad] {name}\")\n",
    "#             # print(f\"{name} grad_norm={p.grad.norm():.4f}\")\n",
    "\n",
    "#     # Step optimizer\n",
    "#     optimizer.step()\n",
    "\n",
    "# avg_train_loss = total_train_loss / len(train_loader)\n",
    "# print(f\"Epoch {epoch} ─ train_loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "# ##### Validation #####\n",
    "# # model.eval()\n",
    "# # total_val_loss = 0.0\n",
    "# # with torch.no_grad():\n",
    "# #     for batch in val_loader:\n",
    "# #         users  = batch[\"user\"].to(device)\n",
    "# #         items  = batch[\"item\"].to(device)\n",
    "# #         seqs   = batch[\"sequence\"].long().to(device)\n",
    "# #         labels = batch[\"rating\"].float().to(device)\n",
    "\n",
    "# #         logits = model(users, seqs, items).view_as(labels)\n",
    "# #         loss = criterion(logits, labels)\n",
    "# #         total_val_loss += loss.item()\n",
    "\n",
    "# # avg_val_loss = total_val_loss / len(val_loader)\n",
    "# # print(f\"Epoch {epoch} ─ val_loss:   {avg_val_loss:.4f}\")\n",
    "\n",
    "# # Scheduler step\n",
    "# # scheduler.step(avg_val_loss)\n",
    "\n",
    "# print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff6faaa",
   "metadata": {},
   "source": [
    "## check nan cases in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c9491de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "# # Extract the attention layer from the model\n",
    "# attention_layer = model.attention_layers[0]\n",
    "\n",
    "# for batch_idx, batch in enumerate(train_loader):\n",
    "#     user_ids, seq, target_item, labels = batch\n",
    "\n",
    "#     # Get the embeddings for the sequence\n",
    "#     sequence_embeddings = model.item_emb(batch[\"sequence\"])\n",
    "    \n",
    "\n",
    "#     # Pass the embeddings through the attention layer\n",
    "#     attention_output, _ = attention_layer(sequence_embeddings, sequence_embeddings, sequence_embeddings)\n",
    "#     # if any NaN values are found in the attention output, print the batch and the attention output\n",
    "#     if torch.isnan(attention_output).any():\n",
    "#         print(f\"Batch {batch_idx} - Attention output contains NaN values.\")\n",
    "#         print(batch[\"sequence\"])\n",
    "#         print(\"Sample seq:\", batch[\"sequence\"][0])\n",
    "#         print(\"Item emb weight stats:\", model.item_emb.weight.min(), model.item_emb.weight.max())\n",
    "#         print(attention_output)\n",
    "#         break\n",
    "#     # Example: Perform some operation with the attention output\n",
    "#     predictions = model.final_layer(attention_output[:, -1, :])  # Use the last position for predictions\n",
    "\n",
    "#     # Check for NaN values in predictions\n",
    "#     if torch.isnan(predictions).any():\n",
    "#         print(f\"Batch {batch_idx} - Predictions contain NaN values.\")\n",
    "#         print(batch[\"sequence\"])\n",
    "#         print(\"Sample seq:\", batch[\"sequence\"][0])\n",
    "#         print(\"Item emb weight stats:\", model.item_emb.weight.min(), model.item_emb.weight.max())\n",
    "#         print(predictions)\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6be76f",
   "metadata": {},
   "source": [
    "## overfit 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0675501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping = EarlyStopping(\n",
    "#     monitor=\"val_loss\", patience=5, mode=\"min\", verbose=False\n",
    "# )\n",
    "# # create log_dir if it does not exist\n",
    "# if not os.path.exists(args.notebook_persit_dp):\n",
    "#     os.makedirs(args.notebook_persit_dp, exist_ok=True)\n",
    "\n",
    "# model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "# lit_model = SASRecLitModule(\n",
    "#     model,\n",
    "#     log_dir=args.notebook_persit_dp,\n",
    "#     accelerator=args.device,\n",
    "#     lr=args.lr,\n",
    "#     l2_emb=args.l2_emb,\n",
    "#     idm= idm\n",
    "# )\n",
    "\n",
    "# log_dir = f\"{args.notebook_persit_dp}/logs/overfit\"\n",
    "# # create log_dir if it does not exist\n",
    "# if not os.path.exists(log_dir):\n",
    "#     os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# # train model\n",
    "# trainer = L.Trainer(\n",
    "#     default_root_dir=log_dir,\n",
    "#     accelerator=args.device if args.device else \"auto\",\n",
    "#     max_epochs=50,\n",
    "#     # max_epochs=args.num_epochs,\n",
    "#     overfit_batches=90,\n",
    "#     callbacks=[early_stopping],\n",
    "# )\n",
    "# trainer.fit(\n",
    "#     model=lit_model,\n",
    "#     train_dataloaders=train_loader,\n",
    "#     val_dataloaders=train_loader,\n",
    "# )\n",
    "# logger.info(f\"Logs available at {trainer.log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7ddfce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:654: UserWarning:\n",
      "\n",
      "Checkpoint directory C:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\data\\first-attempt\\050-sasrec\\checkpoints exists and is not empty.\n",
      "\n",
      "\n",
      "  | Name  | Type   | Params | Mode \n",
      "-----------------------------------------\n",
      "0 | model | SASRec | 717 K  | train\n",
      "-----------------------------------------\n",
      "717 K     Trainable params\n",
      "0         Non-trainable params\n",
      "717 K     Total params\n",
      "2.871     Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e5de07d48941f8b5b6ffb4220b2e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1e73f2050c4db584a80a2a50439df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca621e870ba44b190da7d2be75ac844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f810e6b9bfe7402d8afa5d82f1ca226e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44e4017c5984dd3ac3274772a0f1d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96f6550385841858dda7531ccc7597b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0537c19c097a416885f9436001113d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653828d642be44dc980d6b4318ce4672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022d70f4c5d2421f8dffb1b50552b654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcac63a195704877943490086dd92b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5721e8f2494afdb02247e89390268a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4042bf899447b48f01e732c08cf57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff5c60e80294b7da149c52fd4b3f417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d623836758c463085494a1c0dffdd00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4d622db19c42e491e18ff09c2b6652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1f8484fe96462fbbcc3feb5a2b7fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-05 21:46:55.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.algo.gSASRec.trainer\u001b[0m:\u001b[36mon_fit_end\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1mLogging classification metrics...\u001b[0m\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Invalid artifact path: 'best_checkpoint'. Names may be treated as files in certain cases, and must not resolve to other names when treated as such. This name would resolve to 'best_checkpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResponseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[31mResponseError\u001b[39m: too many 500 error responses",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py:942\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    941\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRetry: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, url)\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py:942\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    941\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRetry: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, url)\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "    \u001b[31m[... skipping similar frames: HTTPConnectionPool.urlopen at line 942 (4 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py:942\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    941\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRetry: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, url)\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py:932\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    931\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m932\u001b[39m     retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    518\u001b[39m     reason = error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    521\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPConnectionPool(host='138.2.61.6', port=5002): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/1/42c1f58452ec49ad9ebe8bbb8d66195b/artifacts/evidently_report_classification.html (Caused by ResponseError('too many 500 error responses'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRetryError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:181\u001b[39m, in \u001b[36mhttp_request\u001b[39m\u001b[34m(host_creds, endpoint, method, max_retries, backoff_factor, backoff_jitter, extra_headers, retry_codes, timeout, raise_on_status, respect_retry_after_header, **kwargs)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_http_response_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackoff_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackoff_jitter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_codes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraise_on_status\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost_creds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrespect_retry_after_header\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrespect_retry_after_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.exceptions.Timeout \u001b[38;5;28;01mas\u001b[39;00m to:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\mlflow\\utils\\request_utils.py:237\u001b[39m, in \u001b[36m_get_http_response_with_retries\u001b[39m\u001b[34m(method, url, max_retries, backoff_factor, backoff_jitter, retry_codes, raise_on_status, allow_redirects, respect_retry_after_header, **kwargs)\u001b[39m\n\u001b[32m    235\u001b[39m allow_redirects = env_value \u001b[38;5;28;01mif\u001b[39;00m allow_redirects \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m allow_redirects\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\requests\\adapters.py:691\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e.reason, ResponseError):\n\u001b[32m--> \u001b[39m\u001b[32m691\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RetryError(e, request=request)\n\u001b[32m    693\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e.reason, _ProxyError):\n",
      "\u001b[31mRetryError\u001b[39m: HTTPConnectionPool(host='138.2.61.6', port=5002): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/1/42c1f58452ec49ad9ebe8bbb8d66195b/artifacts/evidently_report_classification.html (Caused by ResponseError('too many 500 error responses'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1022\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1021\u001b[39m     call._call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mon_fit_end\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mon_fit_end\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1024\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: calling teardown hooks\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:176\u001b[39m, in \u001b[36m_call_lightning_module_hook\u001b[39m\u001b[34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\..\\src\\algo\\gSASRec\\trainer.py:128\u001b[39m, in \u001b[36mSASRecLitModule.on_fit_end\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    127\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLogging classification metrics...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_classification_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLogging ranking metrics...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\OneDrive\\Desktop\\recsys\\real_time_recsys\\notebooks\\..\\src\\algo\\gSASRec\\trainer.py:192\u001b[39m, in \u001b[36mSASRecLitModule._log_classification_metrics\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    191\u001b[39m mlf_client = \u001b[38;5;28mself\u001b[39m.logger.experiment\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m \u001b[43mmlf_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevidently_report_fp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m metric_result \u001b[38;5;129;01min\u001b[39;00m classification_performance_report.as_dict()[\u001b[33m\"\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\mlflow\\tracking\\client.py:2377\u001b[39m, in \u001b[36mMlflowClient.log_artifact\u001b[39m\u001b[34m(self, run_id, local_path, artifact_path)\u001b[39m\n\u001b[32m   2374\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m   2375\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid run id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. `log_artifact` run id must map to a valid run.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2376\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2377\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tracking_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:926\u001b[39m, in \u001b[36mTrackingServiceClient.log_artifact\u001b[39m\u001b[34m(self, run_id, local_path, artifact_path)\u001b[39m\n\u001b[32m    925\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m     \u001b[43martifact_repo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\mlflow\\store\\artifact\\http_artifact_repo.py:63\u001b[39m, in \u001b[36mHttpArtifactRepository.log_artifact\u001b[39m\u001b[34m(self, local_file, artifact_path)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(local_file, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     resp = \u001b[43mhttp_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_host_creds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPUT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m     augmented_raise_for_status(resp)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:204\u001b[39m, in \u001b[36mhttp_request\u001b[39m\u001b[34m(host_creds, endpoint, method, max_retries, backoff_factor, backoff_jitter, extra_headers, retry_codes, timeout, raise_on_status, respect_retry_after_header, **kwargs)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAPI request to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m failed with exception \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mMlflowException\u001b[39m: API request to http://138.2.61.6:5002/api/2.0/mlflow-artifacts/artifacts/1/42c1f58452ec49ad9ebe8bbb8d66195b/artifacts/evidently_report_classification.html failed with exception HTTPConnectionPool(host='138.2.61.6', port=5002): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/1/42c1f58452ec49ad9ebe8bbb8d66195b/artifacts/evidently_report_classification.html (Caused by ResponseError('too many 500 error responses'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[32m     32\u001b[39m trainer = L.Trainer(\n\u001b[32m     33\u001b[39m     default_root_dir=log_dir,\n\u001b[32m     34\u001b[39m     accelerator=args.device \u001b[38;5;28;01mif\u001b[39;00m args.device \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m     logger=args._mlf_logger \u001b[38;5;28;01mif\u001b[39;00m args.log_to_mlflow \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     42\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Change the library as a workaround for the issue in the latest Lightning release\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m#https://github.com/Lightning-AI/pytorch-lightning/pull/20669/commits/429f732a0528c558e701da7ec01e51c1e2e4f32e\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:68\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     65\u001b[39m     exit(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[43m_interrupt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m     trainer._teardown()\n\u001b[32m     70\u001b[39m     \u001b[38;5;66;03m# teardown might access the stage so we reset it after\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:82\u001b[39m, in \u001b[36m_interrupt\u001b[39m\u001b[34m(trainer, exception)\u001b[39m\n\u001b[32m     80\u001b[39m trainer.strategy.on_exception(exception)\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m logger \u001b[38;5;129;01min\u001b[39;00m trainer.loggers:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     \u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinalize\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfailed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning_utilities\\core\\rank_zero.py:41\u001b[39m, in \u001b[36mrank_zero_only.<locals>.wrapped_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe `rank_zero_only.rank` needs to be set before use\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rank == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m default\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loggers\\mlflow.py:289\u001b[39m, in \u001b[36mMLFlowLogger.finalize\u001b[39m\u001b[34m(self, status)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# log checkpoints as artifacts\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._checkpoint_callback:\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_scan_and_log_checkpoints\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_checkpoint_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.experiment.get_run(\u001b[38;5;28mself\u001b[39m.run_id):\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m.experiment.set_terminated(\u001b[38;5;28mself\u001b[39m.run_id, status)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\lightning\\pytorch\\loggers\\mlflow.py:369\u001b[39m, in \u001b[36mMLFlowLogger._scan_and_log_checkpoints\u001b[39m\u001b[34m(self, checkpoint_callback)\u001b[39m\n\u001b[32m    366\u001b[39m artifact_path = Path(\u001b[38;5;28mself\u001b[39m._checkpoint_path_prefix) / Path(p).stem\n\u001b[32m    368\u001b[39m \u001b[38;5;66;03m# Log the checkpoint\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# Create a temporary directory to log on mlflow\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tempfile.TemporaryDirectory() \u001b[38;5;28;01mas\u001b[39;00m tmp_dir:\n\u001b[32m    373\u001b[39m     \u001b[38;5;66;03m# Log the metadata\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\mlflow\\tracking\\client.py:2377\u001b[39m, in \u001b[36mMlflowClient.log_artifact\u001b[39m\u001b[34m(self, run_id, local_path, artifact_path)\u001b[39m\n\u001b[32m   2373\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_id.startswith(TRACE_REQUEST_ID_PREFIX):\n\u001b[32m   2374\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m   2375\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid run id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. `log_artifact` run id must map to a valid run.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2376\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2377\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tracking_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:926\u001b[39m, in \u001b[36mTrackingServiceClient.log_artifact\u001b[39m\u001b[34m(self, run_id, local_path, artifact_path)\u001b[39m\n\u001b[32m    924\u001b[39m     artifact_repo.log_artifacts(local_path, path_name)\n\u001b[32m    925\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m     \u001b[43martifact_repo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\mlflow\\store\\artifact\\http_artifact_repo.py:43\u001b[39m, in \u001b[36mHttpArtifactRepository.log_artifact\u001b[39m\u001b[34m(self, local_file, artifact_path)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlog_artifact\u001b[39m(\u001b[38;5;28mself\u001b[39m, local_file, artifact_path=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[43mverify_artifact_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m     \u001b[38;5;66;03m# Try to perform multipart upload if the file is large.\u001b[39;00m\n\u001b[32m     46\u001b[39m     \u001b[38;5;66;03m# If the server does not support, or if the upload failed, revert to normal upload.\u001b[39;00m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m     48\u001b[39m         MLFLOW_ENABLE_PROXY_MULTIPART_UPLOAD.get()\n\u001b[32m     49\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m os.path.getsize(local_file) >= MLFLOW_MULTIPART_UPLOAD_MINIMUM_FILE_SIZE.get()\n\u001b[32m     50\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trieu\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hm-scalablerecs-QHnDFvap-py3.11\\Lib\\site-packages\\mlflow\\store\\artifact\\artifact_repo.py:464\u001b[39m, in \u001b[36mverify_artifact_path\u001b[39m\u001b[34m(artifact_path)\u001b[39m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mverify_artifact_path\u001b[39m(artifact_path):\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artifact_path \u001b[38;5;129;01mand\u001b[39;00m path_not_unique(artifact_path):\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    465\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid artifact path: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbad_path_message(artifact_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    466\u001b[39m         )\n",
      "\u001b[31mMlflowException\u001b[39m: Invalid artifact path: 'best_checkpoint'. Names may be treated as files in certain cases, and must not resolve to other names when treated as such. This name would resolve to 'best_checkpoint'"
     ]
    }
   ],
   "source": [
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=args.early_stopping_patience, mode=\"min\", verbose=False, min_delta=0.0025\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{args.notebook_persit_dp}/checkpoints\",\n",
    "    filename=\"best_checkpoint\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "model = init_model(n_users, n_items, args.dropout, args.hidden_units, args.num_blocks, args.num_heads)\n",
    "# model = model.double()\n",
    "lit_model = SASRecLitModule(\n",
    "    model,\n",
    "    log_dir=args.notebook_persit_dp,\n",
    "    accelerator=args.device,\n",
    "    lr=args.lr,\n",
    "    l2_emb=args.l2_emb,\n",
    "    idm= idm\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persit_dp}/logs/run\"\n",
    "# create log_dir if it does not exist\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    # max_epochs=5,\n",
    "    # detect_anomaly=True,\n",
    "    max_epochs=args.num_epochs,\n",
    "    # gradient_clip_val=1.0,     \n",
    "    # gradient_clip_algorithm=\"norm\",\n",
    "    callbacks=[early_stopping, checkpoint_callback],\n",
    "    logger=args._mlf_logger if args.log_to_mlflow else None,\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")\n",
    "\n",
    "\n",
    "# Change the library as a workaround for the issue in the latest Lightning release\n",
    "#https://github.com/Lightning-AI/pytorch-lightning/pull/20669/commits/429f732a0528c558e701da7ec01e51c1e2e4f32e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8d60a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = [args]\n",
    "\n",
    "if args.log_to_mlflow:\n",
    "    run_id = trainer.logger.run_id\n",
    "\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        for params in all_params:\n",
    "            params_dict = params.model_dump()\n",
    "            params_ = dict()\n",
    "            for k, v in params_dict.items():\n",
    "                if k == \"top_K\":\n",
    "                    k = \"top_big_K\"\n",
    "                if k == \"top_k\":\n",
    "                    k = \"top_small_k\"\n",
    "                params_[f\"{params.__repr_name__()}.{k}\"] = v\n",
    "            mlflow.log_params(params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hm-scalablerecs-QHnDFvap-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
